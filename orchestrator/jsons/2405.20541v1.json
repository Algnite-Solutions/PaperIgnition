{
    "doc_id": "2405.20541v1",
    "title": "Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models",
    "authors": [
        "Zachary Ankner",
        "Cody Blakeney",
        "Kartik Sreenivasan",
        "Max Marion",
        "Matthew L. Leavitt",
        "Mansheej Paul"
    ],
    "categories": [
        "cs.LG",
        "cs.CL"
    ],
    "published_date": "2024-05-30 23:50:20+00:00",
    "abstract": "In this work, we investigate whether small language models can determine\nhigh-quality subsets of large-scale text datasets that improve the performance\nof larger language models. While existing work has shown that pruning based on\nthe perplexity of a larger model can yield high-quality data, we investigate\nwhether smaller models can be used for perplexity-based pruning and how pruning\nis affected by the domain composition of the data being pruned. We demonstrate\nthat for multiple dataset compositions, perplexity-based pruning of pretraining\ndata can \\emph{significantly} improve downstream task performance: pruning\nbased on perplexities computed with a 125 million parameter model improves the\naverage performance on downstream tasks of a 3 billion parameter model by up to\n2.04 and achieves up to a $1.45\\times$ reduction in pretraining steps to reach\ncommensurate baseline performance. Furthermore, we demonstrate that such\nperplexity-based data pruning also yields downstream performance gains in the\nover-trained and data-constrained regimes.",
    "text_chunks": [
        {
            "id": "S1",
            "type": "text",
            "title": "1Introduction",
            "caption": "1Introduction",
            "metadata": {},
            "text": "\n1 Introduction\nA large focus of the machine learning community has been improving the performance of large language models (LLMs) while reducing their training costs.\nIn this work, we consider how to improve the quality of an LLM by improving the quality of its pretraining data.\nAlthough there are many techniques to improve data quality, such as augmenting training samples with additional information\u00a0(Li et\u00a0al., 2024; Korbak et\u00a0al., 2023), in this work we focus on the predominant method of data pruning: intelligently selecting a high-quality subset of a larger dataset to train on.\n\nData pruning is commonly used for quality filtering of noisy text data.\nSimple approaches include using symbolic rules\u00a0(Bane et\u00a0al., 2022; Raffel et\u00a0al., 2020) or using simple classifiers to determine high-quality samples\u00a0(Wenzek et\u00a0al., 2020).\nHowever, in addition to basic quality filtering, more complex data pruning techniques are also applied to datasets to further improve their quality.\nXie et\u00a0al. (2023b) perform importance resampling where importance scores are calculated based on feature similarity to a target text.\nTirumala et\u00a0al. (2023) prune datasets by deduplicating and diversifying data based on a pretrained language model\u2019s embeddings of the text samples.\nXie et\u00a0al. (2023a) re-weight domain proportions based on learnability as determined by a smaller proxy model.\nMarion et\u00a0al. (2023) investigate data pruning based on multiple neural heuristics of sample difficulty, ultimately concluding that the perplexity of a sample under a reference language model is the best pruning metric.\n\nIn this work, we thoroughly investigate the impact that data pruning based on sample perplexity\u00a0(Marion et\u00a0al., 2023) has on LLM pretraining.\nIn particular, we focus on the interplay between pretraining dataset composition and pruning methodology.\nWe further evaluate perplexity pruning in the over-trained and data-constrained regimes.\nWe also investigate whether evaluating the quality of data interventions based on upstream test set perplexity is a sound methodology for gauging downstream performance.\nTo perform perplexity-based data pruning, we train a small language model on a random subset of the given pretraining dataset and then evaluate its perplexity on each sample in the dataset.\nWe then prune the dataset to only include samples within some range of perplexities (i.e., sub-sample to the highest or lowest perplexity samples).\nWe demonstrate that for two vastly different pretraining data compositions, a small language model can be used to effectively prune the pretraining dataset of a significantly larger model, leading to significant gains in the final model\u2019s downstream performance.\n\nOur work differs from previous work on perplexity-based data pruning for LLM pretraining in three key ways: (i) our emphasis on downstream model quality evaluation, (ii) our exploration of different pretraining dataset domain compositions, and (iii) our analysis of pruning in non-standard training regimes.\nWhile previous works evaluate the resulting LLM\u2019s quality based on upstream metrics such as perplexity on the test split of the pretraining dataset, we evaluate data pruning\u2019s impact based on downstream evaluation benchmarks (e.g. mmlu\u00a0(Hendrycks et\u00a0al., 2021), hellaswag(Zellers et\u00a0al., 2019), etc.).\nEvaluating on more meaningful benchmarks enables us to make stronger, more rigorous conclusions about the impact of perplexity-based data pruning, as we find that some techniques that significantly improve downstream performance have no, or even adverse, effects on upstream performance.\nThis difference in metrics enables us to conclude that smaller models can prune the data for larger models, which was not observed in previous perplexity-basd pruning works.\nSecondly, while previous work only investigates pruning on datasets composed of just one domain (CommonCrawl111https://data.commoncrawl.org/), we consider two datasets with different domain compositions: the Pile\u00a0(Gao et\u00a0al., 2020) and Dolma\u00a0(Soldaini et\u00a0al., 2024).\nThe Pile is composed of many diverse curated domains, with only 15.61% of the data being derived from general web-scrapes, while Dolma is a web-scrape skewed dataset, with 81.31% of its data being derived from the CommonCrawl.\nWe find that successful pruning techniques vary greatly for different dataset compositions to the point that the best technique for one dataset composition may degrade performance for a different composition.\nFinally, we also evaluate perplexity-based data pruning in the less standard regimes of over-training and data-constrained training.\nThis investigation provides a broader understanding for when practitioners should use perplexity pruning for their data.\n\nContributions\nOur work makes the following contributions:\n\n\u2022\nWe demonstrate that, across three datasets of varying domain compositions, a small reference model can effectively prune the pretraining dataset of a significantly larger language model (30\u00d730\\times30 \u00d7 greater parameters), providing both a significant increase in downstream performance and decrease in pretraining steps (Table\u00a01 and Figure\u00a01).\n\n\u2022\nWe show that data pruning techniques can be highly sensitive to the domain composition of the dataset, suggesting the need to evaluate multiple distinct dataset compositions when conducting data pruning research (Table\u00a01 and Table\u00a04).\n\n\u2022\nWe investigate perplexity-based data pruning in multiple non-standard settings demonstrating that it can still lead to gains when over-training and when data-constrained (Section\u00a03.4 and Section\u00a03.5).\n\n\u2022\nWe find that test set perplexity can be a misleading metric for evaluating the efficacy of data pruning techniques, as interventions that result in significantly higher test set perplexity can still achieve better performance on downstream tasks (Table\u00a03).\n\n\n"
        },
        {
            "id": "S2",
            "type": "text",
            "title": "2Perplexity-Based Data Pruning",
            "caption": "2Perplexity-Based Data Pruning",
            "metadata": {},
            "text": "\n2 Perplexity-Based Data Pruning\n\nWe start by training a reference model that will be used to calculate the perplexity of all samples in our dataset.\nFirst, we partition the original dataset into two splits: one for training the reference model and one for training the final model.\nAfter training the reference model on the standard next-token prediction objective, we compute the reference model\u2019s perplexity on each of the samples in the final model\u2019s training split.\nWe then prune the final model\u2019s dataset split to a fraction of its original size, referred to as the selection rate (rssubscript\ud835\udc5f\ud835\udc60r_{s}italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT), by selecting samples according to a selection criteria which can be one of low, medium, or high.\nIn low selection, samples with the lowest perplexity are selected.\nIn medium selection, we select samples whose perplexity is close to the median perplexity, that is, samples with perplexity in the [50\u2212rs2,50+rs2]50subscript\ud835\udc5f\ud835\udc60250subscript\ud835\udc5f\ud835\udc602[50-\\frac{r_{s}}{2},50+\\frac{r_{s}}{2}][ 50 - divide start_ARG italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG , 50 + divide start_ARG italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG ] percentiles of all perplexities.\nIn high selection, samples with the highest perplexity are selected.\nAfter pruning our dataset, we train a final model using the standard next token prediction objective on the pruned version of the final model training split.\nWe present a pseudocode for pruning based on perplexity in Algorithm\u00a01.\n\nWe consider the setting in which the reference model is significantly smaller than the final model.\nWhile this assumption is not strictly necessary, we believe that it is the most practically relevant setup, as it best reflects a data pruning paradigm that would be used for the next generation of LLMs where the models being trained are larger than any existing models.\n"
        },
        {
            "id": "S3",
            "type": "text",
            "title": "3Experiments",
            "caption": "3Experiments",
            "metadata": {},
            "text": "\n3 Experiments\n\n3.1 Setup\nModels.\nAll models are based on the MPT family of transformer models\u00a0(Vaswani et\u00a0al., 2017; MosaicML, 2023c).\nAll reference models have 125 million parameters, and we consider final models with 1 billion and 3 billion parameters.\n\nData.\nWe consider two datasets in this work.\nThe Pile\u00a0(Gao et\u00a0al., 2020) is composed of 22 different domains that range from general web scrapes to legal text.\nDolma\u00a0(Soldaini et\u00a0al., 2024) is composed of 7 different domains and is derived mainly from general web scrapes.\nWe tokenize all datasets using the GPT-4 tokenizer\u00a0(OpenAI, 2022).\n\nTraining and hyperparameters.\nAll reference models are trained for a fixed duration of 26 billion tokens. Unless otherwise specified, all final models are trained to Chinchilla optimal\u00a0(Hoffmann et\u00a0al., 2022), meaning that each final model\u2019s training duration in tokens is 20 times its parameter count.\nAll models are trained using the decoupled Lion optimizer\u00a0(Chen et\u00a0al., 2024) with a cosine learning rate schedule.\nAll reference models and 1B parameter models are trained with a maximum learning rate and weight decay of 2e-4 and all 3B models are trained with a maximum learning rate and weight decay of 1.6e-4.\nTraining is conducted using llm-foundry\u00a0(MosaicML, 2023b) and using both Nvidia A100s and H100s.\nWe perform two trials for each experiment.\n\nEvaluation.\nWe evaluate models on 33 different downstream question-answering tasks using the MosaicML evaluation gauntlet\u00a0(MosaicML, 2023a).\nBefore averaging the accuracy across tasks, we normalize each task by the baseline of random guessing\n222Not to be confused, the random accuracy normalization we use is different from the normalized accuracy reported by the EleutherAI LM Evaluation Harness, which normalizes based on the Byte-length of the response..\nSpecifically, we normalize the accuracy of each individual task as an=am\u2212ar1\u2212arsubscript\ud835\udc4e\ud835\udc5bsubscript\ud835\udc4e\ud835\udc5asubscript\ud835\udc4e\ud835\udc5f1subscript\ud835\udc4e\ud835\udc5fa_{n}=\\frac{a_{m}-a_{r}}{1-a_{r}}italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = divide start_ARG italic_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT - italic_a start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG start_ARG 1 - italic_a start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG, where amsubscript\ud835\udc4e\ud835\udc5aa_{m}italic_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT is the accuracy of the model and arsubscript\ud835\udc4e\ud835\udc5fa_{r}italic_a start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is the expected accuracy of random guessing.\nWe report the average normalized accuracy for each task category as well as the average normalized accuracy across all task categories.\nMore details on tasks and task categories are listed in\u00a0Section\u00a08.\n\n\n3.2 Perplexity-Based Data Pruning Improves Downstream Performance\n\nIf a certain range of perplexities is a good heuristic for data quality, training on that perplexity-pruned subset should improve downstream performance.\nWe sweep across pruning selection criteria and selection rates (Section\u00a07) and find that the best settings are to select high-perplexity samples at a 50% rate for the Pile and to select medium-perplexity samples at a 50% rate for Dolma.\nWe compare the most performant pruning settings to baseline models trained on the original datasets without pruning in\u00a0Table\u00a01.\nAcross all datasets and model sizes, models pretrained on the perplexity pruned version of the dataset significantly outperform the baseline model on average.\nSpecifically, perplexity-based data pruning outperforms the average downstream performance of no pruning for 1B models by 1.89 and 1.51 for the Pile and Dolma respectively, and improves the performance of 3B models by 2.04 and 0.59 for the Pile and Dolma respectively.\nThese results suggest that the perplexity of a small model provides a strong signal of data quality for a much larger model, as training on the data selected by the small model leads to significant downstream performance improvements.\n\n\n3.3 Perplexity-Based Data Pruning Improves Training Efficiency\n\nSince perplexity-based data pruning improves the final performance of models, we also investigate how pruned data affects the training dynamics of models.\nSpecifically, we investigate whether training on perplexity pruned data enables models to achieve the same downstream performance as models trained on the unpruned data in training fewer steps.\nWe plot the average downstream performance of partially trained checkpoints from the 1B baseline and perplexity pruned models in\u00a0Figure\u00a01.\nPerplexity pruning outperforms the baseline model for all intermediate pretraining durations evaluated.\nFurthermore, perplexity pruned models reach the same average normalized accuracy as the baseline models in 1.31\u00d71.31\\times1.31 \u00d7 and 1.45\u00d71.45\\times1.45 \u00d7 fewer steps for Pile 1B and 3B respectively and in 1.29\u00d71.29\\times1.29 \u00d7 and 1.14\u00d71.14\\times1.14 \u00d7 fewer steps for Dolma 1B and Dolma 3B respectively.\nThese results demonstrate that the resulting high-quality data from perplexity-based data pruning enables faster learning which can be leveraged to achieve the same downstream performance as training on unpruned data with fewer pretraining steps.\n\n\n3.4 Perplexity-Based Data Pruning for Over-Trained Models\n\nA recent trend with LLMs has been to over-train models by training them on more tokens than the Chinchilla optimal number of tokens\u00a0(Touvron et\u00a0al., 2023; Gadre et\u00a0al., 2024).\nAs our work targets the data component of LLM pretraining, we investigate the hypothesis that over-training would be more beneficial for models trained on perplexity pruned datasets as the data is of higher quality.\nWe test this hypothesis by training a 1B parameter model for 130B tokens, which is 5\u00d75\\times5 \u00d7 the Chinchilla optimal number of tokens.\nWe evaluate the downstream performance of each over-trained model in\u00a0Table\u00a02.\nThe main observation is that while the absolute gain in average downstream normalized accuracy from perplexity-based data pruning on the Pile is similar for both compute optimal and over-trained models, the gain decreases for Dolma when over-training.\nOn the Pile, we find that the gain from perplexity pruned data is similar in the compute optimal regime and the over-trained regime: we see a gain in average performance of 1.89 when training compute optimal and a gain of 1.74 when over-training.\nOn Dolma, the gain from perplexity pruned data decreases in the over-trained regime: we see a gain of 1.51 when training for a compute optimal duration but this decreases to a gain of 0.84 when over-training.\nThese results show that while the higher quality data resulting from perplexity-based data pruning does still lead to an improvement in downstream performance in the over-trained regime, there is not a relative increase in downstream improvement over the baseline when over-training.\n\n\n3.5 Perplexity-Based Data Pruning for the Data Constrained Regime\nOur experiments so far were conducted in the setting where there exists a sufficient abundance of data such that even after pruning with the desired selection rate there are enough data points to fill the desired token budget without requiring any data to be repeated.\nHowever, there are many training settings that do not fall under this data-abundant regime.\nConsequently, we evaluate how perplexity-based data pruning performs when the number of tokens is constrained, and pruning induces a greater number of repetitions of the data.\nFor each dataset, we vary the available data such that training for a Chinchilla optimal number of tokens requires a different number of repetitions.\nSpecifically, we investigate data budgets that require {0.5,1,2,4,8} repetitions to reach the Chinchilla optimal333Repeat=0.5 means that the available number of tokens is twice the training budget, i.e. the data-abundant setting.\nAs each number of repeats refers to the total number of tokens available, for all pruning experiments the number of repetitions after pruning is actually greater by a factor of 1rs1subscript\ud835\udc5f\ud835\udc60\\frac{1}{r_{s}}divide start_ARG 1 end_ARG start_ARG italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG since we prune the available tokens according to rssubscript\ud835\udc5f\ud835\udc60r_{s}italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, the selection rate.\nSince all models use a selection rate of 0.50.50.50.5, the models trained on the pruned data see the data for 2\u00d72\\times2 \u00d7 more repetitions.\n\nWe plot the average downstream performance as a function of the number of repetitions in\u00a0Figure\u00a02.\nOn both the Pile and Dolma, we find that training on perplexity pruned data yields an improvement for up to two repetitions.\nThese results suggest that perplexity-based data pruning can still provide performance gains for some degree of data constraint.\nFurthermore, our results replicate the findings of Muennighoff et\u00a0al. (2023) that more than four repetitions yields negligible gains.\nSpecifically, the baseline model without pruning maintains commensurate performance for up to four repetitions.\nSimilarly, models trained on perplexity-pruned data maintain commensurate performance for up to two repetitions through the base data, which corresponds to four repetitions after pruning.\nThat training on repeated perplexity-pruned data leads to diminishing gains after four repetitions post-pruning suggests that the higher quality data resulting from pruning does not change the point for which repeating data yields diminishing improvements in performance.\n\n\n3.6 Upstream Perplexity is not a Reliable Evaluation Metric for Data Pruning\n\nAs previous works have used the perplexity of the model on a test split of the pretraining dataset as an approximation to downstream performance, we wanted to explore how well such perplexity-based evaluations agree with downstream performance for data intervention techniques.\nPruning performs an intervention on the dataset, making models trained on the pruned dataset biased estimators of the original data distribution.\nTherefore, it is unlikely that the performance on the original data distribution is a fair evaluation of model quality.\nWe compare the test set perplexity and average downstream performance for 1 billion parameter models trained on the original and pruned version of the Pile and Dolma in\u00a0Table\u00a03.\nFor both the Pile and Dolma, training on perplexity pruned data significantly worsens perplexity on a test split of the pretraining data, while the average downstream performance is significantly improved.\nThis result suggests that test set perplexity may not always be a sound metric for data pruning work and that researchers should instead directly evaluate on downstream benchmarks.\n\n"
        },
        {
            "id": "S4",
            "type": "text",
            "title": "4Understanding the Effects of Perplexity-Based Pruning",
            "caption": "4Understanding the Effects of Perplexity-Based Pruning",
            "metadata": {},
            "text": "\n4 Understanding the Effects of Perplexity-Based Pruning\nIn this section, we investigate how data pruning works by exploring some of the properties of perplexity-based pruning.\n\n4.1 How Are Reference Perplexities Distributed\n\nIn order to better understand how perplexity-based data pruning works, we investigate the distribution of the computed reference model perplexities for each dataset.\nFor each dataset, we randomly sample 10% of the calculated perplexities and perform kernel density estimation to estimate the distribution of log perplexities for a given dataset.\nWe repeat this procedure for the optimal pruned version of the dataset.\nWe plot the resulting estimates of the log perplexity distribution in\u00a0Figure\u00a03.\nWe find that the log perplexity distribution for the Pile is multimodal and asymmetric, while for Dolma and it is unimodal and symmetric.\n\n\n4.2 How Pruning Affects Domain Composition\n\nWe can also interpret the effect that perplexity-based data pruning has on a dataset by examining how pruning affects each domain\u2019s proportion of the total dataset.\nWe plot the pre and post-pruning domain compositions for the Pile and Dolma in\u00a0Figure\u00a04.\nInterestingly, for all datasets pruning increases the proportion of data coming from web-scraped domains while decreasing the proportion of data coming from highly specific technical domains such as code or scientific papers.\nThis trend is more pronounced in the Pile, where the proportions of Pile-CC and OpenWebText2 nearly double, while the proportions of domains such as Pubmed Central, ArXiv, and Github are all reduced by at least a factor of three.\nFuture work should investigate how perplexity-based pruning affects a model\u2019s performance on downstream tasks that are in the same category as the highly pruned domains.\n\n"
        },
        {
            "id": "S5",
            "type": "text",
            "title": "5Related Work",
            "caption": "5Related Work",
            "metadata": {},
            "text": "\n5 Related Work\nClassical methods for pruning text data.\nIn order to improve the quality of raw web scrapes, which often contain very noisy samples, pruning via quality filtering has become a common practice.\nSimple rules-based methods have been employed to prune datasets by filtering out low-quality samples according to some hand-crafted heuristic such as whether the text contains prohibited words, is predominantly English, etc.\u00a0(Bane et\u00a0al., 2022; Raffel et\u00a0al., 2020; Rae et\u00a0al., 2022; Penedo et\u00a0al., 2023).\nN-gram perplexity-based methods, in which an n-gram model is first trained on a high quality, curated corpus and then used to score another corpus, have also been applied to filter text data\u00a0(Moore & Lewis, 2010; Axelrod, 2017; Gao, 2021; Lauren\u00e7on et\u00a0al., 2022; Muennighoff et\u00a0al., 2023).\nAlthough our method also uses perplexity to prune data, it does so in a very different manner.\nIn n-gram perplexity pruning, perplexity is used to estimate whether new text is in distribution as compared to the currated text the n-gram was trained on, while in our model-based perplexity pruning, the reference model is trained on the same distribution of text and the perplexity is more akin to an estimate of the difficulty of an example.\nIn this work, the datasets we leverage already have some basic rules-based pruning applied, and as such, the method we investigate is largely complementary to these existing techniques.\n\nNeural network based methods for pruning text data.\nRecently, there has been much interest in using neural networks to compute metrics that can be used to intelligently prune datasets.\nA common technique in this family of methods is using a model to sample high-quality data from large datasets based on the sample\u2019s similarity to a curated high-quality corpus that serves as a target distribution\u00a0(Feng et\u00a0al., 2022; Xie et\u00a0al., 2023b).\nXie et\u00a0al. (2023a) also consider how to use a small reference model to prune pretraining data for a much larger model, by using a small reference model to learn the optimal weighting of domain proportions to maximize the \"learnability\" of the resulting dataset.\nPruning based on the difficulty or loss of a sample has previously been explored for text data, but the majority of such work focuses on curating data for finetuning\u00a0(Swayamdipta et\u00a0al., 2020; Attendu & Corbeil, 2023; Coleman et\u00a0al., 2020; Mindermann et\u00a0al., 2022; Mekala et\u00a0al., 2024).\nMarion et\u00a0al. (2023), however, investigate multiple model-based sample difficulty heuristics for pruning pretraining text datasets.\nAlthough we use the same method for pruning text pretraining datasets, our analysis differs substantially as we evaluate model quality based on downstream metrics and extend our analysis to multiple different dataset compositions which enables us to conclude that the reference model can be smaller than the final model.\n\nData pruning on vision tasks.\nWhile data pruning is becoming more and more relevant with large amounts of text data, it has also been extensively applied in the vision domain\u00a0(Paul et\u00a0al., 2021; Toneva et\u00a0al., 2018; Park et\u00a0al., 2023). These works often prune data points based on their loss or gradients during training\u00a0(Killamsetty et\u00a0al., 2021; Mirzasoleiman et\u00a0al., 2020). Model-based methods have also been leveraged for image data pruning\u00a0(Fang et\u00a0al., 2024; Schuhmann et\u00a0al., 2021). Note that in the literature, data pruning is also sometimes referred to as coreset selection\u00a0(Guo et\u00a0al., 2022). More recently, Park et\u00a0al. (2022) show that, somewhat surprisingly, active learning\u00a0(Castro & Nowak, 2008) based algorithms tend to outperform most data subset selection algorithms. In the context of contrastive learning, hard-negative mining has been effective as a data pruning method\u00a0(Kalantidis et\u00a0al., 2020; Robinson et\u00a0al., 2020; Zhang & Stratos, 2021).\nRecently, Goyal et\u00a0al. (2024) investigated scaling laws for training on pruned data in the context of vision models.\n\n"
        },
        {
            "id": "S6",
            "type": "text",
            "title": "6Conclusion",
            "caption": "6Conclusion",
            "metadata": {},
            "text": "\n6 Conclusion\nIn this work, we conduct an empirical investigation of the impact that perplexity-based data pruning has on model performance.\nWe demonstrate that small reference models can be used to prune the data of models with up to 30\u00d7\\times\u00d7 more parameters, leading to both significant downstream performance improvements and increased training efficiency.\nWe then investigate perplexity-based data pruning in two non-standard settings: the over-trained and data-constrained regimes.\nWe find that for both settings, training on perplexity pruned data can outperform training on unpruned data, demonstrating that perplexity-based data pruning is a widely applicable and extensible technique.\nWe also investigate upstream metrics for evaluating data pruning techniques and provide an example where evaluating models based on their perplexity on the test split of the pretraining dataset does not align with evaluating based on downstream model performance.\nAdditionally, we demonstrate that optimal pruning techniques can vary greatly for different dataset compositions.\nAlthough we do not present a predictive theory for how pruning parameters should be selected for different datasets, we demonstrate that the optimal pruning parameters for a 1 billion parameter model can successfully transfer to 3\u00a0billion parameter models, potentially suggesting that empirically determining the optimal pruning parameters can be done cheaply.\nOur work takes a key step towards establishing perplexity-based data pruning as a primary technique in the modern data researcher\u2019s toolkit.\n\nAcknowledgments\nThere are a few people who we would like to express our deepest gratitude for the assistance they provided.\nSean Owen helped us with his encyclopedic knowledge of PySpark.\nSam Havens and Daniel King both helped advise the early stages of this work.\nBrett Larsen provided feedback on the presentation of our results.\n\n"
        },
        {
            "id": "S7",
            "type": "text",
            "title": "7Full Data Pruning Settings Sweep",
            "caption": "7Full Data Pruning Settings Sweep",
            "metadata": {},
            "text": "\n7 Full Data Pruning Settings Sweep\nIn this section, we report the results of sweeping over different perplexity-based pruning setting configurations.\nIn particular, for each dataset, we first sweep over the selection criteria to determine where from the distribution of perplexities samples should be selected.\nThen, using the best selection criteria, we sweep the selection rate to determine how much we should prune.\n\nSetup.\nWe use the same training and evaluation setup as detailed in\u00a0Section\u00a03.1.\nWe only perform the sweep over pruning settings for 1 billion parameter final models for computational budget reasons; however, we find that the best selection criteria at the 1 billion parameter scale also confers a performance improvement at the 3 billion parameter scale, as detailed in\u00a03.2.\n\n\n7.1 Finding the Best Selection Criteria\n\nFor each dataset, we first sweep the selection criteria while keeping the selection rate fixed at 50%.\nWe report the performance of each selection criteria in\u00a0Table\u00a04.\nWe find that on the Pile high perplexity selection works the best and on Dolma medium perplexity selection works the best, improving the average downstream performance by 1.89 and 1.51 respectively.\nAn important observation from the sweep is that the best selection criteria from one dataset does not transfer to another dataset and may actually degrade performance compared to the baseline.\nAlthough medium-perplexity selection is the best method on Dolma, selecting medium-perplexity samples on the Pile leads to a decrease in the average downstream performance of 0.23 as compared to not performing pruning.\nThese results inform us that high and medium perplexity selection are the optimal selection criteria for the Pile and Dolma respectively, and that the optimal selection criteria does not necessarily transfer between datasets with different domain compositions.\n\n\n7.2 Finding the Best Selection Rate\n\nUsing the optimal selection criteria that we found for each dataset, we next investigate the best selection rate for each dataset.\nWe investigate three different selection rates: 25%, 50%, and 75%.\nWe present the results for each selection rate in\u00a0Table\u00a05.\nOn the Pile, we find that there is no significant difference in downstream performance for selection rates of 25% and 50%; on Dolma we find that a selection rate of 50% achieves the best average downstream performance.\nFor simplicity, we chose to conduct the rest of the experiments in the paper using a selection rate of 50% on both datasets.\nFurthermore, we find that all the selection rates tested outperform the baseline of no data pruning as measured by average downstream performance.\nThis suggests that the selection criteria has a greater impact on the performance of a pruning configuration than the selection rate.\n\n"
        },
        {
            "id": "S8",
            "type": "text",
            "title": "8Detailed Evaluation Setup",
            "caption": "8Detailed Evaluation Setup",
            "metadata": {},
            "text": "\n8 Detailed Evaluation Setup\nJha et\u00a0al. (2023) also use the MosaicML evaluation gauntlet to perform evaluations in their work.\nAs such, with explicit permission from the authors, we exactly reproduce their text describing the tasks and tasks categories in the evaluation gauntlet. The following is from Section D of their paper:\n\nThe World Knowledge category includes the following datasets:\n\n\u2022\nJeopardy (2,117 questions that are a custom subset of the dataset originally obtained from Wolfe et\u00a0al. (2022))\n\n\u2022\nMMLU (14,042 four-choice multiple choice questions distributed across 57 categories Hendrycks et\u00a0al. (2021)\n\n\u2022\nBIG-bench wikidata (20,321 questions regarding factual information pulled from wikipedia)\u00a0Srivastava et\u00a0al. (2023)\n\n\u2022\nARC easy (2,376 easy multiple choice middle school science questions) Clark et\u00a0al. (2018)\n\n\u2022\nARC challenge (1,172 hard multiple choice science questions) Clark et\u00a0al. (2018)\n\n\u2022\nBIG-bench: misconceptions (219 true or false questions regarding common misconceptions) Srivastava et\u00a0al. (2023)\n\n\nThe Commonsense Reasoning category loosely assesses a model\u2019s ability to do basic reasoning tasks that require commonsense knowledge of objects, their properties, and their behavior. It includes the following datasets:\n\n\u2022\nBIG-bench Strategy QA (2,289 very eclectic yes/no questions on a wide range of commonsense subjects e.g \u201cCan fish get Tonsilitis?\u201d)Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench Strange Stories (174 short stories followed by questions about the characters)Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench Novel Concepts (32 find-the-common-concept problems)Srivastava et\u00a0al. (2023)\n\n\u2022\nCOPA (100 cause/effect multiple choice questions) Roemmele et\u00a0al. (2011)\n\n\u2022\nPIQA (1,838 commonsense physical intuition 2-choice questions) Bisk et\u00a0al. (2020)\n\n\u2022\nOpenBook QA (500 questions that rely on basic physical and scientific intuition about common objects and entities) Mihaylov et\u00a0al. (2018).\n\n\nLanguage Understanding tasks evaluate the model\u2019s ability to understand the structure and properties of languages, and include the following datasets:\n\n\u2022\nLAMBADA (6,153 passages take from books - we use the formatting adopted by OpenAI\u2019s version)Paperno et\u00a0al. (2016)\n\n\u2022\nHellaSwag (10,042 multiple choice scenarios in which the model is prompted with a scenario and choose the most likely conclusion to the scenario from four possible options)Zellers et\u00a0al. (2019)\n\n\u2022\nWinograd Schema Challenge (273 scenarios in which the model must use semantics to correctly resolve the anaphora in a sentence. The Eval Gauntlet uses the partial evaluation technique technique introduced in Trinh & Le (2019)) Levesque et\u00a0al. (2012)\n\n\u2022\nWinogrande (1,267 scenarios in which two possible beginnings of a sentence are presented along with a single ending) Sakaguchi et\u00a0al. (2020)\n\n\u2022\nBIG-bench language identification (10,000 questions on multiple choice language identification) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench conceptual combinations (103 questions using made up words) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench conlang translation (164 example problems in which the model is given translations of simple sentences between English and some fake constructed language) Srivastava et\u00a0al. (2023)\n\n\nSymbolic problem solving tasks test the model\u2019s ability to solve a diverse range of symbolic tasks including arithmetic, logical reasoning, algorithms, and algebra. These datasets include:\n\n\u2022\nBIG-bench elementary math QA (38,160 four-choice multiple choice arithmetic word problems) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench dyck languages (1000 complete-the-sequence questions) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench algorithms (1,320 questions) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench logical deduction (1500 four-choice multiple choice questions relating to relative ordering of objects) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench operators (210 questions involving mathematical operators) Srivastava et\u00a0al. (2023)\n\n\u2022\nBIG-bench repeat copy logic (32 samples in which the model is required to follow some instructions for copying words/symbols)\n\n\u2022\nSimple arithmetic with spaces (1000 arithmetic problems consisting of up to 3 operations and using numbers of up to 3 digits, developed by MosaicML)\n\n\u2022\nSimple arithmetic without spaces (1000 arithmetic problems consisting of up to 3 operations and using numbers of up to 3 digits, developed by MosaicML)\n\n\u2022\nMath QA (2,983 four-choice multiple choice math word problems) Amini et\u00a0al. (2019)\n\n\u2022\nLogiQA (651 four-logical word problems) Liu et\u00a0al. (2020)\n\n\nThe Reading comprehension benchmarks test a model\u2019s ability to answer questions based on the information in a passage of text. The datasets include:\n\n\n\u2022\nBIG-bench Understanding fables (189 short stories) Srivastava et\u00a0al. (2023)\n\n\u2022\nPubmed QA Labeled (1000 hand-labeled medical documents followed by a related question for which the model must respond yes/no/maybe) Jin et\u00a0al. (2019)\n\n\u2022\nSQuAD (10,570 short documents followed by a related question. The model is expected to output the exact correct answer) Rajpurkar et\u00a0al. (2016)\n\n\u2022\nBoolQ (3,270 short passages on a diverse range of subjects followed by a yes/no questions) Clark et\u00a0al. (2019)\n\n\n\n8.1 Evaluation Procedure\nTo compute model performance on the above datasets, the Eval Gauntlet uses one of the following three ICL metrics for each dataset (from MosaicML\u2019s composer library).\n\n\n1.\nInContextLearningQAAccuracy: This metric uses the query, the corresponding correct answer and a list of alternative answers to measure a model\u2019s prediction. If the model\u2019s response conditioned on the query starts with either the correct answer or with one of the alternative answers, it is considered correct. This is used for question-answering tasks such as TriviaQA.\n\n2.\nInContextLearningLMAccuracy: This metric tests a model\u2019s ability to output a precise set of tokens. A model\u2019s output conditioned on a given query is judged to be correct only if the model\u2019s highest probability tokens match the correct sequence of tokens. This is used for language modeling tasks such as LAMBADA.\n\n3.\nInContextLearningMultipleChoiceAccuracy: This metric is used for testing a model\u2019s ability to answer multiple choice questions accurately. It compares the respective perplexity of the query prepended to each of the possible choices, according to the model. If the query-choice pair with the lowest per token perplexity is indeed the correct choice, then the model\u2019s output is judged to be correct. This is used for multiple choice tasks such as HellaSwag, Winograd etc.\n\n\n"
        }
    ],
    "figure_chunks": [
        {
            "id": "S3.F1",
            "type": "figure",
            "title": "2405.20541v1_Figure1",
            "caption": "Figure 1:Average normalized task accuracy evaluated intermittently throughout pretraining for each dataset and model size investigated. Perplexity-based data pruning leads to an improvement in performance for all intermediate training steps evaluated.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.20541v1_Figure1.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F2",
            "type": "figure",
            "title": "2405.20541v1_Figure2",
            "caption": "Figure 2:Downstream task performance as a function of available dataset size.\nThe number of repeats denotes the number of repeats over the raw dataset necessary to achieve the Chinchilla optimal number of tokens.\nTraining on perplexity pruned data leads to an improvement for up to two repeats on both the Pile Dolma.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.20541v1_Figure2.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F3",
            "type": "figure",
            "title": "2405.20541v1_Figure3",
            "caption": "Figure 3:Distribution of sample perplexities as evaluated by the reference model for the Pile and Dolma. We show both the original distribution over the full dataset without pruning as well as the distribution after applying the optimal perplexity-based data pruning technique for a given dataset.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.20541v1_Figure3.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F4",
            "type": "figure",
            "title": "2405.20541v1_Figure4",
            "caption": "Figure 4:Proportion of the total dataset each domain makes up before and after pruning.\nFor all datasets, pruning tends to select more samples from general web domains while leaving out samples from highly specific domains.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.20541v1_Figure4.png",
            "alt_text": "Refer to caption"
        }
    ],
    "table_chunks": [
        {
            "id": "S3.T1",
            "type": "table",
            "title": "2405.20541v1_Table1",
            "caption": "Table 1:Average normalized accuracy grouped by task category for both datasets and both final model sizes.\nFor all datasets and model sizes we find that training on perplexity pruned data outperforms the baseline.\nBold results are within one standard error of the highest score.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.1\">Pruning Method</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.2.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.2.1.1.1\" style=\"font-size:80%;\">World Knowledge</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.3.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.3.1.1.1\" style=\"font-size:80%;\">Common Sense Reasoning</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.4.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.4.1.1.1\" style=\"font-size:80%;\">Language Understanding</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.5.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.5.1.1.1\" style=\"font-size:80%;\">Symbolic Problem Solving</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.6.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.6.1.1.1\" style=\"font-size:80%;\">Reading Comprehension</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.1.1.7.1\">\n<span class=\"ltx_p\" id=\"S3.T1.1.1.1.7.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.7.1.1.1\" style=\"font-size:80%;\">Average</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.2.1\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.1.2.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.2.1.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on Pile</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.2.1.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.3.2\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.3.2.1\"><span class=\"ltx_text\" id=\"S3.T1.1.3.2.1.1\" style=\"background-color:#FAFAFA;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.2.1.1\">15.51</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.3.1.1\">10.31</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.4.1.1\">28.11</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.3.2.5.1.1.1\">3.53</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.3.2.6.1.1.1\">11.16</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.3.2.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.3.2.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.3.2.7.1.1\">13.73</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.4.3\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.4.3.1\"><span class=\"ltx_text\" id=\"S3.T1.1.4.3.1.1\" style=\"background-color:#FAFAFA;\">High Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.2.1.1.1\">18.18</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.3.1.1.1\">12.75</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.4.1.1.1\">33.2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.5.1.1.1\">3.36</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.6.1.1.1\">10.63</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.4.3.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.4.3.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.4.3.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.7.1.1.1\">15.62</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.5.4\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.5.4.1\"><span class=\"ltx_text\" id=\"S3.T1.1.5.4.1.1\" style=\"background-color:#F2F2F2;\">3B Parameters Trained on Pile</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.5.4.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.6.5\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.6.5.1\"><span class=\"ltx_text\" id=\"S3.T1.1.6.5.1.1\" style=\"background-color:#F2F2F2;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.2.1.1\">21.82</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.3.1.1\">13.09</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.4.1.1\">39.08</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.6.5.5.1.1.1\">4.88</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.6.1.1\">14.28</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.6.5.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.6.5.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.6.5.7.1.1\">18.63</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.7.6\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.7.6.1\"><span class=\"ltx_text\" id=\"S3.T1.1.7.6.1.1\" style=\"background-color:#F2F2F2;\">High Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.7.6.2.1.1.1\">25.8</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.7.6.3.1.1.1\">16.24</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.7.6.4.1.1.1\">43.32</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.5.1.1\">2.91</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.7.6.6.1.1.1\">15.07</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.7.6.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.7.6.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.7.6.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.7.6.7.1.1.1\">20.67</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.8.7\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.1.8.7.1\"><span class=\"ltx_text\" id=\"S3.T1.1.8.7.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on Dolma</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S3.T1.1.8.7.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.9.8\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.9.8.1\"><span class=\"ltx_text\" id=\"S3.T1.1.9.8.1.1\" style=\"background-color:#FAFAFA;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.2.1.1\">16.48</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.3.1.1\">12.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.4.1.1\">28.86</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.9.8.5.1.1.1\">3.58</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.6.1.1\">7.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.9.8.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.9.8.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.9.8.7.1.1\">13.84</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.10.9\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.10.9.1\"><span class=\"ltx_text\" id=\"S3.T1.1.10.9.1.1\" style=\"background-color:#FAFAFA;\">Medium Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.2.1.1.1\">17.98</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.3.1.1.1\">13.03</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.4.1.1.1\">31.87</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.5.1.1.1\">3.44</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.6.1.1.1\">10.41</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.10.9.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.10.9.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.10.9.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.10.9.7.1.1.1\">15.35</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.11.10\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.11.10.1\"><span class=\"ltx_text\" id=\"S3.T1.1.11.10.1.1\" style=\"background-color:#F2F2F2;\">3B Parameters Trained on Dolma</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.11.10.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.12.11\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.12.11.1\"><span class=\"ltx_text\" id=\"S3.T1.1.12.11.1.1\" style=\"background-color:#F2F2F2;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.2.1.1\">23.56</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.3.1.1\">14.29</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.4.1.1\">39.57</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.12.11.5.1.1.1\">4.4</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.12.11.6.1.1.1\">14.2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S3.T1.1.12.11.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.12.11.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.12.11.7.1.1\">19.2</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.13.12\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T1.1.13.12.1\"><span class=\"ltx_text\" id=\"S3.T1.1.13.12.1.1\" style=\"background-color:#F2F2F2;\">Medium Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.13.12.2.1.1.1\">24.19</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.13.12.3.1.1.1\">16.48</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.13.12.4.1.1.1\">41.8</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.5.1.1\">3.3</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.6.1.1\">13.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S3.T1.1.13.12.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.1.13.12.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S3.T1.1.13.12.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.13.12.7.1.1.1\">19.79</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S3.T2",
            "type": "table",
            "title": "2405.20541v1_Table2",
            "caption": "Table 2:Downstream task performance for Chinchilla Optimal and5\u00d75\\times5 \u00d7over-trained data budgets.\nThe \u201cImprovement Over Baseline\u201d column refers to the gain observed from perplexity pruning as compared to the baseline trained in the same setting.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.12.10\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.12.10.11.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.12.10.11.1.1\">Pruning Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.12.10.11.1.2\">Average</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.12.10.11.1.3\">Improvement Over Baseline</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.12.10.12.1\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.12.10.12.1.1\"><span class=\"ltx_text\" id=\"S3.T2.12.10.12.1.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on High Perplexity Pile</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T2.12.10.12.1.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T2.12.10.12.1.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.2.2\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.4.2.2.3\"><span class=\"ltx_text\" id=\"S3.T2.4.2.2.3.1\" style=\"background-color:#FAFAFA;\">Chinchilla Optimal</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.1.1.1\"><math alttext=\"15.62\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.3.1.1.1.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T2.3.1.1.1.m1.1a\"><mn id=\"S3.T2.3.1.1.1.m1.1.1\" mathbackground=\"#FAFAFA\" xref=\"S3.T2.3.1.1.1.m1.1.1.cmml\">15.62</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.3.1.1.1.m1.1b\"><cn id=\"S3.T2.3.1.1.1.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.3.1.1.1.m1.1.1\">15.62</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.3.1.1.1.m1.1c\">15.62</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.3.1.1.1.m1.1d\">15.62</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.2.2.2\"><math alttext=\"1.89\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.4.2.2.2.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T2.4.2.2.2.m1.1a\"><mn id=\"S3.T2.4.2.2.2.m1.1.1\" mathbackground=\"#FAFAFA\" xref=\"S3.T2.4.2.2.2.m1.1.1.cmml\">1.89</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.4.2.2.2.m1.1b\"><cn id=\"S3.T2.4.2.2.2.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.4.2.2.2.m1.1.1\">1.89</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.4.2.2.2.m1.1c\">1.89</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.4.2.2.2.m1.1d\">1.89</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.7.5.5\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.5.3.3.1\">\n<math alttext=\"5\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.T2.5.3.3.1.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T2.5.3.3.1.m1.1a\"><mrow id=\"S3.T2.5.3.3.1.m1.1b\"><mn id=\"S3.T2.5.3.3.1.m1.1.1\" mathbackground=\"#FAFAFA\">5</mn><mo id=\"S3.T2.5.3.3.1.m1.1.2\" lspace=\"0.222em\" mathbackground=\"#FAFAFA\">\u00d7</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S3.T2.5.3.3.1.m1.1c\">5\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.5.3.3.1.m1.1d\">5 \u00d7</annotation></semantics></math><span class=\"ltx_text\" id=\"S3.T2.5.3.3.1.1\" style=\"background-color:#FAFAFA;\"> Over-Trained</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.4.4.2\"><math alttext=\"18.83\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.6.4.4.2.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T2.6.4.4.2.m1.1a\"><mn id=\"S3.T2.6.4.4.2.m1.1.1\" mathbackground=\"#FAFAFA\" xref=\"S3.T2.6.4.4.2.m1.1.1.cmml\">18.83</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.6.4.4.2.m1.1b\"><cn id=\"S3.T2.6.4.4.2.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.6.4.4.2.m1.1.1\">18.83</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.6.4.4.2.m1.1c\">18.83</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.6.4.4.2.m1.1d\">18.83</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.7.5.5.3\"><math alttext=\"1.74\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.7.5.5.3.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T2.7.5.5.3.m1.1a\"><mn id=\"S3.T2.7.5.5.3.m1.1.1\" mathbackground=\"#FAFAFA\" xref=\"S3.T2.7.5.5.3.m1.1.1.cmml\">1.74</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.7.5.5.3.m1.1b\"><cn id=\"S3.T2.7.5.5.3.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.7.5.5.3.m1.1.1\">1.74</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.7.5.5.3.m1.1c\">1.74</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.7.5.5.3.m1.1d\">1.74</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.12.10.13.2\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.12.10.13.2.1\"><span class=\"ltx_text\" id=\"S3.T2.12.10.13.2.1.1\" style=\"background-color:#F2F2F2;\">1B Parameters Trained on Medium Perplexity Dolma</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T2.12.10.13.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T2.12.10.13.2.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.9.7.7\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.9.7.7.3\"><span class=\"ltx_text\" id=\"S3.T2.9.7.7.3.1\" style=\"background-color:#F2F2F2;\">Chinchilla Optimal</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.6.6.1\"><math alttext=\"15.35\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.8.6.6.1.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T2.8.6.6.1.m1.1a\"><mn id=\"S3.T2.8.6.6.1.m1.1.1\" mathbackground=\"#F2F2F2\" xref=\"S3.T2.8.6.6.1.m1.1.1.cmml\">15.35</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.8.6.6.1.m1.1b\"><cn id=\"S3.T2.8.6.6.1.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.8.6.6.1.m1.1.1\">15.35</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.8.6.6.1.m1.1c\">15.35</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.8.6.6.1.m1.1d\">15.35</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.9.7.7.2\"><math alttext=\"1.51\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.9.7.7.2.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T2.9.7.7.2.m1.1a\"><mn id=\"S3.T2.9.7.7.2.m1.1.1\" mathbackground=\"#F2F2F2\" xref=\"S3.T2.9.7.7.2.m1.1.1.cmml\">1.51</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.9.7.7.2.m1.1b\"><cn id=\"S3.T2.9.7.7.2.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.9.7.7.2.m1.1.1\">1.51</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.9.7.7.2.m1.1c\">1.51</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.9.7.7.2.m1.1d\">1.51</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.12.10.10\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T2.10.8.8.1\">\n<math alttext=\"5\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.T2.10.8.8.1.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T2.10.8.8.1.m1.1a\"><mrow id=\"S3.T2.10.8.8.1.m1.1b\"><mn id=\"S3.T2.10.8.8.1.m1.1.1\" mathbackground=\"#F2F2F2\">5</mn><mo id=\"S3.T2.10.8.8.1.m1.1.2\" lspace=\"0.222em\" mathbackground=\"#F2F2F2\">\u00d7</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S3.T2.10.8.8.1.m1.1c\">5\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.10.8.8.1.m1.1d\">5 \u00d7</annotation></semantics></math><span class=\"ltx_text\" id=\"S3.T2.10.8.8.1.1\" style=\"background-color:#F2F2F2;\"> Over-Trained</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.11.9.9.2\"><math alttext=\"18.67\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.11.9.9.2.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T2.11.9.9.2.m1.1a\"><mn id=\"S3.T2.11.9.9.2.m1.1.1\" mathbackground=\"#F2F2F2\" xref=\"S3.T2.11.9.9.2.m1.1.1.cmml\">18.67</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.11.9.9.2.m1.1b\"><cn id=\"S3.T2.11.9.9.2.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.11.9.9.2.m1.1.1\">18.67</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.11.9.9.2.m1.1c\">18.67</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.11.9.9.2.m1.1d\">18.67</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.12.10.10.3\"><math alttext=\"0.84\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.12.10.10.3.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T2.12.10.10.3.m1.1a\"><mn id=\"S3.T2.12.10.10.3.m1.1.1\" mathbackground=\"#F2F2F2\" xref=\"S3.T2.12.10.10.3.m1.1.1.cmml\">0.84</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.12.10.10.3.m1.1b\"><cn id=\"S3.T2.12.10.10.3.m1.1.1.cmml\" type=\"float\" xref=\"S3.T2.12.10.10.3.m1.1.1\">0.84</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.12.10.10.3.m1.1c\">0.84</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T2.12.10.10.3.m1.1d\">0.84</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S3.T3",
            "type": "table",
            "title": "2405.20541v1_Table3",
            "caption": "Table 3:Performance as evaluated by perplexity on a test split of the original dataset as well as average normalized task accuracy for 1 billion parameter final models trained on the Pile.\nThe model trained on pruned data has worse pretraining test split perplexity even though it significantly improves average downstream normalized accuracy.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.6.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T3.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T3.2.2.2.3\">Pruning Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1\">Test Set Pplx. (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.1.1.1.1.m1.1\"><semantics id=\"S3.T3.1.1.1.1.m1.1a\"><mo id=\"S3.T3.1.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S3.T3.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.1.1.1.1.m1.1b\"><ci id=\"S3.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.1.1.1.1.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.1.1.1.1.m1.1d\">\u2193</annotation></semantics></math>)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.2.2.2.2\">Downstream Task Avg. (<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.2.2.2.2.m1.1\"><semantics id=\"S3.T3.2.2.2.2.m1.1a\"><mo id=\"S3.T3.2.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S3.T3.2.2.2.2.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.2.2.2.2.m1.1b\"><ci id=\"S3.T3.2.2.2.2.m1.1.1.cmml\" xref=\"S3.T3.2.2.2.2.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.2.2.2.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.2.2.2.2.m1.1d\">\u2191</annotation></semantics></math>)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.6.6.7.1\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T3.6.6.7.1.1\"><span class=\"ltx_text\" id=\"S3.T3.6.6.7.1.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on Pile</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T3.6.6.7.1.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T3.6.6.7.1.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.3.3.3\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.3.3.3.2\"><span class=\"ltx_text\" id=\"S3.T3.3.3.3.2.1\" style=\"background-color:#FAFAFA;\">No Pruning (Baseline)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.3.3.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.3.3.3.3.1\" style=\"background-color:#FAFAFA;\">7.83</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.3.3.3.1\"><math alttext=\"13.73\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.3.3.3.1.m1.1\" style=\"background-color:#FAFAFA;\"><semantics id=\"S3.T3.3.3.3.1.m1.1a\"><mn id=\"S3.T3.3.3.3.1.m1.1.1\" mathbackground=\"#FAFAFA\" xref=\"S3.T3.3.3.3.1.m1.1.1.cmml\">13.73</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.3.3.3.1.m1.1b\"><cn id=\"S3.T3.3.3.3.1.m1.1.1.cmml\" type=\"float\" xref=\"S3.T3.3.3.3.1.m1.1.1\">13.73</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.3.3.3.1.m1.1c\">13.73</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.3.3.3.1.m1.1d\">13.73</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.4.4\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.4.4.2\"><span class=\"ltx_text\" id=\"S3.T3.4.4.4.2.1\" style=\"background-color:#FAFAFA;\">High Perplexity Selected</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.4.4.3\"><span class=\"ltx_text\" id=\"S3.T3.4.4.4.3.1\" style=\"background-color:#FAFAFA;\">8.51</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.4.4.1\"><span class=\"ltx_text ltx_markedasmath ltx_font_bold\" id=\"S3.T3.4.4.4.1.1\" style=\"background-color:#FAFAFA;\">15.62</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.6.6.8.2\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T3.6.6.8.2.1\"><span class=\"ltx_text\" id=\"S3.T3.6.6.8.2.1.1\" style=\"background-color:#F2F2F2;\">1B Parameters Trained on Dolma</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T3.6.6.8.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T3.6.6.8.2.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.5.5.5\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.5.5.5.2\"><span class=\"ltx_text\" id=\"S3.T3.5.5.5.2.1\" style=\"background-color:#F2F2F2;\">No Pruning (Baseline)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.5.5.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.5.5.5.3.1\" style=\"background-color:#F2F2F2;\">13.53</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.5.5.5.1\"><math alttext=\"13.84\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.5.5.5.1.m1.1\" style=\"background-color:#F2F2F2;\"><semantics id=\"S3.T3.5.5.5.1.m1.1a\"><mn id=\"S3.T3.5.5.5.1.m1.1.1\" mathbackground=\"#F2F2F2\" xref=\"S3.T3.5.5.5.1.m1.1.1.cmml\">13.84</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.5.5.5.1.m1.1b\"><cn id=\"S3.T3.5.5.5.1.m1.1.1.cmml\" type=\"float\" xref=\"S3.T3.5.5.5.1.m1.1.1\">13.84</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.5.5.5.1.m1.1c\">13.84</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.5.5.5.1.m1.1d\">13.84</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.6.6.6\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T3.6.6.6.2\"><span class=\"ltx_text\" id=\"S3.T3.6.6.6.2.1\" style=\"background-color:#F2F2F2;\">Medium Perplexity Selected</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.6.6.6.3\"><span class=\"ltx_text\" id=\"S3.T3.6.6.6.3.1\" style=\"background-color:#F2F2F2;\">14.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.6.6.6.1\"><span class=\"ltx_text ltx_markedasmath ltx_font_bold\" id=\"S3.T3.6.6.6.1.1\" style=\"background-color:#F2F2F2;\">15.35</span></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S7.T4",
            "type": "table",
            "title": "2405.20541v1_Table4",
            "caption": "Table 4:Results from sweeping different selection criteria.\nWe report the average normalized accuracy for each task grouping as well as across all tasks.\nWhile high perplexity selection is optimal for the Pile, medium perplexity selection is optimal for Dolma.\nBold results are within one standard error of the highest normalized accuracy.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.1\">Pruning Method</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.2.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.2.1.1.1\" style=\"font-size:80%;\">World Knowledge</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.3.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.3.1.1.1\" style=\"font-size:80%;\">Common Sense Reasoning</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.4.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.4.1.1.1\" style=\"font-size:80%;\">Language Understanding</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.5.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.5.1.1.1\" style=\"font-size:80%;\">Symbolic Problem Solving</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.6.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.6.1.1.1\" style=\"font-size:80%;\">Reading Comprehension</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T4.1.1.1.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.1.1.7.1\">\n<span class=\"ltx_p\" id=\"S7.T4.1.1.1.7.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.1.1.7.1.1.1\" style=\"font-size:80%;\">Average</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T4.1.2.1\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T4.1.2.1.1\"><span class=\"ltx_text\" id=\"S7.T4.1.2.1.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on Pile</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.2.1.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.3.2\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.3.2.1\"><span class=\"ltx_text\" id=\"S7.T4.1.3.2.1.1\" style=\"background-color:#FAFAFA;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.2.1.1\">15.51</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.3.1.1\">10.31</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.4.1.1\">28.11</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.3.2.5.1.1.1\">3.53</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.3.2.6.1.1.1\">11.16</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.3.2.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.3.2.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.3.2.7.1.1\">13.73</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.4.3\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.4.3.1\"><span class=\"ltx_text\" id=\"S7.T4.1.4.3.1.1\" style=\"background-color:#FAFAFA;\">Low Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.2.1.1\">11.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.3.1.1\">5.76</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.4.1.1\">18.66</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.4.3.5.1.1.1\">3.54</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.6.1.1\">8.72</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.4.3.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.4.3.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.4.3.7.1.1\">9.56</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.5.4\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.5.4.1\"><span class=\"ltx_text\" id=\"S7.T4.1.5.4.1.1\" style=\"background-color:#FAFAFA;\">Medium Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.2.1.1\">16.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.3.1.1\">9.01</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.4.1.1\">28.1</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.5.4.5.1.1.1\">3.41</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.5.4.6.1.1.1\">10.86</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.5.4.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.5.4.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.5.4.7.1.1\">13.5</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.6.5\" style=\"background-color:#FAFAFA;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.6.5.1\"><span class=\"ltx_text\" id=\"S7.T4.1.6.5.1.1\" style=\"background-color:#FAFAFA;\">High Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.2.1.1.1\">18.18</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.3.1.1.1\">12.75</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.4.1.1.1\">33.2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.5.1.1.1\">3.36</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.6.1.1.1\">10.63</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.6.5.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.6.5.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.6.5.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.6.5.7.1.1.1\">15.62</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.7.6\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T4.1.7.6.1\"><span class=\"ltx_text\" id=\"S7.T4.1.7.6.1.1\" style=\"background-color:#F2F2F2;\">1B Parameters Trained on Dolma</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T4.1.7.6.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.8.7\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.8.7.1\"><span class=\"ltx_text\" id=\"S7.T4.1.8.7.1.1\" style=\"background-color:#F2F2F2;\">No Pruning (Baseline)</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.2.1.1\">16.48</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.3.1.1\">12.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.4.1.1\">28.86</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.8.7.5.1.1.1\">3.58</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.6.1.1\">7.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.8.7.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.8.7.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.8.7.7.1.1\">13.84</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.9.8\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.9.8.1\"><span class=\"ltx_text\" id=\"S7.T4.1.9.8.1.1\" style=\"background-color:#F2F2F2;\">Low Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.2.1.1\">16.13</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.3.1.1\">10.1</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.4.1.1\">27.28</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.9.8.5.1.1.1\">3.45</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.6.1.1\">7.85</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.9.8.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.9.8.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.9.8.7.1.1\">12.96</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.10.9\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T4.1.10.9.1\"><span class=\"ltx_text\" id=\"S7.T4.1.10.9.1.1\" style=\"background-color:#F2F2F2;\">Medium Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.2.1.1.1\">17.98</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.3.1.1.1\">13.03</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.4.1.1.1\">31.87</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.5.1.1.1\">3.44</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.6.1.1.1\">10.41</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T4.1.10.9.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.10.9.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.10.9.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.10.9.7.1.1.1\">15.35</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.11.10\" style=\"background-color:#F2F2F2;\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S7.T4.1.11.10.1\"><span class=\"ltx_text\" id=\"S7.T4.1.11.10.1.1\" style=\"background-color:#F2F2F2;\">High Perplexity Selected</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.2.1.1\">16.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.11.10.3.1.1.1\">13.12</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.11.10.4.1.1.1\">31.14</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.5.1.1\">3.15</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.6.1.1\">8.55</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T4.1.11.10.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T4.1.11.10.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T4.1.11.10.7.1.1\">14.52</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S7.T5",
            "type": "table",
            "title": "2405.20541v1_Table5",
            "caption": "Table 5:Results from sweeping different selection rates.\nWe report the average normalized accuracy for each task grouping as well as across all tasks.\nBold results are within one standard error of the highest normalized accuracy.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S7.T5.1.1.1.1\">Pruning Method</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.2.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.2.1.1.1\" style=\"font-size:80%;\">World Knowledge</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.3.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.3.1.1.1\" style=\"font-size:80%;\">Common Sense Reasoning</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.4.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.4.1.1.1\" style=\"font-size:80%;\">Language Understanding</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.5.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.5.1.1.1\" style=\"font-size:80%;\">Symbolic Problem Solving</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.6.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.6.1.1.1\" style=\"font-size:80%;\">Reading Comprehension</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T5.1.1.1.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.1.1.7.1\">\n<span class=\"ltx_p\" id=\"S7.T5.1.1.1.7.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.1.1.7.1.1.1\" style=\"font-size:80%;\">Average</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T5.1.2.1\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T5.1.2.1.1\"><span class=\"ltx_text\" id=\"S7.T5.1.2.1.1.1\" style=\"background-color:#FAFAFA;\">1B Parameters Trained on Pile</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.2.1.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.3.2\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T5.1.3.2.1\"><span class=\"ltx_text\" id=\"S7.T5.1.3.2.1.1\" style=\"background-color:#FAFAFA;\">25% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.2.1.1.1\">18.21</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.3.1.1.1\">12.88</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.4.1.1.1\">34.44</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.5.1.1.1\">3.73</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.6.1.1.1\">9.44</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.3.2.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.3.2.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.3.2.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.3.2.7.1.1.1\">15.74</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.4.3\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T5.1.4.3.1\"><span class=\"ltx_text\" id=\"S7.T5.1.4.3.1.1\" style=\"background-color:#FAFAFA;\">50% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.4.3.2.1.1.1\">18.18</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.4.3.3.1.1.1\">12.75</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.4.1.1\">33.2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.5.1.1\">3.36</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.4.3.6.1.1.1\">10.63</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.4.3.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.4.3.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.4.3.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.4.3.7.1.1.1\">15.62</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.5.4\" style=\"background-color:#FAFAFA;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T5.1.5.4.1\"><span class=\"ltx_text\" id=\"S7.T5.1.5.4.1.1\" style=\"background-color:#FAFAFA;\">75% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.2.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.2.1.1\">17.08</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.3.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.3.1.1\">10.11</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.4.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.4.1.1\">31.37</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.5.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.5.4.5.1.1.1\">3.81</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.6.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.6.1.1\">9.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.5.4.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.5.4.7.1\" style=\"background-color:#FAFAFA;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.5.4.7.1.1\">14.28</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.6.5\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T5.1.6.5.1\"><span class=\"ltx_text\" id=\"S7.T5.1.6.5.1.1\" style=\"background-color:#F2F2F2;\">1B Parameters Trained on Dolma</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.2\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.3\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.4\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.5\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.6\" style=\"width:28.5pt;\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"S7.T5.1.6.5.7\" style=\"width:28.5pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.7.6\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T5.1.7.6.1\"><span class=\"ltx_text\" id=\"S7.T5.1.7.6.1.1\" style=\"background-color:#F2F2F2;\">25% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.2.1.1\">17.94</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.7.6.3.1.1.1\">12.16</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.7.6.4.1.1.1\">31.63</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.7.6.5.1.1.1\">3.58</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.6.1.1\">8.91</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.7.6.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.7.6.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.7.6.7.1.1\">14.85</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.8.7\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T5.1.8.7.1\"><span class=\"ltx_text\" id=\"S7.T5.1.8.7.1.1\" style=\"background-color:#F2F2F2;\">50% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.8.7.2.1.1.1\">17.98</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.8.7.3.1.1.1\">13.03</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.8.7.4.1.1.1\">31.87</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.8.7.5.1.1.1\">3.44</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.6.1.1\">10.41</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"S7.T5.1.8.7.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.8.7.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.8.7.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.8.7.7.1.1.1\">15.35</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.9.8\" style=\"background-color:#F2F2F2;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T5.1.9.8.1\"><span class=\"ltx_text\" id=\"S7.T5.1.9.8.1.1\" style=\"background-color:#F2F2F2;\">75% Selection Rate</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.2\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.2.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.9.8.2.1.1.1\">18.2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.3\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.3.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.3.1.1\">11.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.4\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.4.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.4.1.1\">29.96</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.5\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.5.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.5.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.9.8.5.1.1.1\">3.32</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.6\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.6.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.9.8.6.1.1.1\">10.82</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb\" id=\"S7.T5.1.9.8.7\" style=\"width:28.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S7.T5.1.9.8.7.1\" style=\"background-color:#F2F2F2;\">\n<span class=\"ltx_p\" id=\"S7.T5.1.9.8.7.1.1\">14.82</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>"
        }
    ],
    "metadata": {},
    "pdf_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\pdfs\\2405.20541v1.pdf",
    "HTML_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\htmls\\2405.20541v1.html"
}