{
    "doc_id": "2405.19785v3",
    "title": "Recurrent Deep Kernel Learning of Dynamical Systems",
    "authors": [
        "Nicol\u00f2 Botteghi",
        "Paolo Motta",
        "Andrea Manzoni",
        "Paolo Zunino",
        "Mengwu Guo"
    ],
    "categories": [
        "cs.LG",
        "stat.ML"
    ],
    "published_date": "2024-05-30 07:49:02+00:00",
    "abstract": "Digital twins require computationally-efficient reduced-order models (ROMs)\nthat can accurately describe complex dynamics of physical assets. However,\nconstructing ROMs from noisy high-dimensional data is challenging. In this\nwork, we propose a data-driven, non-intrusive method that utilizes stochastic\nvariational deep kernel learning (SVDKL) to discover low-dimensional latent\nspaces from data and a recurrent version of SVDKL for representing and\npredicting the evolution of latent dynamics. The proposed method is\ndemonstrated with two challenging examples -- a double pendulum and a\nreaction-diffusion system. Results show that our framework is capable of (i)\ndenoising and reconstructing measurements, (ii) learning compact\nrepresentations of system states, (iii) predicting system evolution in\nlow-dimensional latent spaces, and (iv) quantifying modeling uncertainties.",
    "text_chunks": [
        {
            "id": "S1",
            "type": "text",
            "title": "1Introduction",
            "caption": "1Introduction",
            "metadata": {},
            "text": "\n1 Introduction\nA digital twin [1, 2, 3, 4] is a virtual replica that mimics the structure, context, and behavior of a physical system. The digital twin is synchronized to its physical twin with data in real time to predict dynamical behaviors and inform critical decisions. Constructing a digital twin typically requires accurate modeling of complex physical phenomena that are often described by nonlinear, time-dependent, parametric partial differential equations (PDEs). Full-order models (FOMs) generated by detailed solvers are often computationally demanding and thus not suitable for the multi-query, real-time contexts in digital twinning, such as uncertainty quantification [5, 6, 7], optimal control [8, 9, 10], shape optimization [11], parameter estimation [12, 13], and model calibration [14, 15]. Therefore, constructing computationally efficient reduced-order models (ROMs) with controlled accuracy is crucial for dealing with real-world systems [16].\n\nGenerally speaking, any surrogate model that reduces the computational cost of a FOM can be considered a ROM. ROMs aim to intelligently represent high-dimensional dynamical systems in carefully-established low-dimensional latent spaces, so that the low-dimensionality improves computational efficiency, and the accuracy remains under control [17, 18, 19, 20, 21, 22, 16]. Despite the wide variety of approaches that can be found in the literature, we can identify two major categories of ROM approaches: intrusive and non-intrusive methods. Intrusive ROM techniques require access to the full-order solvers, which is often inconvenient in industrial implementations, especially for the cases involving legacy code and/or readily executed software. To overcome this limitation, non-intrusive ROM techniques have been developed to learn low-dimensional representations primarily from data, without accessing the code of FOMs. Such flexibility of non-intrusive ROMs has recently motivated the development of a vast amount of data-driven methods, such as dynamic mode decomposition [23, 24], reduced-order operator inference [25, 26, 27, 28], sparse identification of reduced latent dynamics [29, 30, 31, 32, 33, 34], manifold learning using deep auto-encoders [35, 36, 37, 38], data-driven approximation of time-integration schemes [39], Gaussian process modeling for low-dimensional representations [40, 41], and kernel flows [42].\n\nHowever, learning ROMs from noisy data is extremely challenging. While many works in the literature have focused on learning compact representation of high-dimensional data, for example using neural networks (NNs) [43, 44], or quantifying uncertainties using, for example, Gaussian processes (GPs) [45], herein we argue that both challenges must be tackled simultaneously for discovering ROMs properly. NNs excel in learning complex and nonlinear dependencies of the data, while they tend to struggle when quantifying uncertainties. Conversely, GPs struggle with large datasets due to the limited expressivity of the kernels and the need for the inversion of the covariance matrix, while they excel to quantify uncertainties. To overcome these limitations, and to leverage on the positive features of both NNs and GPs synergistically, deep kernel learning (DKL) and stochastic variational DKL (SVDKL) were introduced in recent years [46, 47]. DKL aims to combine the best of the GP and NN worlds by constructing expressive deep kernels that can model complex relations of the data. DKL builds a deep kernel by feeding to a GP the data processed by a NN.\nIn addition, SVDKL relies of variational inference [48] to allow for the use of traditional minibatch training techniques employed by NN-based models, making SVDKL suitable for effectively dealing with large dataset. Variational inference amortizes the cost of sampling from the (non-Gaussian) posterior distribution by approximating the distribution with the best-fitting Gaussian, reducing the computational cost of SVDKL models.\n\nAnother approach to learn expressive deep kernels is kernel flows [42, 49, 50]. Kernel flows are based on the simple idea that good kernels maintain similar accuracy if the data points are reduced. Kernel flows progressively refine the kernel using subsets of the training set. Thus, they offer a solution to scale GPs to large datasets. Similarly to DKL, kernel flows can use sequences of nonlinear transformations to pre-process the data before feeding them to the GP kernel. Kernel flows have been successfully used for modeling low-dimensional dynamical systems [51, 52, 53] even in the case of irregular sampling of the data. Although kernel flows have been applied to low-dimensional dynamical systems, it is worth mentioning that this approach is not inherently limited by the data dimensionality. For example, kernel flows have also been successfully applied to the MNIST dataset [42].\n\nIn this paper, we exploit the SVDKL idea to develop a non-intrusive ROM that can deal with both high-dimensional and noisy data. In particular, with reference to Figure 1, our method includes a SVDKL encoder to compress high-dimensional measurements into low-dimensional distributions of state variables, a recurrent SVDKL latent dynamical model to predict the system\u2019s evolution over time, and a decoder to reconstruct the measurements and interpret the latent representations.\n\nThe model is trained without labeled data in an unsupervised manner by only relying on high-dimensional and noisy measurements of the system. We show the capabilities of our framework in two challenging numerical examples, namely, the dynamics of (i) a double pendulum and of (ii) a distributed reaction-diffusion system, assuming in both cases to deal with measurements over a two-dimensional spatial region at different time instants \u2013 thus mimicking a set of observations acquired by a camera. Our contribution is threefold:\n\n\u2022\nwe improve the prediction accuracy and consistency over long horizons of the SVDKL framework introduced in [41] by modeling the latent dynamics using a recurrent NN,\n\n\u2022\nwe show the capabilities of the framework on challenging chaotic systems, i.e., a double pendulum and a reaction-diffusion problem, and\n\n\u2022\nwe introduce an interpretable way for visualizing and studying uncertainties over latent variables by looking at the standard deviation in the measurement space.\n\n\nThe paper is organized as follows: in Section 2, we introduce the building blocks of our framework, namely GPs, and DKL, and in Section 3, we describe our novel DKL-based method. Section 4 presents the numerical experiments, shows and discusses the results, and Section 5 concludes the paper.\n"
        },
        {
            "id": "S2",
            "type": "text",
            "title": "2Preliminaries",
            "caption": "2Preliminaries",
            "metadata": {},
            "text": "\n2 Preliminaries\nThroughout this section, we assume to deal with a dataset of N\ud835\udc41Nitalic_N input vectors X=[\ud835\udc311,\u2026,\ud835\udc31N]\ud835\udc4bsubscript\ud835\udc311\u2026subscript\ud835\udc31\ud835\udc41X=[\\mathbf{x}_{1},...,\\mathbf{x}_{N}]italic_X = [ bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , bold_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ], in which the input is an element \ud835\udc31\u2208\u211d|\ud835\udc31|\ud835\udc31superscript\u211d\ud835\udc31\\mathbf{x}\\in\\mathbb{R}^{|\\mathbf{x}|}bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT | bold_x | end_POSTSUPERSCRIPT and |\ud835\udc31|\ud835\udc31|\\mathbf{x}|| bold_x | denotes its dimensionality, and correspondingly a vector of targets \ud835\udc32=[y1,\u2026,yN]T\ud835\udc32superscriptsubscript\ud835\udc661\u2026subscript\ud835\udc66\ud835\udc41\ud835\udc47\\mathbf{y}=[y_{1},...,y_{N}]^{T}bold_y = [ italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_y start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, with the output y\u2208\u211d\ud835\udc66\u211dy\\in\\mathbb{R}italic_y \u2208 blackboard_R.\n\n2.1 Gaussian Processes\nA Gaussian process (GP) [45] f\u2062(\ud835\udc31)\u223c\ud835\udca2\u2062\ud835\udcab\u2062(\u03bc,k\ud835\udf38)similar-to\ud835\udc53\ud835\udc31\ud835\udca2\ud835\udcab\ud835\udf07subscript\ud835\udc58\ud835\udf38f(\\mathbf{x})\\sim\\mathcal{GP}(\\mu,k_{\\boldsymbol{\\gamma}})italic_f ( bold_x ) \u223c caligraphic_G caligraphic_P ( italic_\u03bc , italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ) is a collection of random variables, any finite number of which is Gaussian distributed:\n\nf\u2062(\ud835\udc31)\u223c\ud835\udca2\u2062\ud835\udcab\u2062(\u03bc\u2062(\ud835\udc31),k\u2062(\ud835\udc31,\ud835\udc31\u2032;\ud835\udf38)),y=f\u2062(\ud835\udc31)+\u03f5,\u03f5\u223c\ud835\udca9\u2062(0,\u03c3\u03f52).formulae-sequencesimilar-to\ud835\udc53\ud835\udc31\ud835\udca2\ud835\udcab\ud835\udf07\ud835\udc31\ud835\udc58\ud835\udc31superscript\ud835\udc31\u2032\ud835\udf38formulae-sequence\ud835\udc66\ud835\udc53\ud835\udc31italic-\u03f5similar-toitalic-\u03f5\ud835\udca90superscriptsubscript\ud835\udf0eitalic-\u03f52f(\\mathbf{x})\\sim\\mathcal{GP}(\\mu(\\mathbf{x}),k(\\mathbf{x},\\mathbf{x}^{\\prime}%\n;{\\boldsymbol{\\gamma}})),\\ \\ \\ \\ \\ {y}=f(\\mathbf{x})+\\epsilon,\\ \\ \\ \\ \\ %\n\\epsilon\\sim\\mathcal{N(}0,\\sigma_{\\epsilon}^{2})\\,.italic_f ( bold_x ) \u223c caligraphic_G caligraphic_P ( italic_\u03bc ( bold_x ) , italic_k ( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b3 ) ) , italic_y = italic_f ( bold_x ) + italic_\u03f5 , italic_\u03f5 \u223c caligraphic_N ( 0 , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) .\n(1)\n\nA GP is characterized by its mean function \u03bc\u2062(\ud835\udc31)=\ud835\udd3c\u2062[f\u2062(\ud835\udc31)]\ud835\udf07\ud835\udc31\ud835\udd3cdelimited-[]\ud835\udc53\ud835\udc31\\mu(\\mathbf{x})=\\mathbb{E}[f(\\mathbf{x})]italic_\u03bc ( bold_x ) = blackboard_E [ italic_f ( bold_x ) ] and its covariance/kernel function k\u2062(\ud835\udc31,\ud835\udc31\u2032;\ud835\udf38)=k\ud835\udf38\u2062(\ud835\udc31,\ud835\udc31\u2032)=\ud835\udd3c\u2062[(f\u2062(\ud835\udc31)\u2212\u03bc\u2062(\ud835\udc31))\u2062(f\u2062(\ud835\udc31\u2032)\u2212\u03bc\u2062(\ud835\udc31\u2032))]\ud835\udc58\ud835\udc31superscript\ud835\udc31\u2032\ud835\udf38subscript\ud835\udc58\ud835\udf38\ud835\udc31superscript\ud835\udc31\u2032\ud835\udd3cdelimited-[]\ud835\udc53\ud835\udc31\ud835\udf07\ud835\udc31\ud835\udc53superscript\ud835\udc31\u2032\ud835\udf07superscript\ud835\udc31\u2032k(\\mathbf{x},\\mathbf{x}^{\\prime};{\\boldsymbol{\\gamma}})=k_{\\boldsymbol{\\gamma}%\n}(\\mathbf{x},\\mathbf{x}^{\\prime})=\\mathbb{E}[(f(\\mathbf{x})-\\mu(\\mathbf{x}))(f%\n(\\mathbf{x}^{\\prime})-\\mu(\\mathbf{x}^{\\prime}))]italic_k ( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b3 ) = italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = blackboard_E [ ( italic_f ( bold_x ) - italic_\u03bc ( bold_x ) ) ( italic_f ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) - italic_\u03bc ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) ] with hyperparameters \ud835\udf38\ud835\udf38\\boldsymbol{\\gamma}bold_italic_\u03b3, \ud835\udc31\ud835\udc31\\mathbf{x}bold_x and \ud835\udc31\u2032superscript\ud835\udc31\u2032\\mathbf{x}^{\\prime}bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT being two input locations, and \u03f5italic-\u03f5\\epsilonitalic_\u03f5 is an additive noise term with variance \u03c3\u03f52superscriptsubscript\ud835\udf0eitalic-\u03f52\\sigma_{\\epsilon}^{2}italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. A popular choice of kernel is the squared-exponential (SE) kernel:\n\nk\ud835\udf38\u2062(\ud835\udc31,\ud835\udc31\u2032)=\u03c3f2\u2062exp\u2061(\u221212\u2062\u2016\ud835\udc31\u2212\ud835\udc31\u2032\u20162l2),subscript\ud835\udc58\ud835\udf38\ud835\udc31superscript\ud835\udc31\u2032superscriptsubscript\ud835\udf0e\ud835\udc53212superscriptnorm\ud835\udc31superscript\ud835\udc31\u20322superscript\ud835\udc592k_{{\\boldsymbol{\\gamma}}}(\\mathbf{x},\\mathbf{x}^{\\prime})=\\sigma_{f}^{2}\\exp%\n\\left(-\\frac{1}{2}\\frac{||\\mathbf{x}-\\mathbf{x}^{\\prime}||^{2}}{l^{2}}\\right)\\,,italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = italic_\u03c3 start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_exp ( - divide start_ARG 1 end_ARG start_ARG 2 end_ARG divide start_ARG | | bold_x - bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) ,\n(2)\n\nwith \ud835\udf38=[\u03c3f2,l]\ud835\udf38superscriptsubscript\ud835\udf0e\ud835\udc532\ud835\udc59\\boldsymbol{\\gamma}=[\\sigma_{f}^{2},l]bold_italic_\u03b3 = [ italic_\u03c3 start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_l ], \u03c3f2superscriptsubscript\ud835\udf0e\ud835\udc532\\sigma_{f}^{2}italic_\u03c3 start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT being a noise scale and l\ud835\udc59litalic_l the length scale. The hyperparameters of the GP regression, namely [\ud835\udf38,\u03c3\u03f52]\ud835\udf38superscriptsubscript\ud835\udf0eitalic-\u03f52[\\boldsymbol{\\gamma},\\sigma_{\\epsilon}^{2}][ bold_italic_\u03b3 , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ], can be estimated by maximizing the marginal likelihood as follows:\n\n[\ud835\udf38\u2217,(\u03c3\u03f52)\u2217]=arg\u2061max\ud835\udf38,\u03c3\u03f52\u2061log\u2061p\u2062(\ud835\udc32|X)=arg\u2061max\ud835\udf38,\u03c3\u03f52\u2061{\u221212\u2062\ud835\udc32T\u2062(k\ud835\udf38\u2062(X,X)+\u03c3\u03f52\u2062I)\u22121\u2062\ud835\udc32\u221212\u2062log\u2061|k\ud835\udf38\u2062(X,X)+\u03c3\u03f52\u2062I|\u2212N2\u2062log\u2061(2\u2062\u03c0)},superscript\ud835\udf38superscriptsuperscriptsubscript\ud835\udf0eitalic-\u03f52subscript\ud835\udf38superscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc5dconditional\ud835\udc32\ud835\udc4bsubscript\ud835\udf38superscriptsubscript\ud835\udf0eitalic-\u03f5212superscript\ud835\udc32\ud835\udc47superscriptsubscript\ud835\udc58\ud835\udf38\ud835\udc4b\ud835\udc4bsuperscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc3c1\ud835\udc3212subscript\ud835\udc58\ud835\udf38\ud835\udc4b\ud835\udc4bsuperscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc3c\ud835\udc4122\ud835\udf0b\\begin{split}[\\boldsymbol{\\gamma}^{*},(\\sigma_{\\epsilon}^{2})^{*}]&=\\arg\\max_{%\n\\boldsymbol{\\gamma},\\sigma_{\\epsilon}^{2}}\\leavevmode\\nobreak\\ \\log p(\\mathbf{%\ny}|X)\\\\\n&=\\arg\\max_{\\boldsymbol{\\gamma},\\sigma_{\\epsilon}^{2}}\\left\\{-\\frac{1}{2}%\n\\mathbf{y}^{T}(k_{\\boldsymbol{\\gamma}}(X,X)+\\sigma_{\\epsilon}^{2}I)^{-1}%\n\\mathbf{y}-\\frac{1}{2}\\log|k_{\\boldsymbol{\\gamma}}(X,X)+\\sigma_{\\epsilon}^{2}I%\n|-\\frac{N}{2}\\log(2\\pi)\\right\\}\\,,\\\\\n\\end{split}start_ROW start_CELL [ bold_italic_\u03b3 start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , ( italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ] end_CELL start_CELL = roman_arg roman_max start_POSTSUBSCRIPT bold_italic_\u03b3 , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT roman_log italic_p ( bold_y | italic_X ) end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = roman_arg roman_max start_POSTSUBSCRIPT bold_italic_\u03b3 , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT { - divide start_ARG 1 end_ARG start_ARG 2 end_ARG bold_y start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X ) + italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_I ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_y - divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_log | italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X ) + italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_I | - divide start_ARG italic_N end_ARG start_ARG 2 end_ARG roman_log ( 2 italic_\u03c0 ) } , end_CELL end_ROW\n(3)\n\nGiven the training data of input-output pairs (X,\ud835\udc32)\ud835\udc4b\ud835\udc32(X,\\mathbf{y})( italic_X , bold_y ), the standard rule for conditioning Gaussians gives a predictive (posterior) Gaussian distribution of the noise-free outputs \ud835\udc1f\u2217superscript\ud835\udc1f\\mathbf{f}^{*}bold_f start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT at unseen test inputs X\u2217superscript\ud835\udc4b{X}^{*}italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT:\n\n\ud835\udc1f\u2217|X\u2217,X,\ud835\udc32\u223c\ud835\udca9\u2062(\ud835\udf41\u2217,\u03a3\u2217),\ud835\udf41\u2217=k\ud835\udf38\u2062(X,X\u2217)T\u2062(k\ud835\udf38\u2062(X,X)+\u03c3\u03f52\u2062I)\u22121\u2062(\ud835\udc32\u2212\u03bc\u2062(X)),\u03a3\u2217=k\ud835\udf38\u2062(X\u2217,X\u2217)\u2212k\ud835\udf38\u2062(X,X\u2217)T\u2062(k\ud835\udf38\u2062(X,X)+\u03c3\u03f52\u2062I)\u22121\u2062k\ud835\udf38\u2062(X,X\u2217).formulae-sequencesimilar-toconditionalsuperscript\ud835\udc1fsuperscript\ud835\udc4b\ud835\udc4b\ud835\udc32\ud835\udca9superscript\ud835\udf41superscript\u03a3formulae-sequencesuperscript\ud835\udf41subscript\ud835\udc58\ud835\udf38superscript\ud835\udc4bsuperscript\ud835\udc4b\ud835\udc47superscriptsubscript\ud835\udc58\ud835\udf38\ud835\udc4b\ud835\udc4bsuperscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc3c1\ud835\udc32\ud835\udf07\ud835\udc4bsuperscript\u03a3subscript\ud835\udc58\ud835\udf38superscript\ud835\udc4bsuperscript\ud835\udc4bsubscript\ud835\udc58\ud835\udf38superscript\ud835\udc4bsuperscript\ud835\udc4b\ud835\udc47superscriptsubscript\ud835\udc58\ud835\udf38\ud835\udc4b\ud835\udc4bsuperscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc3c1subscript\ud835\udc58\ud835\udf38\ud835\udc4bsuperscript\ud835\udc4b\\begin{split}\\mathbf{f}^{*}|X^{*},X,\\mathbf{y}&\\sim\\mathcal{N}(\\boldsymbol{\\mu%\n}^{*},\\Sigma^{*})\\,,\\\\\n\\boldsymbol{\\mu}^{*}&=k_{\\boldsymbol{\\gamma}}(X,X^{*})^{T}(k_{\\boldsymbol{%\n\\gamma}}(X,X)+\\sigma_{\\epsilon}^{2}I)^{-1}(\\mathbf{y}-\\mu(X))\\,,\\\\\n\\Sigma^{*}&=k_{\\boldsymbol{\\gamma}}(X^{*},X^{*})-k_{\\boldsymbol{\\gamma}}(X,X^{%\n*})^{T}(k_{\\boldsymbol{\\gamma}}(X,X)+\\sigma_{\\epsilon}^{2}I)^{-1}k_{%\n\\boldsymbol{\\gamma}}(X,X^{*})\\,.\\\\\n\\end{split}start_ROW start_CELL bold_f start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT | italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_X , bold_y end_CELL start_CELL \u223c caligraphic_N ( bold_italic_\u03bc start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , roman_\u03a3 start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) , end_CELL end_ROW start_ROW start_CELL bold_italic_\u03bc start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_CELL start_CELL = italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X ) + italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_I ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_y - italic_\u03bc ( italic_X ) ) , end_CELL end_ROW start_ROW start_CELL roman_\u03a3 start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_CELL start_CELL = italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) - italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X ) + italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_I ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) . end_CELL end_ROW\n(4)\n\n\n\n2.2 Deep Kernel Learning\nThe choice of the kernel is a crucial aspect for the performance of a GP. For example, a SE kernel (see Equation 2) can only learn information about the data using the noise-scale and the length-scale parameters, which tell us how quickly the correlation in our data varies with respect to the distance of the input-data pairs. This is clearly a limiting factor when dealing with complex datasets with non-trivial dependencies and correlations. To overcome the problem of the limited expressivity of GP kernels, deep kernel learning (DKL) was introduced in [45].\n\nThe key idea of DKL is to embed a (deep) NN g\u2062(\ud835\udc31;\ud835\udf3d)\ud835\udc54\ud835\udc31\ud835\udf3dg(\\mathbf{x};\\boldsymbol{\\theta})italic_g ( bold_x ; bold_italic_\u03b8 ) of parameters \ud835\udf3d\ud835\udf3d\\boldsymbol{\\theta}bold_italic_\u03b8, i.e., the weights and biases of the NN, into the kernel function of a GP:\n\nkDKL\u2062(\ud835\udc31,\ud835\udc31\u2032;\ud835\udf38,\ud835\udf3d)=k\ud835\udf38\u2062(g\u2062(\ud835\udc31;\ud835\udf3d),g\u2062(\ud835\udc31\u2032;\ud835\udf3d))=k\u2062(g\u2062(\ud835\udc31;\ud835\udf3d),g\u2062(\ud835\udc31\u2032;\ud835\udf3d);\ud835\udf38).subscript\ud835\udc58DKL\ud835\udc31superscript\ud835\udc31\u2032\ud835\udf38\ud835\udf3dsubscript\ud835\udc58\ud835\udf38\ud835\udc54\ud835\udc31\ud835\udf3d\ud835\udc54superscript\ud835\udc31\u2032\ud835\udf3d\ud835\udc58\ud835\udc54\ud835\udc31\ud835\udf3d\ud835\udc54superscript\ud835\udc31\u2032\ud835\udf3d\ud835\udf38k_{\\text{DKL}}(\\mathbf{x},\\mathbf{x^{\\prime}};{\\boldsymbol{\\gamma}},%\n\\boldsymbol{\\theta})=k_{{\\boldsymbol{\\gamma}}}(g(\\mathbf{x};\\boldsymbol{\\theta%\n}),g(\\mathbf{x^{\\prime}};\\boldsymbol{\\theta}))=k(g(\\mathbf{x};\\boldsymbol{%\n\\theta}),g(\\mathbf{x^{\\prime}};\\boldsymbol{\\theta});\\boldsymbol{\\gamma})\\,.italic_k start_POSTSUBSCRIPT DKL end_POSTSUBSCRIPT ( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b3 , bold_italic_\u03b8 ) = italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_g ( bold_x ; bold_italic_\u03b8 ) , italic_g ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b8 ) ) = italic_k ( italic_g ( bold_x ; bold_italic_\u03b8 ) , italic_g ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b8 ) ; bold_italic_\u03b3 ) .\n(5)\n\nIn this way, we can rely on the expressive power of NNs to learn compact and low-dimensional representations of the data, and unveil the non-trivial dependencies of the data. Then, we can feed these representations to the GP for quantifying the uncertainties.\n\nThe GP hyperparameters \ud835\udf38\ud835\udf38\\boldsymbol{\\gamma}bold_italic_\u03b3 and the NN parameters \ud835\udf3d\ud835\udf3d\\boldsymbol{\\theta}bold_italic_\u03b8 are jointly learned by maximizing the log marginal likelihood (see Equation (3)). It is possible to use the chain rule to compute derivatives of the log marginal likelihood, that we indicate with \u2112\u2062(\ud835\udf38,\ud835\udf3d)\u2112\ud835\udf38\ud835\udf3d\\mathcal{L}(\\boldsymbol{\\gamma},\\boldsymbol{\\theta})caligraphic_L ( bold_italic_\u03b3 , bold_italic_\u03b8 ), with respect to kernel hyperparameters \ud835\udf38\ud835\udf38\\boldsymbol{\\gamma}bold_italic_\u03b3 and the NN parameters \ud835\udf3d\ud835\udf3d\\boldsymbol{\\theta}bold_italic_\u03b8, thus obtaining:\n\n\u2202\u2112\u2062(\ud835\udf38,\ud835\udf3d)\u2202\ud835\udf38=\u2202\u2112\u2062(\ud835\udf38,\ud835\udf3d)\u2202k\ud835\udf38\u2062\u2202k\ud835\udf38\u2202\ud835\udf38,\u2202\u2112\u2062(\ud835\udf38,\ud835\udf3d)\u2202\ud835\udf3d=\u2202\u2112\u2062(\ud835\udf38,\ud835\udf3d)\u2202k\ud835\udf38\u2062\u2202k\ud835\udf38\u2202g\u2062(\ud835\udc31,\ud835\udf3d)\u2062\u2202g\u2062(\ud835\udc31,\ud835\udf3d)\u2202\ud835\udf3d.formulae-sequence\u2112\ud835\udf38\ud835\udf3d\ud835\udf38\u2112\ud835\udf38\ud835\udf3dsubscript\ud835\udc58\ud835\udf38subscript\ud835\udc58\ud835\udf38\ud835\udf38\u2112\ud835\udf38\ud835\udf3d\ud835\udf3d\u2112\ud835\udf38\ud835\udf3dsubscript\ud835\udc58\ud835\udf38subscript\ud835\udc58\ud835\udf38\ud835\udc54\ud835\udc31\ud835\udf3d\ud835\udc54\ud835\udc31\ud835\udf3d\ud835\udf3d\\frac{\\partial\\mathcal{L}(\\boldsymbol{\\gamma},\\boldsymbol{\\theta})}{\\partial{%\n\\boldsymbol{\\gamma}}}=\\frac{\\partial\\mathcal{L}(\\boldsymbol{\\gamma},%\n\\boldsymbol{\\theta})}{\\partial k_{{\\boldsymbol{\\gamma}}}}\\frac{\\partial k_{{%\n\\boldsymbol{\\gamma}}}}{\\partial{\\boldsymbol{\\gamma}}},\\hskip 19.91684pt\\frac{%\n\\partial\\mathcal{L}(\\boldsymbol{\\gamma},\\boldsymbol{\\theta})}{\\partial%\n\\boldsymbol{\\theta}}=\\frac{\\partial\\mathcal{L}(\\boldsymbol{\\gamma},\\boldsymbol%\n{\\theta})}{\\partial k_{{\\boldsymbol{\\gamma}}}}\\frac{\\partial k_{{\\boldsymbol{%\n\\gamma}}}}{\\partial g(\\mathbf{x},\\boldsymbol{\\theta})}\\frac{\\partial g(\\mathbf%\n{x},\\boldsymbol{\\theta})}{\\partial\\boldsymbol{\\theta}}.divide start_ARG \u2202 caligraphic_L ( bold_italic_\u03b3 , bold_italic_\u03b8 ) end_ARG start_ARG \u2202 bold_italic_\u03b3 end_ARG = divide start_ARG \u2202 caligraphic_L ( bold_italic_\u03b3 , bold_italic_\u03b8 ) end_ARG start_ARG \u2202 italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT end_ARG divide start_ARG \u2202 italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT end_ARG start_ARG \u2202 bold_italic_\u03b3 end_ARG , divide start_ARG \u2202 caligraphic_L ( bold_italic_\u03b3 , bold_italic_\u03b8 ) end_ARG start_ARG \u2202 bold_italic_\u03b8 end_ARG = divide start_ARG \u2202 caligraphic_L ( bold_italic_\u03b3 , bold_italic_\u03b8 ) end_ARG start_ARG \u2202 italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT end_ARG divide start_ARG \u2202 italic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT end_ARG start_ARG \u2202 italic_g ( bold_x , bold_italic_\u03b8 ) end_ARG divide start_ARG \u2202 italic_g ( bold_x , bold_italic_\u03b8 ) end_ARG start_ARG \u2202 bold_italic_\u03b8 end_ARG .\n(6)\n\nOptimizing the GP hyperparameters through Equation (3) requires to repeatedly invert the covariance matrix k\ud835\udf38\u2062(X,X)+\u03c3\u03f52\u2062Isubscript\ud835\udc58\ud835\udf38\ud835\udc4b\ud835\udc4bsuperscriptsubscript\ud835\udf0eitalic-\u03f52\ud835\udc3ck_{\\boldsymbol{\\gamma}}(X,X)+\\sigma_{\\epsilon}^{2}Iitalic_k start_POSTSUBSCRIPT bold_italic_\u03b3 end_POSTSUBSCRIPT ( italic_X , italic_X ) + italic_\u03c3 start_POSTSUBSCRIPT italic_\u03f5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_I, with size N\u00d7N\ud835\udc41\ud835\udc41N\\times Nitalic_N \u00d7 italic_N. However, for large datasets, i.e., when N\u226b1much-greater-than\ud835\udc411N\\gg 1italic_N \u226b 1, the full covariance matrix may be too large to be stored in memory and computationally prohibitive to invert it. In these cases, it is common practice in machine learning to utilize minibatches of randomly-samples data points to compute the loss functions and compute the gradients. However, when we use minibatches to train the GPs, the posterior distribution is not Gaussian anymore, even when a Gaussian likelihood is used. When dealing with non-Gaussian posteriors, we can rely on variational inference (VI) [48]. VI is an approximation technique for dealing with non-Gaussian posteriors, deriving from minibatch training and/or non-Gaussian likelihoods. VI allows one to approximate the posterior by the best-fitting Gaussian distribution using a set of samples, often called inducing points, from the posterior. VI allows for drastically reducing the computation cost of standard GPs and effectively utilizing DKL with large datasets.\n\nStochastic variational DKL (SVDKL) [47] extends DKL to minibatch training and non-Gaussian posteriors by means of VI. SVDKL can deal with large dataset, effectively mitigating the main limitations of traditional GPs. SVDKL is also considerably cheaper than Bayesian NNs or ensembles methods [54, 55], making it an essential architecture in many applications. SVDKL can be used as a building block for learning ROMs from high-dimensional and noisy data [41]. The framework proposed in [41] is composed of (i) a SVDKL encoder-decoder scheme for learning low-dimensional representations of the data and (ii) a SVDKL using the representations to predict the dynamics of the systems forward in time. The encoder-decoder scheme resembles a variational autoencoder [56], but with better uncertainty quantification capabilities due to the presence of the GP kernel.\n\n"
        },
        {
            "id": "S3",
            "type": "text",
            "title": "3Recurrent Stochastic Variational Deep Kernel Learning for Dynamical Systems",
            "caption": "3Recurrent Stochastic Variational Deep Kernel Learning for Dynamical Systems",
            "metadata": {},
            "text": "\n3 Recurrent Stochastic Variational Deep Kernel Learning for Dynamical Systems\n\n3.1 Problem Statement\nIn our research, we consider nonlinear dynamical systems expressed in the state-space form:\n\n\ud835\udc2c\u02d9\u2062(t)=f\u2062(\ud835\udc2c\u2062(t),\ud835\udc2e\u2062(t);\ud835\udc29),\ud835\udc2c\u2062(t0)=\ud835\udc2c0,t\u2208[t0,tf],formulae-sequence\u02d9\ud835\udc2c\ud835\udc61\ud835\udc53\ud835\udc2c\ud835\udc61\ud835\udc2e\ud835\udc61\ud835\udc29formulae-sequence\ud835\udc2csubscript\ud835\udc610subscript\ud835\udc2c0\ud835\udc61subscript\ud835\udc610subscript\ud835\udc61\ud835\udc53\\dot{\\mathbf{s}}(t)=f(\\mathbf{s}(t),\\mathbf{u}(t);\\mathbf{p}),\\hskip 14.22636%\npt\\mathbf{s}(t_{0})=\\mathbf{s}_{0},\\hskip 14.22636ptt\\in[t_{0},t_{f}]\\,,over\u02d9 start_ARG bold_s end_ARG ( italic_t ) = italic_f ( bold_s ( italic_t ) , bold_u ( italic_t ) ; bold_p ) , bold_s ( italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = bold_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t \u2208 [ italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ] ,\n(7)\n\nwhere \ud835\udc2c\u2062(t)\u2208\u211d|\ud835\udc2c|\ud835\udc2c\ud835\udc61superscript\u211d\ud835\udc2c\\mathbf{s}(t)\\in\\mathbb{R}^{|\\mathbf{s}|}bold_s ( italic_t ) \u2208 blackboard_R start_POSTSUPERSCRIPT | bold_s | end_POSTSUPERSCRIPT represents the state vector at time t\ud835\udc61titalic_t, \ud835\udc2c\u02d9\u2062(t)\u02d9\ud835\udc2c\ud835\udc61\\dot{\\mathbf{s}}(t)over\u02d9 start_ARG bold_s end_ARG ( italic_t ) its time derivative, \ud835\udc2e\u2062(t)\u2208\u211d|\ud835\udc2e|\ud835\udc2e\ud835\udc61superscript\u211d\ud835\udc2e\\mathbf{u}(t)\\in\\mathbb{R}^{|\\mathbf{u}|}bold_u ( italic_t ) \u2208 blackboard_R start_POSTSUPERSCRIPT | bold_u | end_POSTSUPERSCRIPT is the control input at time t\ud835\udc61titalic_t, \ud835\udc29\u2208\u211d|\ud835\udc29|\ud835\udc29superscript\u211d\ud835\udc29\\mathbf{p}\\in\\mathbb{R}^{|\\mathbf{p}|}bold_p \u2208 blackboard_R start_POSTSUPERSCRIPT | bold_p | end_POSTSUPERSCRIPT is the vector of parameters, \ud835\udc2c0subscript\ud835\udc2c0\\mathbf{s}_{0}bold_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is the initial condition, and t0subscript\ud835\udc610t_{0}italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and tfsubscript\ud835\udc61\ud835\udc53t_{f}italic_t start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT are the initial and final times, respectively. The nonlinear function f\ud835\udc53fitalic_f determines the evolution of the system with respect to the current state \ud835\udc2c\u2062(t)\ud835\udc2c\ud835\udc61\\mathbf{s}(t)bold_s ( italic_t ) and control input \ud835\udc2e\u2062(t)\ud835\udc2e\ud835\udc61\\mathbf{u}(t)bold_u ( italic_t ).\n\nIn many real-world applications, the state \ud835\udc2c\u2062(t)\ud835\udc2c\ud835\udc61\\mathbf{s}(t)bold_s ( italic_t ) and the FOM f\ud835\udc53fitalic_f may be unknown or not readily available. However, we can often obtain indirect information about these systems through measurements collected by sensor devices. We denote the measurements at a generic timestep t\ud835\udc61titalic_t with \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, with \ud835\udc31\u2208\u211d|\ud835\udc31|\ud835\udc31superscript\u211d\ud835\udc31\\mathbf{x}\\in\\mathbb{R}^{|\\mathbf{x}|}bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT | bold_x | end_POSTSUPERSCRIPT, and the measurement at timestep t+1\ud835\udc611t+1italic_t + 1 as \ud835\udc31t+1subscript\ud835\udc31\ud835\udc611\\mathbf{x}_{t+1}bold_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT due to the discrete-time nature of the measurements. Given a set of M\ud835\udc40Mitalic_M observed trajectories \u039e=[X1,\u22ef,XM]\u039esubscript\ud835\udc4b1\u22efsubscript\ud835\udc4b\ud835\udc40\\Xi=[X_{1},\\cdots,X_{M}]roman_\u039e = [ italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u22ef , italic_X start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ], controls \u03a9=[U1,\u22ef,UM]\u03a9subscript\ud835\udc481\u22efsubscript\ud835\udc48\ud835\udc40\\Omega=[U_{1},\\cdots,U_{M}]roman_\u03a9 = [ italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u22ef , italic_U start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ], and parameters P=[\ud835\udc291,\u22ef,\ud835\udc29M]\ud835\udc43subscript\ud835\udc291\u22efsubscript\ud835\udc29\ud835\udc40P=[\\mathbf{p}_{1},\\cdots,\\mathbf{p}_{M}]italic_P = [ bold_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u22ef , bold_p start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ], if any, where for each trajectory we collect N\ud835\udc41Nitalic_N high-dimensional and noisy measurements Xi=[\ud835\udc311,\u22ef,\ud835\udc31N]subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc311\u22efsubscript\ud835\udc31\ud835\udc41X_{i}=[\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{N}]italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u22ef , bold_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ], N\u22121\ud835\udc411N-1italic_N - 1 control inputs Ui=[\ud835\udc2e1,\u22ef,\ud835\udc2eN\u22121]subscript\ud835\udc48\ud835\udc56subscript\ud835\udc2e1\u22efsubscript\ud835\udc2e\ud835\udc411U_{i}=[\\mathbf{u}_{1},\\cdots,\\mathbf{u}_{N-1}]italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ bold_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u22ef , bold_u start_POSTSUBSCRIPT italic_N - 1 end_POSTSUBSCRIPT ], and one parameter vector \ud835\udc29isubscript\ud835\udc29\ud835\udc56\\mathbf{p}_{i}bold_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, our objective is to introduce a framework for: (i) learning a compact representation \ud835\udc33\ud835\udc33\\mathbf{z}bold_z of the unknown state variables \ud835\udc2c\ud835\udc2c\\mathbf{s}bold_s, and (ii) learning a surrogate ROM \u03be\ud835\udf09\\xiitalic_\u03be as a proxy for f\ud835\udc53fitalic_f that predicts the dynamics of the latent state variables, given, if any, control inputs and parameters. Due to the high dimensionality and corruption of the measurement data, and the unsupervised nature of the learning process111We do not rely on the true environment states in our framework., achieving objectives (i) and (ii) is extremely challenging.\n\nFor conciseness, we use simplified notation \ud835\udc31t\u2212Hsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc3b\\mathbf{x}_{t}^{-H}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT to represent the series \ud835\udc31t\u2212H,\u22ef,\ud835\udc31tsubscript\ud835\udc31\ud835\udc61\ud835\udc3b\u22efsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t-H},\\cdots,\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t - italic_H end_POSTSUBSCRIPT , \u22ef , bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT throughout the paper, with H\ud835\udc3bHitalic_H denoting the history length. This applies not only to the full states \ud835\udc31\ud835\udc31\\mathbf{x}bold_x but also to the latent states \ud835\udc33\ud835\udc33\\mathbf{z}bold_z and control inputs \ud835\udc2e\ud835\udc2e\\mathbf{u}bold_u.\n\n\n3.2 Model Architecture\nTo tackle these two challenges, we introduce a novel recurrent SVDKL architecture (see Figure 1) that is composed of three main blocks (see Figure 2, 3, and 4, respectively):\n\n1.\nan SVDKL encoder that projects the high-dimensional measurements \ud835\udc31\ud835\udc31\\mathbf{x}bold_x into a Gaussian distribution over the latent state variables p\u2062(\ud835\udc33|\ud835\udc31)\ud835\udc5dconditional\ud835\udc33\ud835\udc31p(\\mathbf{z}|\\mathbf{x})italic_p ( bold_z | bold_x ),\n\n2.\na decoder that reconstructs the measurements \ud835\udc31^^\ud835\udc31\\hat{\\mathbf{x}}over^ start_ARG bold_x end_ARG from the latent variables \ud835\udc33\ud835\udc33\\mathbf{z}bold_z, and\n\n3.\na recurrent SVDKL forward dynamical model predicting the evolution of the system using a history of latent state variables \ud835\udc33t\u2212Hsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3b\\mathbf{z}_{t}^{-H}bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT and control inputs \ud835\udc2et\u2212Hsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc3b\\mathbf{u}_{t}^{-H}bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT, and parameters \ud835\udc29\ud835\udc29\\mathbf{p}bold_p, if available.\n\n\nWith reference to Figure 2, the encoder \u03d5:\u211d|\ud835\udc31|\u2192[0,1]|\ud835\udc33|:italic-\u03d5\u2192superscript\u211d\ud835\udc31superscript01\ud835\udc33\\phi:\\mathbb{R}^{|\\mathbf{x}|}\\rightarrow[0,1]^{|\\mathbf{z}|}italic_\u03d5 : blackboard_R start_POSTSUPERSCRIPT | bold_x | end_POSTSUPERSCRIPT \u2192 [ 0 , 1 ] start_POSTSUPERSCRIPT | bold_z | end_POSTSUPERSCRIPT is modeled using a SVDKL of parameters \ud835\udf3d\u03d5subscript\ud835\udf3ditalic-\u03d5\\boldsymbol{\\theta}_{\\phi}bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT and hyperparameters \ud835\udf38\u03d5,\u03c3\u03d52subscript\ud835\udf38italic-\u03d5superscriptsubscript\ud835\udf0eitalic-\u03d52\\boldsymbol{\\gamma}_{\\phi},\\sigma_{\\phi}^{2}bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, with [0,1]|\ud835\udc33|superscript01\ud835\udc33[0,1]^{|\\mathbf{z}|}[ 0 , 1 ] start_POSTSUPERSCRIPT | bold_z | end_POSTSUPERSCRIPT indicating the distribution over the latent variables \ud835\udc33\ud835\udc33\\mathbf{z}bold_z. In particular, the encoder \u03d5italic-\u03d5\\phiitalic_\u03d5 maps a high-dimensional measurement \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT to a latent state distribution p\u2062(\ud835\udc33t|\ud835\udc31t)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc61subscript\ud835\udc31\ud835\udc61p(\\mathbf{z}_{t}|\\mathbf{x}_{t})italic_p ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ):\n\nzi,t=fi\u03d5\u2062(\ud835\udc31t)+\u03f5\u03d5,\u03f5\u03d5\u223c\ud835\udca9\u2062(0,\u03c3\u03d52),fi\u03d5\u2062(\ud835\udc31t)\u223c\ud835\udca2\u2062\ud835\udcab\u2062(\u03bc\u2062(g\u03d5\u2062(\ud835\udc31t;\ud835\udf3d\u03d5)),k\u2062(g\u03d5\u2062(\ud835\udc31t;\ud835\udf3d\u03d5),g\u03d5\u2062(\ud835\udc31t\u2032\u2032;\ud835\udf3d\u03d5);\ud835\udf38\u03d5,i)),1\u2264i\u2264|\ud835\udc33|,\\begin{split}z_{i,t}&=f_{i}^{\\phi}(\\mathbf{x}_{t})+\\epsilon_{\\phi},\\quad%\n\\epsilon_{\\phi}\\sim\\mathcal{N}(0,\\sigma^{2}_{\\phi})\\,,\\\\\nf_{i}^{\\phi}(\\mathbf{x}_{t})&\\sim\\mathcal{GP}(\\mu(g_{\\phi}(\\mathbf{x}_{t};%\n\\boldsymbol{\\theta}_{\\phi})),k(g_{\\phi}(\\mathbf{x}_{t};\\boldsymbol{\\theta}_{%\n\\phi}),g_{\\phi}(\\mathbf{x}^{\\prime}_{t^{\\prime}};\\boldsymbol{\\theta}_{\\phi});%\n\\boldsymbol{\\gamma}_{\\phi,i})),\\quad 1\\leq i\\leq|\\mathbf{z}|\\,,\\end{split}start_ROW start_CELL italic_z start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT end_CELL start_CELL = italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) + italic_\u03f5 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03f5 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT \u223c caligraphic_N ( 0 , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) , end_CELL end_ROW start_ROW start_CELL italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_CELL start_CELL \u223c caligraphic_G caligraphic_P ( italic_\u03bc ( italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) ) , italic_k ( italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) ; bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 , italic_i end_POSTSUBSCRIPT ) ) , 1 \u2264 italic_i \u2264 | bold_z | , end_CELL end_ROW\n(8)\n\nwhere zi,tsubscript\ud835\udc67\ud835\udc56\ud835\udc61z_{i,t}italic_z start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT indicates the sample from the it\u2062hsuperscript\ud835\udc56\ud835\udc61\u210ei^{th}italic_i start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT GP with SE kernel k\u2062(\u2219,\u2219\u2032;\ud835\udf38\u03d5)\ud835\udc58\u2219superscript\u2219\u2032subscript\ud835\udf38italic-\u03d5k(\\bullet,\\bullet^{\\prime};\\boldsymbol{\\gamma}_{\\phi})italic_k ( \u2219 , \u2219 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) and mean \u03bc\ud835\udf07\\muitalic_\u03bc, \u03f5\u03d5subscriptitalic-\u03f5italic-\u03d5\\epsilon_{\\phi}italic_\u03f5 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT is an independently-added noise, and |\ud835\udc33|\ud835\udc33|\\mathbf{z}|| bold_z | indicates the dimension of \ud835\udc33\ud835\udc33\\mathbf{z}bold_z. The GP inputs g\u03d5\u2062(\ud835\udc31t;\ud835\udf3d\u03d5)subscript\ud835\udc54italic-\u03d5subscript\ud835\udc31\ud835\udc61subscript\ud835\udf3ditalic-\u03d5g_{\\phi}(\\mathbf{x}_{t};\\boldsymbol{\\theta}_{\\phi})italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) and g\u03d5\u2062(\ud835\udc31t\u2032;\ud835\udf3d\u03d5)subscript\ud835\udc54italic-\u03d5subscriptsuperscript\ud835\udc31\u2032\ud835\udc61subscript\ud835\udf3ditalic-\u03d5g_{\\phi}(\\mathbf{x}^{\\prime}_{t};\\boldsymbol{\\theta}_{\\phi})italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) are the representations of the data pair (\ud835\udc31,\ud835\udc31\u2032)\ud835\udc31superscript\ud835\udc31\u2032(\\mathbf{x},\\mathbf{x}^{\\prime})( bold_x , bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) obtained from the NN g\u03d5\u2062(\u2219;\ud835\udf3d\u03d5)subscript\ud835\udc54italic-\u03d5\u2219subscript\ud835\udf3ditalic-\u03d5g_{\\phi}(\\bullet;\\boldsymbol{\\theta}_{\\phi})italic_g start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ( \u2219 ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT ) with parameters \ud835\udf3d\u03d5subscript\ud835\udf3ditalic-\u03d5\\boldsymbol{\\theta}_{\\phi}bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT.\n\nWith reference to Figure 3, the decoder \u03c8\ud835\udf13\\psiitalic_\u03c8 is modeled using an NN with parameters \ud835\udf3d\u03c8subscript\ud835\udf3d\ud835\udf13\\boldsymbol{\\theta}_{\\psi}bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT. The decoder maps a sample \ud835\udc33\ud835\udc33\\mathbf{z}bold_z to the conditional distribution p\u2062(\ud835\udc31^|\ud835\udc33)\ud835\udc5dconditional^\ud835\udc31\ud835\udc33p(\\hat{\\mathbf{x}}|\\mathbf{z})italic_p ( over^ start_ARG bold_x end_ARG | bold_z ). Similar to VAEs [56], the distribution p\u2062(\ud835\udc31^|\ud835\udc33)\ud835\udc5dconditional^\ud835\udc31\ud835\udc33p(\\hat{\\mathbf{x}}|\\mathbf{z})italic_p ( over^ start_ARG bold_x end_ARG | bold_z ) is approximated to be independently-distributed Gaussian distributions. In general, the decoding NN \u03c8\ud835\udf13\\psiitalic_\u03c8 learns the means and variances of these distributions. Following [57, 58], however, our decoder in this work only learns the mean vector of \ud835\udc31^|\ud835\udc33conditional^\ud835\udc31\ud835\udc33\\hat{\\mathbf{x}}|\\mathbf{z}over^ start_ARG bold_x end_ARG | bold_z, while the covariance is set to the identity matrix I\ud835\udc3cIitalic_I, i.e., \u03c8:\u211d|\ud835\udc33|\u2192[0,1]|\ud835\udc31|:\ud835\udf13\u2192superscript\u211d\ud835\udc33superscript01\ud835\udc31\\psi:\\mathbb{R}^{|\\mathbf{z}|}\\rightarrow[0,1]^{|\\mathbf{x}|}italic_\u03c8 : blackboard_R start_POSTSUPERSCRIPT | bold_z | end_POSTSUPERSCRIPT \u2192 [ 0 , 1 ] start_POSTSUPERSCRIPT | bold_x | end_POSTSUPERSCRIPT and\n\n\ud835\udc31^t|\ud835\udc33t\u223c\ud835\udca9\u03c8(\ud835\udc33t;\ud835\udf3d\u03c8),I).\\hat{\\mathbf{x}}_{t}|\\mathbf{z}_{t}\\sim\\mathcal{N}\\psi(\\mathbf{z}_{t};%\n\\boldsymbol{\\theta}_{\\psi}),I).over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u223c caligraphic_N italic_\u03c8 ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT ) , italic_I ) .\n(9)\n\nThe reconstruction \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT can be obtained by feeding \ud835\udc33tsubscript\ud835\udc33\ud835\udc61\\mathbf{z}_{t}bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT to the decoder \u03c8\ud835\udf13\\psiitalic_\u03c8 and then sampling from this distribution.\n\nWith reference to Figure 4, the forward dynamical model \u03be:\u211d|\ud835\udc33|\u00d7\u211d|\ud835\udc2e|\u00d7\u211d|\ud835\udc29|\u2192[0,1]|\ud835\udc33|:\ud835\udf09\u2192superscript\u211d\ud835\udc33superscript\u211d\ud835\udc2esuperscript\u211d\ud835\udc29superscript01\ud835\udc33\\xi:\\mathbb{R}^{|\\mathbf{z}|}\\times\\mathbb{R}^{|\\mathbf{u}|}\\times\\mathbb{R}^{%\n|\\mathbf{p}|}\\rightarrow[0,1]^{|\\mathbf{z}|}italic_\u03be : blackboard_R start_POSTSUPERSCRIPT | bold_z | end_POSTSUPERSCRIPT \u00d7 blackboard_R start_POSTSUPERSCRIPT | bold_u | end_POSTSUPERSCRIPT \u00d7 blackboard_R start_POSTSUPERSCRIPT | bold_p | end_POSTSUPERSCRIPT \u2192 [ 0 , 1 ] start_POSTSUPERSCRIPT | bold_z | end_POSTSUPERSCRIPT, with parameters \ud835\udf3d\u03besubscript\ud835\udf3d\ud835\udf09\\boldsymbol{\\theta}_{\\xi}bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT and hyperparameters \ud835\udf38\u03be,\u03c3\u03be2subscript\ud835\udf38\ud835\udf09superscriptsubscript\ud835\udf0e\ud835\udf092\\boldsymbol{\\gamma}_{\\xi},\\sigma_{\\xi}^{2}bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, is a SVDKL with a recurrent NN architecture, i.e., a long short-term memory (LSTM) NN [59], that maps sequences of latent states, actions, and parameters to latent next state distribution p\u2062(\ud835\udc33t+1|\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc611superscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc3b\ud835\udc29p\\left(\\mathbf{z}_{t+1}|\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t}^{-H},\\mathbf{p}\\right)italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ).\n\nIn particular, we can write the latent next states \ud835\udc33t+1subscript\ud835\udc33\ud835\udc611\\mathbf{z}_{t+1}bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT as:\n\nzi,t+1=fi\u03be\u2062(\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29)+\u03f5\u03be,\u03f5\u03be\u223c\ud835\udca9\u2062(0,\u03c3\u03be2),fi\u03be\u2062(\u2219)\u223c\ud835\udca2\ud835\udcab(\u03bc(g\u03be(\u2219;\ud835\udf3d\u03be),k(g\u03be(\u2219;\ud835\udf3d\u03be),g\u03be(\u2219\u2032;\ud835\udf3d\u03be);\ud835\udf38\u03be,i)),1\u2264i\u2264|\ud835\udc33|,\\begin{split}z_{i,t+1}&=f_{i}^{\\xi}\\left(\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t}^{-%\nH},\\mathbf{p}\\right)+\\epsilon_{\\xi},\\quad\\epsilon_{\\xi}\\sim\\mathcal{N}(0,%\n\\sigma^{2}_{\\xi})\\,,\\\\\nf_{i}^{\\xi}(\\bullet)&\\sim\\mathcal{GP}(\\mu(g_{\\xi}(\\bullet;\\boldsymbol{\\theta}_%\n{\\xi}),k(g_{\\xi}(\\bullet;\\boldsymbol{\\theta}_{\\xi}),g_{\\xi}(\\bullet^{\\prime};%\n\\boldsymbol{\\theta}_{\\xi});\\boldsymbol{\\gamma}_{{\\xi},i}))\\,,\\quad 1\\leq i\\leq%\n|\\mathbf{z}|\\,,\\end{split}start_ROW start_CELL italic_z start_POSTSUBSCRIPT italic_i , italic_t + 1 end_POSTSUBSCRIPT end_CELL start_CELL = italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03be end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ) + italic_\u03f5 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03f5 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT \u223c caligraphic_N ( 0 , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) , end_CELL end_ROW start_ROW start_CELL italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03be end_POSTSUPERSCRIPT ( \u2219 ) end_CELL start_CELL \u223c caligraphic_G caligraphic_P ( italic_\u03bc ( italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( \u2219 ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) , italic_k ( italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( \u2219 ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( \u2219 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) ; bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be , italic_i end_POSTSUBSCRIPT ) ) , 1 \u2264 italic_i \u2264 | bold_z | , end_CELL end_ROW\n(10)\n\nwhere zi,t+1subscript\ud835\udc67\ud835\udc56\ud835\udc611z_{i,t+1}italic_z start_POSTSUBSCRIPT italic_i , italic_t + 1 end_POSTSUBSCRIPT is sampled from the it\u2062hsuperscript\ud835\udc56\ud835\udc61\u210ei^{th}italic_i start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT GP, H\ud835\udc3bHitalic_H is the history length, and \u03f5\u03besubscriptitalic-\u03f5\ud835\udf09\\epsilon_{\\xi}italic_\u03f5 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT is a noise term. Similarly to the encoder, the GP inputs g\u03be\u2062(\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29;\ud835\udf3d\u03be)subscript\ud835\udc54\ud835\udf09superscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc3b\ud835\udc29subscript\ud835\udf3d\ud835\udf09g_{\\xi}\\left(\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t}^{-H},\\mathbf{p};\\boldsymbol{%\n\\theta}_{\\xi}\\right)italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) and g\u03be\u2062((\ud835\udc33\u2032)t\u2212H,(\ud835\udc2e\u2032)t\u2212H,\ud835\udc29\u2032;\ud835\udf3d\u03be)subscript\ud835\udc54\ud835\udf09superscriptsubscriptsuperscript\ud835\udc33\u2032\ud835\udc61\ud835\udc3bsuperscriptsubscriptsuperscript\ud835\udc2e\u2032\ud835\udc61\ud835\udc3bsuperscript\ud835\udc29\u2032subscript\ud835\udf3d\ud835\udf09g_{\\xi}\\left((\\mathbf{z}^{\\prime})_{t}^{-H},(\\mathbf{u}^{\\prime})_{t}^{-H},%\n\\mathbf{p}^{\\prime};\\boldsymbol{\\theta}_{\\xi}\\right)italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( ( bold_z start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , ( bold_u start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) are the representations of obtained from the NN g\u03be\u2062(\u2219;\ud835\udf3d\u03be)subscript\ud835\udc54\ud835\udf09\u2219subscript\ud835\udf3d\ud835\udf09g_{\\xi}(\\bullet;\\boldsymbol{\\theta}_{\\xi})italic_g start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ( \u2219 ; bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) with parameters \ud835\udf3d\u03besubscript\ud835\udf3d\ud835\udf09\\boldsymbol{\\theta}_{\\xi}bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT.\n\nThe encoder and decoder have the same NN architecture proposed in [41]. On the other hand, the forward dynamical model replaces the fully-connected NN used in [41] with a recurrent neural network to improve the reliability and accuracy of the predictions forward in time.\n\n\n3.3 Training Objectives\nThe aforementioned encoder, decoder, and forward dynamical model are jointly trained to infer meaningful low-dimensional representations of the measurements and predict the system evolution forward in time.\nThe first objective term is formulated by utilizing the reconstruction loss, commonly used for training VAEs, which maximizes the marginal likelihood222In practice this is achieved by minimizing the negative log-marginal likelihood. for the reconstruction of \ud835\udc31tsubscript\ud835\udc31\ud835\udc61{\\mathbf{x}}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT by \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT:\n\n\u2112recon\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8)=\ud835\udd3c\ud835\udc31t\u223c\u039e\u2062[\u2212log\u2061\ud835\udd3c\ud835\udc33t|\ud835\udc31t\u2062p\u2062(\ud835\udc31^t|\ud835\udc33t)],subscript\u2112reconsubscript\ud835\udf3ditalic-\u03d5subscript\ud835\udf38italic-\u03d5subscriptsuperscript\ud835\udf0e2italic-\u03d5subscript\ud835\udf3d\ud835\udf13subscript\ud835\udd3csimilar-tosubscript\ud835\udc31\ud835\udc61\u039edelimited-[]subscript\ud835\udd3cconditionalsubscript\ud835\udc33\ud835\udc61subscript\ud835\udc31\ud835\udc61\ud835\udc5dconditionalsubscript^\ud835\udc31\ud835\udc61subscript\ud835\udc33\ud835\udc61\\mathcal{L}_{\\text{recon}}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{\\gamma}_{%\n\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi})=\\mathbb{E}_{\\mathbf{x}_{t}%\n\\sim\\Xi}[-\\log\\mathbb{E}_{{\\mathbf{z}}_{t}|\\mathbf{x}_{t}}p(\\hat{\\mathbf{x}}_{%\nt}|\\mathbf{z}_{t})]\\,,caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT ) = blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u223c roman_\u039e end_POSTSUBSCRIPT [ - roman_log blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_p ( over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] ,\n(11)\n\nwhere \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the reconstructed vector of the measurement \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, obtained by feeding \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT through the encoder \u03d5italic-\u03d5\\phiitalic_\u03d5 and decoder \u03c8\ud835\udf13\\psiitalic_\u03c8, p\u2062(\ud835\udc33|\ud835\udc31)\ud835\udc5dconditional\ud835\udc33\ud835\udc31p(\\mathbf{z}|\\mathbf{x})italic_p ( bold_z | bold_x ) is the distribution learned by the encoder (see Equation (8)), and p\u2062(\ud835\udc31^|\ud835\udc33)\ud835\udc5dconditional^\ud835\udc31\ud835\udc33p(\\hat{\\mathbf{x}}|\\mathbf{z})italic_p ( over^ start_ARG bold_x end_ARG | bold_z ) the distribution learned by the decoder (see Equation (9)). The minimization of loss function in Equation (11) with respect to the encoder and decoder parameters is analogous to the one commonly used by VAEs, which allows us to learn compact representations of the measurements while quantifying the uncertainties in the reconstructions.\n\nFor training the dynamical model \u03be\ud835\udf09\\xiitalic_\u03be, we do not rely on true state values \ud835\udc2c\ud835\udc2c\\mathbf{s}bold_s, but on the sequences of measurements collected at different time steps t\ud835\udc61titalic_t. Therefore, we are not able to use supervised learning techniques to optimize the NN parameters and kernel hyperparameters.\nHowever, we can use the posterior distribution p\u2062(\ud835\udc33t+1|\ud835\udc31t+1)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc611subscript\ud835\udc31\ud835\udc611p(\\mathbf{z}_{t+1}|\\mathbf{x}_{t+1})italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) (see Equation (8)) as the target distribution for learning p\u2062(\ud835\udc33t+1|\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc611superscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc3b\ud835\udc29p\\left(\\mathbf{z}_{t+1}|\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t}^{-H},\\mathbf{p}\\right)italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ).\nThis process translates into evaluating the Kullback-Leiber (KL) divergence between these two distributions:\n\n\u211breg(1)\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=KL[p(\ud835\udc33t+1|\ud835\udc31t+1)\u2225\ud835\udd3c\ud835\udc33t\u2212H|\ud835\udc31t\u2212Hp(\ud835\udc33t+1|\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29)],\\begin{split}&\\mathcal{R}_{\\text{reg}}^{(1)}(\\boldsymbol{\\theta}_{\\phi},%\n\\boldsymbol{\\gamma}_{\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},%\n\\boldsymbol{\\theta}_{\\xi},\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})\\\\\n=\\leavevmode\\nobreak\\ &\\text{KL}\\left[p(\\mathbf{z}_{t+1}|\\mathbf{x}_{t+1})\\Big%\n{\\|}\\leavevmode\\nobreak\\ \\mathbb{E}_{\\mathbf{z}_{t}^{-H}|\\mathbf{x}_{t}^{-H}}%\n\\leavevmode\\nobreak\\ p\\left(\\mathbf{z}_{t+1}|\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t%\n}^{-H},\\mathbf{p}\\right)\\right]\\,,\\end{split}start_ROW start_CELL end_CELL start_CELL caligraphic_R start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) end_CELL end_ROW start_ROW start_CELL = end_CELL start_CELL KL [ italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) \u2225 blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ) ] , end_CELL end_ROW\n(12)\n\nwhere the superscript (1)1(1)( 1 ) in \u211breg(1)superscriptsubscript\u211breg1\\mathcal{R}_{\\text{reg}}^{(1)}caligraphic_R start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT indicates that we perform a 1-step ahead prediction of the latent states from time step t\ud835\udc61titalic_t to t+1\ud835\udc611t+1italic_t + 1 and the subscript reg stands for regularization. The distribution p\u2062(\ud835\udc33t+1|\ud835\udc31t+1)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc611subscript\ud835\udc31\ud835\udc611p(\\mathbf{z}_{t+1}|\\mathbf{x}_{t+1})italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) is obtained by encoding the next measurement \ud835\udc31t+1subscript\ud835\udc31\ud835\udc611\\mathbf{x}_{t+1}bold_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT through \u03d5italic-\u03d5\\phiitalic_\u03d5 (see Figure 2), p\u2062(\ud835\udc33t+1|\ud835\udc33t\u2212H,\ud835\udc2et\u2212H,\ud835\udc29)\ud835\udc5dconditionalsubscript\ud835\udc33\ud835\udc611superscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc3b\ud835\udc29p\\left(\\mathbf{z}_{t+1}|\\mathbf{z}_{t}^{-H},\\mathbf{u}_{t}^{-H},\\mathbf{p}\\right)italic_p ( bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ) is the distribution obtained by the forward dynamical model \u03be\ud835\udf09\\xiitalic_\u03be (see Figure 4), and the expectation \ud835\udd3c\ud835\udc33t\u2212H|\ud835\udc31t\u2212Hsubscript\ud835\udd3cconditionalsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3bsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc3b\\mathbb{E}_{\\mathbf{z}_{t}^{-H}|\\mathbf{x}_{t}^{-H}}blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT end_POSTSUBSCRIPT indicates the marginalization of a sequence of latent variables \ud835\udc33t\u2212Hsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc3b\\mathbf{z}_{t}^{-H}bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT obtained by feeding the measurements \ud835\udc31t\u2212Hsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc3b\\mathbf{x}_{t}^{-H}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT to the encoder \u03d5italic-\u03d5\\phiitalic_\u03d5.\nDifferent from [41], we extend this loss to T\ud835\udc47Titalic_T-step predictions:\n\n\u2112reg\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=\ud835\udd3c\ud835\udc31\u223c\u039e,\ud835\udc2e\u223c\u03a9,\ud835\udc29\u223cP\u20621T\u2062\u2211i=1T\u211breg(i)\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2),subscript\u2112regsubscript\ud835\udf3ditalic-\u03d5subscript\ud835\udf38italic-\u03d5subscriptsuperscript\ud835\udf0e2italic-\u03d5subscript\ud835\udf3d\ud835\udf13subscript\ud835\udf3d\ud835\udf09subscript\ud835\udf38\ud835\udf09subscriptsuperscript\ud835\udf0e2\ud835\udf09subscript\ud835\udd3cformulae-sequencesimilar-to\ud835\udc31\u039eformulae-sequencesimilar-to\ud835\udc2e\u03a9similar-to\ud835\udc29\ud835\udc431\ud835\udc47superscriptsubscript\ud835\udc561\ud835\udc47superscriptsubscript\u211breg\ud835\udc56subscript\ud835\udf3ditalic-\u03d5subscript\ud835\udf38italic-\u03d5subscriptsuperscript\ud835\udf0e2italic-\u03d5subscript\ud835\udf3d\ud835\udf13subscript\ud835\udf3d\ud835\udf09subscript\ud835\udf38\ud835\udf09subscriptsuperscript\ud835\udf0e2\ud835\udf09\\mathcal{L}_{\\text{reg}}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{\\gamma}_{\\phi}%\n,\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},\\boldsymbol{\\theta}_{\\xi},%\n\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})=\\mathbb{E}_{\\mathbf{x}\\sim\\Xi,%\n\\mathbf{u}\\sim\\Omega,\\mathbf{p}\\sim P}\\frac{1}{T}\\sum_{i=1}^{T}\\mathcal{R}_{%\n\\text{reg}}^{(i)}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{\\gamma}_{\\phi},\\sigma%\n^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},\\boldsymbol{\\theta}_{\\xi},\\boldsymbol{%\n\\gamma}_{\\xi},\\sigma^{2}_{\\xi})\\,,caligraphic_L start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) = blackboard_E start_POSTSUBSCRIPT bold_x \u223c roman_\u039e , bold_u \u223c roman_\u03a9 , bold_p \u223c italic_P end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG italic_T end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT caligraphic_R start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) ,\n(13)\n\nwhere we now perform T\ud835\udc47Titalic_T-step ahead predictions from time step t+1\ud835\udc611t+1italic_t + 1 to t+T\ud835\udc61\ud835\udc47t+Titalic_t + italic_T, and\n\n\u211breg(i)\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=KL[p(\ud835\udc33t+i|\ud835\udc31t+i)\u2225\ud835\udd3c\ud835\udc33t+i\u22121\u2212H|\ud835\udc31t+i\u22121\u2212Hp(\ud835\udc33t+i|\ud835\udc33t+i\u22121\u2212H,\ud835\udc2et+i\u22121\u2212H,\ud835\udc29)].\\begin{split}&\\mathcal{R}_{\\text{reg}}^{(i)}(\\boldsymbol{\\theta}_{\\phi},%\n\\boldsymbol{\\gamma}_{\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},%\n\\boldsymbol{\\theta}_{\\xi},\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})\\\\\n=\\leavevmode\\nobreak\\ &\\text{KL}\\left[p(\\mathbf{z}_{t+i}|\\mathbf{x}_{t+i})\\Big%\n{\\|}\\leavevmode\\nobreak\\ \\mathbb{E}_{\\mathbf{z}_{t+i-1}^{-H}\\big{|}\\mathbf{x}_%\n{t+i-1}^{-H}}p\\left(\\mathbf{z}_{t+i}\\leavevmode\\nobreak\\ |\\leavevmode\\nobreak%\n\\ \\mathbf{z}_{t+i-1}^{-H},\\mathbf{u}_{t+i-1}^{-H},\\mathbf{p}\\right)\\right].%\n\\end{split}start_ROW start_CELL end_CELL start_CELL caligraphic_R start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) end_CELL end_ROW start_ROW start_CELL = end_CELL start_CELL KL [ italic_p ( bold_z start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT ) \u2225 blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_p ( bold_z start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ) ] . end_CELL end_ROW\n(14)\n\nSimilar to Equation (12), the expectation \ud835\udd3c\ud835\udc33t+i\u22121\u2212H|\ud835\udc31t+i\u22121\u2212Hsubscript\ud835\udd3cconditionalsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc561\ud835\udc3bsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3b\\mathbb{E}_{\\mathbf{z}_{t+i-1}^{-H}|\\mathbf{x}_{t+i-1}^{-H}}blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT end_POSTSUBSCRIPT indicates the marginalization of a sequence of latent variables \ud835\udc33t+i\u22121\u2212Hsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc561\ud835\udc3b\\mathbf{z}_{t+i-1}^{-H}bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT obtained by feeding the measurements \ud835\udc31t+i\u22121\u2212Hsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3b\\mathbf{x}_{t+i-1}^{-H}bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT to the encoder \u03d5italic-\u03d5\\phiitalic_\u03d5 (Figure 2).\n\nAdditionally, we include a T\ud835\udc47Titalic_T-step reconstruction loss of the \u201cnext measurements\u201d for timesteps t+1,\u22ef,t+T\ud835\udc611\u22ef\ud835\udc61\ud835\udc47t+1,\\cdots,t+Titalic_t + 1 , \u22ef , italic_t + italic_T, which is a variant of the reconstruction loss in Equation (11) to optimize the parameters in the encoder, decoder, and forward model:\n\n\u2112recon-next\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=\ud835\udd3c\ud835\udc31\u223c\u039e,\ud835\udc2e\u223c\u03a9,\ud835\udc29\u223cP\u20621T\u2062\u2211i=1T\u211brecon-next(i)\u2062(\u2219),subscript\u2112recon-nextsubscript\ud835\udf3ditalic-\u03d5subscript\ud835\udf38italic-\u03d5subscriptsuperscript\ud835\udf0e2italic-\u03d5subscript\ud835\udf3d\ud835\udf13subscript\ud835\udf3d\ud835\udf09subscript\ud835\udf38\ud835\udf09subscriptsuperscript\ud835\udf0e2\ud835\udf09subscript\ud835\udd3cformulae-sequencesimilar-to\ud835\udc31\u039eformulae-sequencesimilar-to\ud835\udc2e\u03a9similar-to\ud835\udc29\ud835\udc431\ud835\udc47superscriptsubscript\ud835\udc561\ud835\udc47superscriptsubscript\u211brecon-next\ud835\udc56\u2219\\mathcal{L}_{\\text{recon-next}}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{\\gamma}%\n_{\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},\\boldsymbol{\\theta}_{\\xi}%\n,\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})=\\mathbb{E}_{\\mathbf{x}\\sim\\Xi,%\n\\mathbf{u}\\sim\\Omega,\\mathbf{p}\\sim P}\\frac{1}{T}\\sum_{i=1}^{T}\\mathcal{R}_{%\n\\text{recon-next}}^{(i)}(\\bullet)\\,,caligraphic_L start_POSTSUBSCRIPT recon-next end_POSTSUBSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) = blackboard_E start_POSTSUBSCRIPT bold_x \u223c roman_\u039e , bold_u \u223c roman_\u03a9 , bold_p \u223c italic_P end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG italic_T end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT caligraphic_R start_POSTSUBSCRIPT recon-next end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ( \u2219 ) ,\n(15)\n\nwhere the superscript (i)\ud835\udc56(i)( italic_i ) indicated the ithsuperscript\ud835\udc56thi^{\\text{th}}italic_i start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT step\u2019s reconstruction loss\n\n\u211brecon-next(i)(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=\u2225\ud835\udc31t+i\u2212\ud835\udd3c[\ud835\udc31^t+i|\ud835\udc31t+i\u22121\u2212H,\ud835\udc2et+i\u22121\u2212H,\ud835\udc29]\u22252,\\mathcal{R}_{\\text{recon-next}}^{(i)}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{%\n\\gamma}_{\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},\\boldsymbol{\\theta%\n}_{\\xi},\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})=\\left\\|\\mathbf{x}_{t+i}-%\n\\mathbb{E}[\\hat{\\mathbf{x}}_{t+i}\\leavevmode\\nobreak\\ |\\leavevmode\\nobreak\\ %\n\\mathbf{x}_{t+i-1}^{-H},\\mathbf{u}_{t+i-1}^{-H},\\mathbf{p}]\\right\\|^{2}\\,,caligraphic_R start_POSTSUBSCRIPT recon-next end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) = \u2225 bold_x start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT - blackboard_E [ over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ] \u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,\n(16)\n\nand the marginalized \ud835\udc31^t+isubscript^\ud835\udc31\ud835\udc61\ud835\udc56\\hat{\\mathbf{x}}_{t+i}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT in the expectation \ud835\udd3c\u2062[\ud835\udc31^t+i|\ud835\udc31t+i\u22121\u2212H]\ud835\udd3cdelimited-[]conditionalsubscript^\ud835\udc31\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3b\\mathbb{E}\\left[\\hat{\\mathbf{x}}_{t+i}|\\mathbf{x}_{t+i-1}^{-H}\\right]blackboard_E [ over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT ] is sampled by encoding the sequence of measurements \ud835\udc31t+i\u22121\u2212Hsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3b\\mathbf{x}_{t+i-1}^{-H}bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT through \u03d5italic-\u03d5\\phiitalic_\u03d5 (see Figure 2), predicting the next latent states through \u03be\ud835\udf09\\xiitalic_\u03be (see Figure 4), and then decoding through \u03c8\ud835\udf13\\psiitalic_\u03c8 (see Figure 3):\n\n\ud835\udd3c\u2062[\ud835\udc31^t+i|\ud835\udc31t+i\u22121\u2212H,\ud835\udc2et+i\u22121\u2212H,\ud835\udc29]=\ud835\udd3c\ud835\udc33t+i\u22121\u2212H|\ud835\udc31t+i\u22121\u2212H\u2062\ud835\udd3c\ud835\udc33t+i|\ud835\udc33t+i\u22121\u2212H,\ud835\udc2et+i\u22121\u2212H,\ud835\udc29\u2062\ud835\udd3c\u2062[\ud835\udc31^t+i|\ud835\udc33t+i].\ud835\udd3cdelimited-[]conditionalsubscript^\ud835\udc31\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc561\ud835\udc3b\ud835\udc29subscript\ud835\udd3cconditionalsuperscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc561\ud835\udc3bsuperscriptsubscript\ud835\udc31\ud835\udc61\ud835\udc561\ud835\udc3bsubscript\ud835\udd3cconditionalsubscript\ud835\udc33\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc33\ud835\udc61\ud835\udc561\ud835\udc3bsuperscriptsubscript\ud835\udc2e\ud835\udc61\ud835\udc561\ud835\udc3b\ud835\udc29\ud835\udd3cdelimited-[]conditionalsubscript^\ud835\udc31\ud835\udc61\ud835\udc56subscript\ud835\udc33\ud835\udc61\ud835\udc56\\mathbb{E}\\left[\\hat{\\mathbf{x}}_{t+i}\\leavevmode\\nobreak\\ |\\leavevmode%\n\\nobreak\\ \\mathbf{x}_{t+i-1}^{-H},\\mathbf{u}_{t+i-1}^{-H},\\mathbf{p}\\right]=%\n\\mathbb{E}_{\\mathbf{z}_{t+i-1}^{-H}|\\mathbf{x}_{t+i-1}^{-H}}\\mathbb{E}_{%\n\\mathbf{z}_{t+i}|\\mathbf{z}_{t+i-1}^{-H},\\mathbf{u}_{t+i-1}^{-H},\\mathbf{p}}%\n\\mathbb{E}\\left[\\hat{\\mathbf{x}}_{t+i}|\\mathbf{z}_{t+i}\\right].blackboard_E [ over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p ] = blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT | bold_x start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_u start_POSTSUBSCRIPT italic_t + italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_H end_POSTSUPERSCRIPT , bold_p end_POSTSUBSCRIPT blackboard_E [ over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT | bold_z start_POSTSUBSCRIPT italic_t + italic_i end_POSTSUBSCRIPT ] .\n(17)\n\n\nEventually, the two SVDKL models, \u03d5italic-\u03d5\\phiitalic_\u03d5 and \u03be\ud835\udf09\\xiitalic_\u03be, utilize VI to approximate the posterior distributions in Equations (8) and (10), respectively. Thus, in addition to the aforementioned loss terms, we include the VI losses KL[p(\ud835\udc2f)||q(\ud835\udc2f)]\\text{KL}[p(\\mathbf{v})||q(\\mathbf{v})]KL [ italic_p ( bold_v ) | | italic_q ( bold_v ) ] for both SVDKL models. Here p\u2062(\ud835\udc2f)\ud835\udc5d\ud835\udc2fp(\\mathbf{v})italic_p ( bold_v ) is the posterior to be approximated over the inducing points \ud835\udc2f\ud835\udc2f\\mathbf{v}bold_v, and q\u2062(\ud835\udc2f)\ud835\udc5e\ud835\udc2fq(\\mathbf{v})italic_q ( bold_v ) represents an approximating candidate distribution. The total VI loss term is the sum of the encoder\u2019s VI loss \u2112VI\u03d5\u2062(\ud835\udf38\u03d5,\u03c3\u03d52)superscriptsubscript\u2112VIitalic-\u03d5subscript\ud835\udf38italic-\u03d5superscriptsubscript\ud835\udf0eitalic-\u03d52\\mathcal{L}_{\\text{VI}}^{\\phi}(\\boldsymbol{\\gamma}_{\\phi},\\sigma_{\\phi}^{2})caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT ( bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) and the forward dynamical model\u2019s VI loss \u2112VI\u03be\u2062(\ud835\udf38\u03be,\u03c3\u03be2)superscriptsubscript\u2112VI\ud835\udf09subscript\ud835\udf38\ud835\udf09superscriptsubscript\ud835\udf0e\ud835\udf092\\mathcal{L}_{\\text{VI}}^{\\xi}(\\boldsymbol{\\gamma}_{\\xi},\\sigma_{\\xi}^{2})caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03be end_POSTSUPERSCRIPT ( bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ):\n\n\u2112VI=\u2112VI\u03d5\u2062(\ud835\udf38\u03d5,\u03c3\u03d52)+\u2112VI\u03be\u2062(\ud835\udf38\u03be,\u03c3\u03be2).subscript\u2112VIsuperscriptsubscript\u2112VIitalic-\u03d5subscript\ud835\udf38italic-\u03d5superscriptsubscript\ud835\udf0eitalic-\u03d52superscriptsubscript\u2112VI\ud835\udf09subscript\ud835\udf38\ud835\udf09superscriptsubscript\ud835\udf0e\ud835\udf092\\mathcal{L}_{\\text{VI}}=\\mathcal{L}_{\\text{VI}}^{\\phi}(\\boldsymbol{\\gamma}_{%\n\\phi},\\sigma_{\\phi}^{2})+\\mathcal{L}_{\\text{VI}}^{\\xi}(\\boldsymbol{\\gamma}_{%\n\\xi},\\sigma_{\\xi}^{2})\\,.caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT ( bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) + caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03be end_POSTSUPERSCRIPT ( bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) .\n(18)\n\n\nThe overall loss function that will be jointly optimized is simply the weighted sum of all the aforementioned objective terms:\n\n\u2112total\u2062(\ud835\udf3d\u03d5,\ud835\udf38\u03d5,\u03c3\u03d52,\ud835\udf3d\u03c8,\ud835\udf3d\u03be,\ud835\udf38\u03be,\u03c3\u03be2)=\u2112recon+\u03c9reg\u2062\u2112reg+\u2112recon-next+\u03c9var\u2062\u2112VI,subscript\u2112totalsubscript\ud835\udf3ditalic-\u03d5subscript\ud835\udf38italic-\u03d5subscriptsuperscript\ud835\udf0e2italic-\u03d5subscript\ud835\udf3d\ud835\udf13subscript\ud835\udf3d\ud835\udf09subscript\ud835\udf38\ud835\udf09subscriptsuperscript\ud835\udf0e2\ud835\udf09subscript\u2112reconsubscript\ud835\udf14regsubscript\u2112regsubscript\u2112recon-nextsubscript\ud835\udf14varsubscript\u2112VI\\mathcal{L}_{\\text{total}}(\\boldsymbol{\\theta}_{\\phi},\\boldsymbol{\\gamma}_{%\n\\phi},\\sigma^{2}_{\\phi},\\boldsymbol{\\theta}_{\\psi},\\boldsymbol{\\theta}_{\\xi},%\n\\boldsymbol{\\gamma}_{\\xi},\\sigma^{2}_{\\xi})=\\mathcal{L}_{\\text{recon}}+\\omega_%\n{\\text{reg}}\\mathcal{L}_{\\text{reg}}+\\mathcal{L}_{\\text{recon-next}}+\\omega_{%\n\\text{var}}\\mathcal{L}_{\\text{VI}}\\,,caligraphic_L start_POSTSUBSCRIPT total end_POSTSUBSCRIPT ( bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03c8 end_POSTSUBSCRIPT , bold_italic_\u03b8 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , bold_italic_\u03b3 start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03be end_POSTSUBSCRIPT ) = caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT + italic_\u03c9 start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT recon-next end_POSTSUBSCRIPT + italic_\u03c9 start_POSTSUBSCRIPT var end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT VI end_POSTSUBSCRIPT ,\n(19)\n\nin which \u03c9regsubscript\ud835\udf14reg\\omega_{\\text{reg}}italic_\u03c9 start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT and \u03c9varsubscript\ud835\udf14var\\omega_{\\text{var}}italic_\u03c9 start_POSTSUBSCRIPT var end_POSTSUBSCRIPT are scalar factors chosen to balance the contribution of the different terms. We perform a simple grid search to find these coefficients and leave more advanced strategies for hyperparameter optimization to future work.\n\n"
        },
        {
            "id": "S4",
            "type": "text",
            "title": "4Numerical Results",
            "caption": "4Numerical Results",
            "metadata": {},
            "text": "\n4 Numerical Results\nWe test our framework on two commonly-studied, yet complex, baselines: (i) a double pendulum with an actuated joint, and (ii) a parametric reaction-diffusion system (see Figure 5). Both systems present chaotic dynamics, making their evolution over time hard to capture accurately.\n\nWe assume to have access only to high-dimensional and noisy measurements \ud835\udc31\ud835\udc31\\mathbf{x}bold_x of these systems. In our experiments, we aim to (a) denoise of the measurements, (b) learn compact and interpretable representations, (c) predict the systems\u2019 dynamics, and (d) quantify uncertainties.\n\nDenoising of Measurements. When dealing with noisy data, an aspect of paramount importance is the ability of the models to remove the noise from the data, that is, denoising. To test the denoising capabilities of our framework, we add Gaussian noise over the measurements:\n\n\ud835\udc31t=\ud835\udc31t+\u03f5\ud835\udc31\u03f5\ud835\udc31\u223c\ud835\udca9\u2062(\ud835\udfce,\u03c3\ud835\udc312\u2062I),subscript\ud835\udc31\ud835\udc61subscript\ud835\udc31\ud835\udc61subscriptbold-italic-\u03f5\ud835\udc31subscriptbold-italic-\u03f5\ud835\udc31similar-to\ud835\udca90subscriptsuperscript\ud835\udf0e2\ud835\udc31\ud835\udc3c\\begin{split}\\mathbf{x}_{t}&=\\mathbf{x}_{t}+\\boldsymbol{\\epsilon}_{\\mathbf{x}}%\n\\\\\n\\boldsymbol{\\epsilon}_{\\mathbf{x}}&\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}_{%\n\\mathbf{x}}I)\\,,\\\\\n\\end{split}start_ROW start_CELL bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_CELL start_CELL = bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + bold_italic_\u03f5 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL bold_italic_\u03f5 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT end_CELL start_CELL \u223c caligraphic_N ( bold_0 , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT italic_I ) , end_CELL end_ROW\n(20)\n\nwhere \u03c3\ud835\udc312\u2208{0.0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310.0superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0.0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0.0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT } corresponds to the variance. We aim at recovering the original measurements (see Figure 6 and 10). In addition, to provide a quantitative evaluation, we utilize the peak signal-to-noise ratio (PSNR) and the L1subscript\ud835\udc3f1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT norm to assess the denosing abilities of our method. The PSNR measures the ratio between the maximum possible power of a signal, i.e., max\u2061(\ud835\udc31t2)subscriptsuperscript\ud835\udc312\ud835\udc61\\max(\\mathbf{x}^{2}_{t})roman_max ( bold_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ), and the power of the corrupting noise, i.e., \u2016\ud835\udc31t\u2212\ud835\udc31^t\u201622superscriptsubscriptnormsubscript\ud835\udc31\ud835\udc61subscript^\ud835\udc31\ud835\udc6122||\\mathbf{x}_{t}-\\hat{\\mathbf{x}}_{t}||_{2}^{2}| | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The PSNR is defined as:\n\nPSNR=10\u22c5log10\u2061(max\u2061(\ud835\udc31t2)\u2016\ud835\udc31t\u2212\ud835\udc31^t\u201622),PSNR\u22c510subscript10superscriptsubscript\ud835\udc31\ud835\udc612superscriptsubscriptnormsubscript\ud835\udc31\ud835\udc61subscript^\ud835\udc31\ud835\udc6122\\text{PSNR}=10\\cdot\\log_{10}\\left(\\frac{\\max(\\mathbf{x}_{t}^{2})}{||\\mathbf{x}%\n_{t}-\\hat{\\mathbf{x}}_{t}||_{2}^{2}}\\right)\\,,PSNR = 10 \u22c5 roman_log start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ( divide start_ARG roman_max ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) end_ARG start_ARG | | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) ,\n(21)\n\nwhere \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT correspond to the (noisy) measurement and its reconstruction at a generic timestep t\ud835\udc61titalic_t, respectively. The L1subscript\ud835\udc3f1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT norm measures how close the recovered measurement \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is to the uncorrupted measurement \ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The L1subscript\ud835\udc3f1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT norm is the absolute difference between the original and reconstructed measurements:\n\nL1=\u2016\ud835\udc31t\u2212\ud835\udc31^t\u20161=|\ud835\udc31t\u2212\ud835\udc31^t|.subscript\ud835\udc3f1subscriptnormsubscript\ud835\udc31\ud835\udc61subscript^\ud835\udc31\ud835\udc611subscript\ud835\udc31\ud835\udc61subscript^\ud835\udc31\ud835\udc61L_{1}=||\\mathbf{x}_{t}-\\hat{\\mathbf{x}}_{t}||_{1}=|\\mathbf{x}_{t}-\\hat{\\mathbf%\n{x}}_{t}|.italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = | | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | .\n(22)\n\nWe report these results in Table 1 and 2.\n\nLearning Compact and Interpretable Representations. The second aspect we are interested in is assessing the ability of the framework to learn compact and interpretable latent representations of the system states. To visualize the latent (state) representations, we employ the t-distributed stochastic neighbor embedding (t-SNE) method [60] to project the latent states to a 2-dimensional space and inspect their correlation with the true state variables (see Figure 6 and 10).\n\nPredicting the Dynamics. The goal of our method is to learn a ROM that can accurately and efficiently predict the evolution of different dynamical systems. Therefore, after training the model, we evaluate its predictions forward in time by feeding the initial state to the ROM and autoregressively predict the trajectory of the systems. We then compare the predicted trajectories with the trajectories from a test set that were not used for the training of the model (see Figure 8 and 12.\n\nQuantifying Uncertainties. Ultimately, we would like to quantify uncertainties, deriving from the noisy measurements, properly. However, uncertainties over the latent variables are hard to visualize and, consequently analyze [41]. Therefore, we study uncertainties in the measurement space that can be more informative then uncertainties over the latent variables. We generate multiple rollouts of the ROM for a fixed initial condition, we decode the latent-space trajectories back to the measurement space using the decoder, we compute standard deviation of the different trajectories, and we plot heatmaps representing the evolution of the uncertainties over time (see Figure 9 and 13).\n\n4.1 Double Pendulum\nThe first example we consider is an actuated double pendulum. The double pendulum exhibits chaotic and nonlinear behavior, making the prediction of its dynamics from high-dimensional and noisy measurements extremely challenging. Its dynamics can be described as a function of its joint angles (\u03b81,\u03b82)subscript\ud835\udf031subscript\ud835\udf032(\\theta_{1},\\theta_{2})( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ), velocities (\u03b8\u02d91,\u03b8\u02d92)subscript\u02d9\ud835\udf031subscript\u02d9\ud835\udf032(\\dot{\\theta}_{1},\\dot{\\theta}_{2})( over\u02d9 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over\u02d9 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ), and accelerations (\u03b8\u00a81,\u03b8\u00a82)subscript\u00a8\ud835\udf031subscript\u00a8\ud835\udf032(\\ddot{\\theta}_{1},\\ddot{\\theta}_{2})( over\u00a8 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over\u00a8 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). We indicate with \u03b81,\u03b82subscript\ud835\udf031subscript\ud835\udf032\\theta_{1},\\theta_{2}italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT the angle of the first joint and second joint, l1,l2subscript\ud835\udc591subscript\ud835\udc592l_{1},l_{2}italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT the length of the two links, and m1,m2subscript\ud835\udc5a1subscript\ud835\udc5a2m_{1},m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT the mass of the two links. The equations of motions of the double pendulum can be written as in state-space form as:\n\n\u03b8\u02d91=\u03c91,\u03b8\u02d92=\u03c92,\u03c9\u02d91=\u2212g\u2062(2\u2062m1+m2)\u2062sin\u2061\u03b81\u2212m2\u2062g\u2062sin\u2061(\u03b81\u22122\u2062\u03b82)\u22122\u2062sin\u2061(\u03b81\u2212\u03b82)\u2062m2\u2062(\u03c922\u2062l2+\u03c912\u2062l1\u2062cos\u2061(\u03b81\u2212\u03b82))l1\u2062(2\u2062m1+m2\u2212m2\u2062cos\u2061(2\u2062\u03b81\u22122\u2062\u03b82))+u1,\u03c9\u02d92=2\u2062sin\u2061(\u03b81\u2212\u03b82)\u2062(\u03c912\u2062l1\u2062(m1+m2)+g\u2062(m1+m2)\u2062cos\u2061\u03b81+\u03c922\u2062l2\u2062m2\u2062cos\u2061(\u03b81\u2212\u03b82))l2\u2062(2\u2062m1+m2\u2212m2\u2062cos\u2061(2\u2062\u03b81\u22122\u2062\u03b82)),formulae-sequencesubscript\u02d9\ud835\udf031subscript\ud835\udf141formulae-sequencesubscript\u02d9\ud835\udf032subscript\ud835\udf142formulae-sequencesubscript\u02d9\ud835\udf141\ud835\udc542subscript\ud835\udc5a1subscript\ud835\udc5a2subscript\ud835\udf031subscript\ud835\udc5a2\ud835\udc54subscript\ud835\udf0312subscript\ud835\udf0322subscript\ud835\udf031subscript\ud835\udf032subscript\ud835\udc5a2superscriptsubscript\ud835\udf1422subscript\ud835\udc592superscriptsubscript\ud835\udf1412subscript\ud835\udc591subscript\ud835\udf031subscript\ud835\udf032subscript\ud835\udc5912subscript\ud835\udc5a1subscript\ud835\udc5a2subscript\ud835\udc5a22subscript\ud835\udf0312subscript\ud835\udf032subscript\ud835\udc621subscript\u02d9\ud835\udf1422subscript\ud835\udf031subscript\ud835\udf032superscriptsubscript\ud835\udf1412subscript\ud835\udc591subscript\ud835\udc5a1subscript\ud835\udc5a2\ud835\udc54subscript\ud835\udc5a1subscript\ud835\udc5a2subscript\ud835\udf031superscriptsubscript\ud835\udf1422subscript\ud835\udc592subscript\ud835\udc5a2subscript\ud835\udf031subscript\ud835\udf032subscript\ud835\udc5922subscript\ud835\udc5a1subscript\ud835\udc5a2subscript\ud835\udc5a22subscript\ud835\udf0312subscript\ud835\udf032\\begin{split}\\dot{\\theta}_{1}&=\\omega_{1}\\,,\\\\\n\\dot{\\theta}_{2}&=\\omega_{2}\\,,\\\\\n\\dot{\\omega}_{1}&=\\frac{-g(2m_{1}+m_{2})\\sin\\theta_{1}-m_{2}g\\sin(\\theta_{1}-2%\n\\theta_{2})-2\\sin(\\theta_{1}-\\theta_{2})m_{2}(\\omega_{2}^{2}l_{2}+\\omega_{1}^{%\n2}l_{1}\\cos(\\theta_{1}-\\theta_{2}))}{l_{1}(2m_{1}+m_{2}-m_{2}\\cos(2\\theta_{1}-%\n2\\theta_{2}))}+u_{1}\\,,\\\\\n\\dot{\\omega}_{2}&=\\frac{2\\sin(\\theta_{1}-\\theta_{2})(\\omega_{1}^{2}l_{1}(m_{1}%\n+m_{2})+g(m_{1}+m_{2})\\cos\\theta_{1}+\\omega_{2}^{2}l_{2}m_{2}\\cos(\\theta_{1}-%\n\\theta_{2}))}{l_{2}(2m_{1}+m_{2}-m_{2}\\cos(2\\theta_{1}-2\\theta_{2}))}\\,,\\\\\n\\end{split}start_ROW start_CELL over\u02d9 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL start_CELL = italic_\u03c9 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , end_CELL end_ROW start_ROW start_CELL over\u02d9 start_ARG italic_\u03b8 end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL start_CELL = italic_\u03c9 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , end_CELL end_ROW start_ROW start_CELL over\u02d9 start_ARG italic_\u03c9 end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL start_CELL = divide start_ARG - italic_g ( 2 italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) roman_sin italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_g roman_sin ( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 2 italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) - 2 roman_sin ( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_\u03c9 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_\u03c9 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT roman_cos ( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ) end_ARG start_ARG italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 2 italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_cos ( 2 italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 2 italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ) end_ARG + italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , end_CELL end_ROW start_ROW start_CELL over\u02d9 start_ARG italic_\u03c9 end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL start_CELL = divide start_ARG 2 roman_sin ( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_\u03c9 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) + italic_g ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) roman_cos italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u03c9 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_cos ( italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ) end_ARG start_ARG italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 2 italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_cos ( 2 italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 2 italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ) end_ARG , end_CELL end_ROW\n(23)\n\nwhere \u03c91subscript\ud835\udf141\\omega_{1}italic_\u03c9 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u03c92subscript\ud835\udf142\\omega_{2}italic_\u03c9 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are the angular velocities of the first and second link of the double pendulum, respectively, and u1subscript\ud835\udc621u_{1}italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT the control input (torque) to the first joint. The measurements \ud835\udc31\ud835\udc31\\mathbf{x}bold_x are high-dimensional snapshots of dimension 84\u00d784\u00d738484384\\times 84\\times 384 \u00d7 84 \u00d7 3 of the double pendulum dynamics (see Equation (23)) when a random control u1subscript\ud835\udc621u_{1}italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is applied. An example of measurement is shown in Figure 5 (left).\n\nIn Figure 6, we show the reconstructions \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \ud835\udc31^t+1subscript^\ud835\udc31\ud835\udc611\\hat{\\mathbf{x}}_{t+1}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT for different levels of noise of the measurements \u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }. In this case, we set the latent dimension |\ud835\udc33|=20\ud835\udc3320|\\mathbf{z}|=20| bold_z | = 20 and the history length H=20\ud835\udc3b20H=20italic_H = 20. As shown by the results, the model can properly denoise the noisy measurements, even in the case of high levels of noise (\u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).The ability to remove the noise from the measurements derives from the ability of the model to encode the relevant features into the latent state.\n\nTo further understand the effect of the recurrent SVDKL architecture on the prediction performance of the ROM, we quantitatively analyze, using the PSNR and L1 metric , the quality of the reconstructions \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \ud835\udc31^t+1subscript^\ud835\udc31\ud835\udc611\\hat{\\mathbf{x}}_{t+1}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT. The results for different values of H\ud835\udc3bHitalic_H, where H=1\ud835\udc3b1H=1italic_H = 1 corresponds to the original architecture proposed in [41], and noise variance \u03c3\ud835\udc312subscriptsuperscript\ud835\udf0e2\ud835\udc31\\sigma^{2}_{\\mathbf{x}}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT are reported in Table 1. Increasing the history length H\ud835\udc3bHitalic_H improves the encoding and latent model performance and consequently denoising abilities of the model, as shown by a higher PSNR and a lower L1subscript\ud835\udc3f1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT norm. However, due to the sequential nature of the LSTM, longer input sequences requires more computations and may slow down the training. We found that a value of H\u2208[10,20]\ud835\udc3b1020H\\in[10,20]italic_H \u2208 [ 10 , 20 ] provides a good trade-off between results and computational burden.\n\nIn Figure 7, we show the latent variables for different value of noise applied to the measurements. Due to the strong denoising capabilities of our model, the latent representations, visualized via t-SNE, are minimally affected and their correlation with the true variables of the systems, i.e. the angles \u03b81subscript\ud835\udf031\\theta_{1}italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u03b82subscript\ud835\udf032\\theta_{2}italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, remains high. Again, we show the results for |\ud835\udc33|=20\ud835\udc3320|\\mathbf{z}|=20| bold_z | = 20 and H=20\ud835\udc3b20H=20italic_H = 20.\n\nTo assess the prediction capability of the proposed ROM, we predict the dynamics forward in time from a history of measurements of length H\ud835\udc3bHitalic_H. In Figure 8, we show the reconstruction of the predicted trajectories in comparison with the true ones from the test set.\n\nThe reconstructions remain close to the true measurements, even with the highest noise level (\u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT) for the first 20 timesteps. Afterwards, especially in the noisy-measurement cases, we notice a gradual divergence. However, it is worth mentioning that the double pendulum is a chaotic systems and small perturbations of the initial conditions generate drastically different trajectories. Therefore, it is natural to observe this behavior, especially with additive noise on the measurements acting as a perturbation of the initial conditions.\n\nIn Figure 9, we show the uncertainty quantification capabilities of our framework by analyzing the uncertainties over the same trajectory with different noise levels (\u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0 and \u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).\n\nIt is possible to notice that the model is sensitive to the noise added to the measurements, as the standard deviation of the predicted trajectory grows with more noise, i.e., the pendulum position is more blurred in the case of \u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT than in the case of \u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0.\n\n\n4.2 Nonlinear Reaction-Diffusion Problem\nThe second example we consider is a lambda\u2013omega reaction\u2013diffusion system that can be used to describe a wide variety of physical phenomena, spanning from chemistry to biology and geology. The equations describing the dynamics can be written as:\n\nu\u02d9=(1\u2212(u2+v2))\u2062u+\u03b2\u2062(u2+v2)\u2062v+d\u2062(ux\u2062x,uy\u2062y),v\u02d9=\u03b2\u2062(u2+v2)\u2062u+(1\u2212(u2+v2))\u2062v+d\u2062(vx\u2062x,vy\u2062y),formulae-sequence\u02d9\ud835\udc621superscript\ud835\udc622superscript\ud835\udc632\ud835\udc62\ud835\udefdsuperscript\ud835\udc622superscript\ud835\udc632\ud835\udc63\ud835\udc51subscript\ud835\udc62\ud835\udc65\ud835\udc65subscript\ud835\udc62\ud835\udc66\ud835\udc66\u02d9\ud835\udc63\ud835\udefdsuperscript\ud835\udc622superscript\ud835\udc632\ud835\udc621superscript\ud835\udc622superscript\ud835\udc632\ud835\udc63\ud835\udc51subscript\ud835\udc63\ud835\udc65\ud835\udc65subscript\ud835\udc63\ud835\udc66\ud835\udc66\\begin{split}\\dot{u}&=(1-(u^{2}+v^{2}))u+\\beta(u^{2}+v^{2})v+d(u_{xx},u_{yy})%\n\\,,\\\\\n\\dot{v}&=\\beta(u^{2}+v^{2})u+(1-(u^{2}+v^{2}))v+d(v_{xx},v_{yy})\\,,\\\\\n\\end{split}start_ROW start_CELL over\u02d9 start_ARG italic_u end_ARG end_CELL start_CELL = ( 1 - ( italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_v start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ) italic_u + italic_\u03b2 ( italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_v start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) italic_v + italic_d ( italic_u start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT ) , end_CELL end_ROW start_ROW start_CELL over\u02d9 start_ARG italic_v end_ARG end_CELL start_CELL = italic_\u03b2 ( italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_v start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) italic_u + ( 1 - ( italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_v start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ) italic_v + italic_d ( italic_v start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT ) , end_CELL end_ROW\n(24)\n\nwhere u=u\u2062(x,y,t)\ud835\udc62\ud835\udc62\ud835\udc65\ud835\udc66\ud835\udc61u=u(x,y,t)italic_u = italic_u ( italic_x , italic_y , italic_t ) and v=v\u2062(x,y,t)\ud835\udc63\ud835\udc63\ud835\udc65\ud835\udc66\ud835\udc61v=v(x,y,t)italic_v = italic_v ( italic_x , italic_y , italic_t ) describe the evolution of the spiral wave over time in the spatial domain (x,y)\u2208[\u221210,10]\ud835\udc65\ud835\udc661010(x,y)\\in[-10,10]( italic_x , italic_y ) \u2208 [ - 10 , 10 ], and \u03b2\ud835\udefd\\betaitalic_\u03b2 and d\ud835\udc51ditalic_d are the parameters regulating the reaction and diffusion behavior of the system, respectively. Our parameter of interest is \u03b2\ud835\udefd\\betaitalic_\u03b2, varying in the range [0.5,1.5]0.51.5[0.5,1.5][ 0.5 , 1.5 ]. Similarly to [61], we assume periodic boundary conditions and initial condition equal to:\n\nu(x,y,0)=v(x,y,0)=tanh(x2+y2cos((x+iy)\u2212x2+y2).u(x,y,0)=v(x,y,0)=\\tanh(\\sqrt{x^{2}+y^{2}}\\cos((x+iy)-\\sqrt{x^{2}+y^{2}}).italic_u ( italic_x , italic_y , 0 ) = italic_v ( italic_x , italic_y , 0 ) = roman_tanh ( square-root start_ARG italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG roman_cos ( ( italic_x + italic_i italic_y ) - square-root start_ARG italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) .\n(25)\n\nIn this case, the measurements \ud835\udc31\ud835\udc31\\mathbf{x}bold_x are obtained by spatially discretizing the PDE with a 128\u00d7128128128128\\times 128128 \u00d7 128 grid.\n\nIn Figure 10, we show the reconstructions \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \ud835\udc31^t+1subscript^\ud835\udc31\ud835\udc611\\hat{\\mathbf{x}}_{t+1}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT for different levels of noise of the measurements \u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }. Similarly to the double pendulum example, we set the latent dimension |\ud835\udc33|=20\ud835\udc3320|\\mathbf{z}|=20| bold_z | = 20 and the history length H=20\ud835\udc3b20H=20italic_H = 20. As shown in Figure 10, the model can properly denoise the noisy measurements, even in the case of high levels of noise (\u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).\n\nSimilarly to the case of the double pendulum, we quantitatively analyze, using the PSNR and L1 metrics, the quality of the reconstructions \ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \ud835\udc31^t+1subscript^\ud835\udc31\ud835\udc611\\hat{\\mathbf{x}}_{t+1}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT. The results for different values of H\ud835\udc3bHitalic_H, where H=1\ud835\udc3b1H=1italic_H = 1 corresponds to the original architecture proposed in [41], and noise \u03c3\ud835\udc312subscriptsuperscript\ud835\udf0e2\ud835\udc31\\sigma^{2}_{\\mathbf{x}}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT are reported in Table 2. Even in the reaction-diffusion PDE, increasing the history length H\ud835\udc3bHitalic_H improves the encoding and latent model performance and consequently denoising abilities of the model.\n\nIn Figure 11, we show the latent variables for different value of noise applied to the measurements. Similarly to the pendulum example, due to the strong denoising capabilities of our model, the latent representations, visualized via t-SNE, are minimally affected by the noise. This aspect can be noticed by the fact that the latent representations do no qualitatively change for different levels of noise. Again, we show the results for |\ud835\udc33|=20\ud835\udc3320|\\mathbf{z}|=20| bold_z | = 20 and H=20\ud835\udc3b20H=20italic_H = 20.\n\nTo assess the prediction capability of the proposed ROM, we predict the dynamics forward in time from a history of measurements of length H\ud835\udc3bHitalic_H. In Figure 12, we show the reconstruction of the predicted trajectories in comparison with the true ones from the test set.\n\nThe reconstructions remain close to the true measurements, even with the highest noise level (\u03c3\ud835\udc312=0.52superscriptsubscript\ud835\udf0e\ud835\udc312superscript0.52\\sigma_{\\mathbf{x}}^{2}=0.5^{2}italic_\u03c3 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).\n\nIn Figure 13, we show the uncertainty quantification capabilities of our framework by analyzing the uncertainties over the same trajectory with different noise levels (\u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0 and \u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT).\n\nAgain, it is possible to notice that the model is sensitive to the noise added to the measurements, as the standard deviation of the predicted trajectory grows with more noise, i.e., the spiral is more blurred in the case of \u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT than in the case of \u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0.\n\n"
        },
        {
            "id": "S5",
            "type": "text",
            "title": "5Conclusion and Discussion",
            "caption": "5Conclusion and Discussion",
            "metadata": {},
            "text": "\n5 Conclusion and Discussion\nIn this paper, we introduced a recurrent SVDKL architecture for learning ROMs for chaotic dynamical systems from high-dimensional and noisy measurements. This novel approach extends the architecture proposed in [41] with a recurrent network and two multi-step loss functions to improve the reliability of the long-term predictions of the latent dynamical SVDKL model. The method was tested on an actuated double pendulum and a parametric reaction-diffusion PDE. Our method, in both test cases, is capable of properly denoising the measurement, learning interpretable latent representations, and consistently predicting the evolution of the systems. Eventually, we propose a way to visualize and analyze the uncertainties quantification capabilities of the framework.\n\nIn recent years, model and dimensionality reduction [23, 24, 25, 27, 28, 36, 37, 38], uncertainty quantification [5, 6, 7, 26], and measurement denoising [40, 42] have been essential aspects of the research in scientific machine learning. However, novel methods have been very often tailored for only one or two of these challenges at a time. Simultaneously tackling all these challenges is very difficult. To the best of our knowledge, the proposed method in this work is the first one capable of denoising high-dimensional measurements, reducing their dimensionality into interpretable latent spaces, predicting system evolution, and quantifying modeling uncertainties simultaneously, as shown in Section 4.\n"
        },
        {
            "id": "Sx1",
            "type": "text",
            "title": "Acknowledgments",
            "caption": "Acknowledgments",
            "metadata": {},
            "text": "\nAcknowledgments\nAM acknowledges the Project \u201cReduced Order Modeling and Deep Learning for the real- time approximation of PDEs (DREAM)\u201d (Starting Grant No. FIS00003154), funded by the Italian Science Fund (FIS) - Ministero dell\u2019Universit\u00e0 e della Ricerca and the project FAIR (Future Artificial Intelligence Research), funded by the NextGenerationEU program within the PNRR-PE-AI scheme (M4C2, Investment 1.3, Line on Artificial Intelligence). AM and PZ are members of the Gruppo Nazionale Calcolo Scientifico-Istituto Nazionale di Alta Matematica (GNCS-INdAM) and acknowledge the project \u201cDipartimento di Eccellenza\u201d 2023-2027, funded by MUR. This work was in part carried out when MG held a position at the University of Twente (NL), for which he acknowledges financial support from Sectorplan B\u00e8ta under the focus area Mathematics of Computational Science.\n"
        }
    ],
    "figure_chunks": [
        {
            "id": "S1.F1",
            "type": "figure",
            "title": "2405.19785v3_Figure1",
            "caption": "Figure 1:Proposed framework for reduced-order modeling of dynamical systems. We encode the measurements\ud835\udc31tsubscript\ud835\udc31\ud835\udc61\\mathbf{x}_{t}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTat different time instances into the latent variables\ud835\udc33tsubscript\ud835\udc33\ud835\udc61\\mathbf{z}_{t}bold_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTby means of a deep kernel learning encoder. Then, we feed a sequence of lengthH\ud835\udc3bHitalic_Hof consecutive latent variables\ud835\udc33t\u2212H:tsubscript\ud835\udc33:\ud835\udc61\ud835\udc3b\ud835\udc61\\mathbf{z}_{t-H:t}bold_z start_POSTSUBSCRIPT italic_t - italic_H : italic_t end_POSTSUBSCRIPT, actions\ud835\udc2et\u2212H:tsubscript\ud835\udc2e:\ud835\udc61\ud835\udc3b\ud835\udc61\\mathbf{u}_{t-H:t}bold_u start_POSTSUBSCRIPT italic_t - italic_H : italic_t end_POSTSUBSCRIPT, and parameters\ud835\udc29\ud835\udc29\\mathbf{p}bold_pto a recurrent deep kernel learning to predict the next latent variable\ud835\udc33t+1subscript\ud835\udc33\ud835\udc611\\mathbf{z}_{t+1}bold_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT. The measurements are then reconstructed\ud835\udc31^^\ud835\udc31\\hat{\\mathbf{x}}over^ start_ARG bold_x end_ARGby means of a decoder from the latent variables.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure1.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F2",
            "type": "figure",
            "title": "2405.19785v3_Figure2",
            "caption": "Figure 2:Architecture of the SVDKL encoder.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure2.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F3",
            "type": "figure",
            "title": "2405.19785v3_Figure3",
            "caption": "Figure 3:Architecture of the decoder.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure3.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F4",
            "type": "figure",
            "title": "2405.19785v3_Figure4",
            "caption": "Figure 4:Architecture of the forward dynamical model.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure4.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F5",
            "type": "figure",
            "title": "2405.19785v3_Figure5",
            "caption": "Figure 5:Double pendulum and reaction-diffusion systems.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure5.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F6",
            "type": "figure",
            "title": "2405.19785v3_Figure6",
            "caption": "Figure 6:Reconstructions of\ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTwith noise levels\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }applied to input measurements. The noise level increases from the top to the bottom images.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure6.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F7",
            "type": "figure",
            "title": "2405.19785v3_Figure7",
            "caption": "Figure 7:t-SNE visualization of the mean of the latent state distribution for different levels of noise\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }on the measurements, Figure a), b), and c), respectively. The first angle\u03b81subscript\ud835\udf031\\theta_{1}italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTis fixed within a range, while the color bar represents the second angle\u03b82subscript\ud835\udf032\\theta_{2}italic_\u03b8 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure7.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F8",
            "type": "figure",
            "title": "2405.19785v3_Figure8",
            "caption": "Figure 8:Predictions of the dynamic\ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT(purple box) for different noise levels\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }applied to input measurements (blue box). The true trajectory is highlighted by the green box.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure8.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F9",
            "type": "figure",
            "title": "2405.19785v3_Figure9",
            "caption": "Figure 9:Evolution over time of the standard deviation of the trajectories projected in the image space for\u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0and\u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure9.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F10",
            "type": "figure",
            "title": "2405.19785v3_Figure10",
            "caption": "Figure 10:Reconstructions of\ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTwith noise levels\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }applied to input measurements. The noise level increases from the top to the bottom images.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure10.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F11",
            "type": "figure",
            "title": "2405.19785v3_Figure11",
            "caption": "Figure 11:t-SNE visualization of the mean of the latent state distribution for different levels of noise\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }on the measurements, Figure a), b), and c), respectively. The colorbar represents the timesteps.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure11.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F12",
            "type": "figure",
            "title": "2405.19785v3_Figure12",
            "caption": "Figure 12:Predictions of the dynamic\ud835\udc31^tsubscript^\ud835\udc31\ud835\udc61\\hat{\\mathbf{x}}_{t}over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT(purple box) for different noise levels\u03c3\ud835\udc312\u2208{0,0.252,0.52}subscriptsuperscript\ud835\udf0e2\ud835\udc310superscript0.252superscript0.52\\sigma^{2}_{\\mathbf{x}}\\in\\{0,0.25^{2},0.5^{2}\\}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT \u2208 { 0 , 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT }applied to input measurements (blue box). The true trajectory is highlighted by the green box.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure12.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F13",
            "type": "figure",
            "title": "2405.19785v3_Figure13",
            "caption": "Figure 13:Evolution over time of the standard deviation of the trajectories projected in the image space for\u03c3\ud835\udc312=0.0subscriptsuperscript\ud835\udf0e2\ud835\udc310.0\\sigma^{2}_{\\mathbf{x}}=0.0italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0and\u03c3\ud835\udc312=0.52subscriptsuperscript\ud835\udf0e2\ud835\udc31superscript0.52\\sigma^{2}_{\\mathbf{x}}=0.5^{2}italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19785v3_Figure13.png",
            "alt_text": "Refer to caption"
        }
    ],
    "table_chunks": [
        {
            "id": "S4.T1",
            "type": "table",
            "title": "2405.19785v3_Table1",
            "caption": "Table 1:Quantitative results in the case of the double pendulum for different values ofH\ud835\udc3bHitalic_H. All the models are trained using the loss function in Equation (19) withT=3\ud835\udc473T=3italic_T = 3.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.23\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.2.2.3\" style=\"padding-bottom:2.15277pt;\">Noise Level</th>\n<th class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.1\" style=\"padding-bottom:2.15277pt;\">Reconstruction <math alttext=\"\\hat{\\mathbf{x}}_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.1.1.1.m1.1\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><msub id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"><mover accent=\"true\" id=\"S4.T1.1.1.1.m1.1.1.2\" xref=\"S4.T1.1.1.1.m1.1.1.2.cmml\"><mi id=\"S4.T1.1.1.1.m1.1.1.2.2\" xref=\"S4.T1.1.1.1.m1.1.1.2.2.cmml\">\ud835\udc31</mi><mo id=\"S4.T1.1.1.1.m1.1.1.2.1\" xref=\"S4.T1.1.1.1.m1.1.1.2.1.cmml\">^</mo></mover><mi id=\"S4.T1.1.1.1.m1.1.1.3\" xref=\"S4.T1.1.1.1.m1.1.1.3.cmml\">t</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><apply id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">subscript</csymbol><apply id=\"S4.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2\"><ci id=\"S4.T1.1.1.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.1\">^</ci><ci id=\"S4.T1.1.1.1.m1.1.1.2.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.2\">\ud835\udc31</ci></apply><ci id=\"S4.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.3\">\ud835\udc61</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\hat{\\mathbf{x}}_{t}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.1.1.1.m1.1d\">over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t\" id=\"S4.T1.2.2.2\" style=\"padding-bottom:2.15277pt;\">Reconstruction <math alttext=\"\\hat{\\mathbf{x}}_{t+1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.2.2.2.m1.1\"><semantics id=\"S4.T1.2.2.2.m1.1a\"><msub id=\"S4.T1.2.2.2.m1.1.1\" xref=\"S4.T1.2.2.2.m1.1.1.cmml\"><mover accent=\"true\" id=\"S4.T1.2.2.2.m1.1.1.2\" xref=\"S4.T1.2.2.2.m1.1.1.2.cmml\"><mi id=\"S4.T1.2.2.2.m1.1.1.2.2\" xref=\"S4.T1.2.2.2.m1.1.1.2.2.cmml\">\ud835\udc31</mi><mo id=\"S4.T1.2.2.2.m1.1.1.2.1\" xref=\"S4.T1.2.2.2.m1.1.1.2.1.cmml\">^</mo></mover><mrow id=\"S4.T1.2.2.2.m1.1.1.3\" xref=\"S4.T1.2.2.2.m1.1.1.3.cmml\"><mi id=\"S4.T1.2.2.2.m1.1.1.3.2\" xref=\"S4.T1.2.2.2.m1.1.1.3.2.cmml\">t</mi><mo id=\"S4.T1.2.2.2.m1.1.1.3.1\" xref=\"S4.T1.2.2.2.m1.1.1.3.1.cmml\">+</mo><mn id=\"S4.T1.2.2.2.m1.1.1.3.3\" xref=\"S4.T1.2.2.2.m1.1.1.3.3.cmml\">1</mn></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.m1.1b\"><apply id=\"S4.T1.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1\">subscript</csymbol><apply id=\"S4.T1.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.2\"><ci id=\"S4.T1.2.2.2.m1.1.1.2.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.2.1\">^</ci><ci id=\"S4.T1.2.2.2.m1.1.1.2.2.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.2.2\">\ud835\udc31</ci></apply><apply id=\"S4.T1.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.3\"><plus id=\"S4.T1.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.3.1\"></plus><ci id=\"S4.T1.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T1.2.2.2.m1.1.1.3.2\">\ud835\udc61</ci><cn id=\"S4.T1.2.2.2.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T1.2.2.2.m1.1.1.3.3\">1</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.m1.1c\">\\hat{\\mathbf{x}}_{t+1}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.2.2.2.m1.1d\">over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T1.3.3.1\"><math alttext=\"\\sigma^{2}_{\\mathbf{x}}=0.0\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.3.3.1.m1.1\"><semantics id=\"S4.T1.3.3.1.m1.1a\"><mrow id=\"S4.T1.3.3.1.m1.1.1\" xref=\"S4.T1.3.3.1.m1.1.1.cmml\"><msubsup id=\"S4.T1.3.3.1.m1.1.1.2\" xref=\"S4.T1.3.3.1.m1.1.1.2.cmml\"><mi id=\"S4.T1.3.3.1.m1.1.1.2.2.2\" xref=\"S4.T1.3.3.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T1.3.3.1.m1.1.1.2.3\" xref=\"S4.T1.3.3.1.m1.1.1.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T1.3.3.1.m1.1.1.2.2.3\" xref=\"S4.T1.3.3.1.m1.1.1.2.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T1.3.3.1.m1.1.1.1\" xref=\"S4.T1.3.3.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T1.3.3.1.m1.1.1.3\" xref=\"S4.T1.3.3.1.m1.1.1.3.cmml\">0.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.1.m1.1b\"><apply id=\"S4.T1.3.3.1.m1.1.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1\"><eq id=\"S4.T1.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.1\"></eq><apply id=\"S4.T1.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.3.3.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2\">subscript</csymbol><apply id=\"S4.T1.3.3.1.m1.1.1.2.2.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.3.3.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2\">superscript</csymbol><ci id=\"S4.T1.3.3.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><cn id=\"S4.T1.3.3.1.m1.1.1.2.2.3.cmml\" type=\"integer\" xref=\"S4.T1.3.3.1.m1.1.1.2.2.3\">2</cn></apply><ci id=\"S4.T1.3.3.1.m1.1.1.2.3.cmml\" xref=\"S4.T1.3.3.1.m1.1.1.2.3\">\ud835\udc31</ci></apply><cn id=\"S4.T1.3.3.1.m1.1.1.3.cmml\" type=\"float\" xref=\"S4.T1.3.3.1.m1.1.1.3\">0.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.1.m1.1c\">\\sigma^{2}_{\\mathbf{x}}=0.0</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.3.3.1.m1.1d\">italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.0</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.6.6.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.6.6.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.2.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.4.4.2.1.1.1.m1.1\"><semantics id=\"S4.T1.4.4.2.1.1.1.m1.1a\"><mi id=\"S4.T1.4.4.2.1.1.1.m1.1.1\" xref=\"S4.T1.4.4.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.2.1.1.1.m1.1b\"><ci id=\"S4.T1.4.4.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.4.4.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.4.4.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.5.5.3.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.5.5.3.2.2.2.m1.1\"><semantics id=\"S4.T1.5.5.3.2.2.2.m1.1a\"><mi id=\"S4.T1.5.5.3.2.2.2.m1.1.1\" xref=\"S4.T1.5.5.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.5.5.3.2.2.2.m1.1b\"><ci id=\"S4.T1.5.5.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.5.5.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.5.5.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.5.5.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.6.6.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.6.6.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.6.6.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.4.3.4.3\">29.12</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.4.3.4.4\">53.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.5.3\">33.20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.5.4\">22.25</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.6.3\">31.89</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.4.3.6.4\">22.71</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_rr ltx_border_tt\" id=\"S4.T1.9.9.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.9.9.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.7.5.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.7.7.5.1.1.1.m1.1\"><semantics id=\"S4.T1.7.7.5.1.1.1.m1.1a\"><mi id=\"S4.T1.7.7.5.1.1.1.m1.1.1\" xref=\"S4.T1.7.7.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.7.7.5.1.1.1.m1.1b\"><ci id=\"S4.T1.7.7.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.7.7.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.7.7.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.7.7.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.8.8.6.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.8.8.6.2.2.2.m1.1\"><semantics id=\"S4.T1.8.8.6.2.2.2.m1.1a\"><mi id=\"S4.T1.8.8.6.2.2.2.m1.1.1\" xref=\"S4.T1.8.8.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.8.8.6.2.2.2.m1.1b\"><ci id=\"S4.T1.8.8.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.8.8.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.8.8.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.8.8.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.9.9.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.9.9.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.9.9.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.7.3.4.3\">21.72</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.7.3.4.4\">208.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.5.3\">31.33</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.5.4\">32.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.6.3\">30.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.9.9.7.3.6.4\">37.50</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.10.10.1\"><math alttext=\"\\sigma^{2}_{\\mathbf{x}}=0.25^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.10.10.1.m1.1\"><semantics id=\"S4.T1.10.10.1.m1.1a\"><mrow id=\"S4.T1.10.10.1.m1.1.1\" xref=\"S4.T1.10.10.1.m1.1.1.cmml\"><msubsup id=\"S4.T1.10.10.1.m1.1.1.2\" xref=\"S4.T1.10.10.1.m1.1.1.2.cmml\"><mi id=\"S4.T1.10.10.1.m1.1.1.2.2.2\" xref=\"S4.T1.10.10.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T1.10.10.1.m1.1.1.2.3\" xref=\"S4.T1.10.10.1.m1.1.1.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T1.10.10.1.m1.1.1.2.2.3\" xref=\"S4.T1.10.10.1.m1.1.1.2.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T1.10.10.1.m1.1.1.1\" xref=\"S4.T1.10.10.1.m1.1.1.1.cmml\">=</mo><msup id=\"S4.T1.10.10.1.m1.1.1.3\" xref=\"S4.T1.10.10.1.m1.1.1.3.cmml\"><mn id=\"S4.T1.10.10.1.m1.1.1.3.2\" xref=\"S4.T1.10.10.1.m1.1.1.3.2.cmml\">0.25</mn><mn id=\"S4.T1.10.10.1.m1.1.1.3.3\" xref=\"S4.T1.10.10.1.m1.1.1.3.3.cmml\">2</mn></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.10.10.1.m1.1b\"><apply id=\"S4.T1.10.10.1.m1.1.1.cmml\" xref=\"S4.T1.10.10.1.m1.1.1\"><eq id=\"S4.T1.10.10.1.m1.1.1.1.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.1\"></eq><apply id=\"S4.T1.10.10.1.m1.1.1.2.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.10.10.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2\">subscript</csymbol><apply id=\"S4.T1.10.10.1.m1.1.1.2.2.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.10.10.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2\">superscript</csymbol><ci id=\"S4.T1.10.10.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><cn id=\"S4.T1.10.10.1.m1.1.1.2.2.3.cmml\" type=\"integer\" xref=\"S4.T1.10.10.1.m1.1.1.2.2.3\">2</cn></apply><ci id=\"S4.T1.10.10.1.m1.1.1.2.3.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.2.3\">\ud835\udc31</ci></apply><apply id=\"S4.T1.10.10.1.m1.1.1.3.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T1.10.10.1.m1.1.1.3.1.cmml\" xref=\"S4.T1.10.10.1.m1.1.1.3\">superscript</csymbol><cn id=\"S4.T1.10.10.1.m1.1.1.3.2.cmml\" type=\"float\" xref=\"S4.T1.10.10.1.m1.1.1.3.2\">0.25</cn><cn id=\"S4.T1.10.10.1.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T1.10.10.1.m1.1.1.3.3\">2</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.10.10.1.m1.1c\">\\sigma^{2}_{\\mathbf{x}}=0.25^{2}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.10.10.1.m1.1d\">italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.13.13.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.13.13.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.13.13.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.2.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.11.11.2.1.1.1.m1.1\"><semantics id=\"S4.T1.11.11.2.1.1.1.m1.1a\"><mi id=\"S4.T1.11.11.2.1.1.1.m1.1.1\" xref=\"S4.T1.11.11.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.11.11.2.1.1.1.m1.1b\"><ci id=\"S4.T1.11.11.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.11.11.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.11.11.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.11.11.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.3.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.12.12.3.2.2.2.m1.1\"><semantics id=\"S4.T1.12.12.3.2.2.2.m1.1a\"><mi id=\"S4.T1.12.12.3.2.2.2.m1.1.1\" xref=\"S4.T1.12.12.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.12.12.3.2.2.2.m1.1b\"><ci id=\"S4.T1.12.12.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.12.12.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.12.12.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.12.12.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.13.13.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.13.13.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.13.13.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.13.13.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.13.13.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.13.13.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.13.13.4.3.4.3\">26.97</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.13.13.4.3.4.4\">86.15</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.13.13.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.5.3\">29.26</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.5.4\">62.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.13.13.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.6.3\">29.45</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4.3.6.4\">60.14</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_rr ltx_border_t\" id=\"S4.T1.16.16.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.16.16.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.5.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.14.14.5.1.1.1.m1.1\"><semantics id=\"S4.T1.14.14.5.1.1.1.m1.1a\"><mi id=\"S4.T1.14.14.5.1.1.1.m1.1.1\" xref=\"S4.T1.14.14.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.14.14.5.1.1.1.m1.1b\"><ci id=\"S4.T1.14.14.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.14.14.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.14.14.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.14.14.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.6.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.15.15.6.2.2.2.m1.1\"><semantics id=\"S4.T1.15.15.6.2.2.2.m1.1a\"><mi id=\"S4.T1.15.15.6.2.2.2.m1.1.1\" xref=\"S4.T1.15.15.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.15.15.6.2.2.2.m1.1b\"><ci id=\"S4.T1.15.15.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.15.15.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.15.15.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.15.15.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.16.16.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.16.16.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.16.16.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.16.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.16.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.16.7.3.4.3\">22.98</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.16.7.3.4.4\">180.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.5.3\">28.19</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.5.4\">74.69</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.6.3\">28.44</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.7.3.6.4\">72.55</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.17.17.1\"><math alttext=\"\\sigma^{2}_{\\mathbf{x}}=0.5^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.17.17.1.m1.1\"><semantics id=\"S4.T1.17.17.1.m1.1a\"><mrow id=\"S4.T1.17.17.1.m1.1.1\" xref=\"S4.T1.17.17.1.m1.1.1.cmml\"><msubsup id=\"S4.T1.17.17.1.m1.1.1.2\" xref=\"S4.T1.17.17.1.m1.1.1.2.cmml\"><mi id=\"S4.T1.17.17.1.m1.1.1.2.2.2\" xref=\"S4.T1.17.17.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T1.17.17.1.m1.1.1.2.3\" xref=\"S4.T1.17.17.1.m1.1.1.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T1.17.17.1.m1.1.1.2.2.3\" xref=\"S4.T1.17.17.1.m1.1.1.2.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T1.17.17.1.m1.1.1.1\" xref=\"S4.T1.17.17.1.m1.1.1.1.cmml\">=</mo><msup id=\"S4.T1.17.17.1.m1.1.1.3\" xref=\"S4.T1.17.17.1.m1.1.1.3.cmml\"><mn id=\"S4.T1.17.17.1.m1.1.1.3.2\" xref=\"S4.T1.17.17.1.m1.1.1.3.2.cmml\">0.5</mn><mn id=\"S4.T1.17.17.1.m1.1.1.3.3\" xref=\"S4.T1.17.17.1.m1.1.1.3.3.cmml\">2</mn></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.17.17.1.m1.1b\"><apply id=\"S4.T1.17.17.1.m1.1.1.cmml\" xref=\"S4.T1.17.17.1.m1.1.1\"><eq id=\"S4.T1.17.17.1.m1.1.1.1.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.1\"></eq><apply id=\"S4.T1.17.17.1.m1.1.1.2.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.17.17.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2\">subscript</csymbol><apply id=\"S4.T1.17.17.1.m1.1.1.2.2.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T1.17.17.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2\">superscript</csymbol><ci id=\"S4.T1.17.17.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><cn id=\"S4.T1.17.17.1.m1.1.1.2.2.3.cmml\" type=\"integer\" xref=\"S4.T1.17.17.1.m1.1.1.2.2.3\">2</cn></apply><ci id=\"S4.T1.17.17.1.m1.1.1.2.3.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.2.3\">\ud835\udc31</ci></apply><apply id=\"S4.T1.17.17.1.m1.1.1.3.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T1.17.17.1.m1.1.1.3.1.cmml\" xref=\"S4.T1.17.17.1.m1.1.1.3\">superscript</csymbol><cn id=\"S4.T1.17.17.1.m1.1.1.3.2.cmml\" type=\"float\" xref=\"S4.T1.17.17.1.m1.1.1.3.2\">0.5</cn><cn id=\"S4.T1.17.17.1.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T1.17.17.1.m1.1.1.3.3\">2</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.17.17.1.m1.1c\">\\sigma^{2}_{\\mathbf{x}}=0.5^{2}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.17.17.1.m1.1d\">italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.20.20.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.20.20.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.20.20.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.18.18.2.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.18.18.2.1.1.1.m1.1\"><semantics id=\"S4.T1.18.18.2.1.1.1.m1.1a\"><mi id=\"S4.T1.18.18.2.1.1.1.m1.1.1\" xref=\"S4.T1.18.18.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.18.18.2.1.1.1.m1.1b\"><ci id=\"S4.T1.18.18.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.18.18.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.18.18.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.18.18.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.19.19.3.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.19.19.3.2.2.2.m1.1\"><semantics id=\"S4.T1.19.19.3.2.2.2.m1.1a\"><mi id=\"S4.T1.19.19.3.2.2.2.m1.1.1\" xref=\"S4.T1.19.19.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.19.19.3.2.2.2.m1.1b\"><ci id=\"S4.T1.19.19.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.19.19.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.19.19.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.19.19.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.20.20.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.20.20.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.20.20.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.20.20.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.20.20.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.20.20.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.20.20.4.3.4.3\">23.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.20.20.4.3.4.4\">179.97</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.20.20.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.5.3\">24.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.5.4\">155.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.20.20.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.6.3\">24.77</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.4.3.6.4\">150.84</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_rr ltx_border_t\" id=\"S4.T1.23.23.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.23.23.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.21.21.5.1.1.1\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.21.21.5.1.1.1.m1.1\"><semantics id=\"S4.T1.21.21.5.1.1.1.m1.1a\"><mi id=\"S4.T1.21.21.5.1.1.1.m1.1.1\" xref=\"S4.T1.21.21.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.21.21.5.1.1.1.m1.1b\"><ci id=\"S4.T1.21.21.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.21.21.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.21.21.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.21.21.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.22.22.6.2.2.2\" style=\"padding-bottom:1.07639pt;\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.22.22.6.2.2.2.m1.1\"><semantics id=\"S4.T1.22.22.6.2.2.2.m1.1a\"><mi id=\"S4.T1.22.22.6.2.2.2.m1.1.1\" xref=\"S4.T1.22.22.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.22.22.6.2.2.2.m1.1b\"><ci id=\"S4.T1.22.22.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.22.22.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.22.22.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.22.22.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.3.4\" style=\"padding-bottom:1.07639pt;\"><span class=\"ltx_text\" id=\"S4.T1.23.23.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.3.3\" style=\"padding-bottom:1.07639pt;\">\n<span class=\"ltx_text\" id=\"S4.T1.23.23.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T1.23.23.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.23.23.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.23.23.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.23.23.7.3.4.3\">20.23</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.23.23.7.3.4.4\">322.15</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.5.3\">24.46</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.5.4\">159.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.6.3\">24.59</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.7.3.6.4\">156.12</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S4.T2",
            "type": "table",
            "title": "2405.19785v3_Table2",
            "caption": "Table 2:Quantitative results in the case of the reaction-diffusion PDE for different values ofH\ud835\udc3bHitalic_H. All the models are trained using the loss function in Equation (19) withT=3\ud835\udc473T=3italic_T = 3.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.23\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T2.2.2.3\"></th>\n<th class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.1\">State reconstruction <math alttext=\"\\hat{\\mathbf{x}}_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.1.1.1.m1.1\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><msub id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\"><mover accent=\"true\" id=\"S4.T2.1.1.1.m1.1.1.2\" xref=\"S4.T2.1.1.1.m1.1.1.2.cmml\"><mi id=\"S4.T2.1.1.1.m1.1.1.2.2\" xref=\"S4.T2.1.1.1.m1.1.1.2.2.cmml\">\ud835\udc31</mi><mo id=\"S4.T2.1.1.1.m1.1.1.2.1\" xref=\"S4.T2.1.1.1.m1.1.1.2.1.cmml\">^</mo></mover><mi id=\"S4.T2.1.1.1.m1.1.1.3\" xref=\"S4.T2.1.1.1.m1.1.1.3.cmml\">t</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><apply id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">subscript</csymbol><apply id=\"S4.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.2\"><ci id=\"S4.T2.1.1.1.m1.1.1.2.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.2.1\">^</ci><ci id=\"S4.T2.1.1.1.m1.1.1.2.2.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.2.2\">\ud835\udc31</ci></apply><ci id=\"S4.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.3\">\ud835\udc61</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\hat{\\mathbf{x}}_{t}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.1.1.1.m1.1d\">over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t\" id=\"S4.T2.2.2.2\">Next state reconstruction <math alttext=\"\\hat{\\mathbf{x}}_{t+1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.2.2.2.m1.1\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><msub id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\"><mover accent=\"true\" id=\"S4.T2.2.2.2.m1.1.1.2\" xref=\"S4.T2.2.2.2.m1.1.1.2.cmml\"><mi id=\"S4.T2.2.2.2.m1.1.1.2.2\" xref=\"S4.T2.2.2.2.m1.1.1.2.2.cmml\">\ud835\udc31</mi><mo id=\"S4.T2.2.2.2.m1.1.1.2.1\" xref=\"S4.T2.2.2.2.m1.1.1.2.1.cmml\">^</mo></mover><mrow id=\"S4.T2.2.2.2.m1.1.1.3\" xref=\"S4.T2.2.2.2.m1.1.1.3.cmml\"><mi id=\"S4.T2.2.2.2.m1.1.1.3.2\" xref=\"S4.T2.2.2.2.m1.1.1.3.2.cmml\">t</mi><mo id=\"S4.T2.2.2.2.m1.1.1.3.1\" xref=\"S4.T2.2.2.2.m1.1.1.3.1.cmml\">+</mo><mn id=\"S4.T2.2.2.2.m1.1.1.3.3\" xref=\"S4.T2.2.2.2.m1.1.1.3.3.cmml\">1</mn></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><apply id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">subscript</csymbol><apply id=\"S4.T2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.2\"><ci id=\"S4.T2.2.2.2.m1.1.1.2.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.2.1\">^</ci><ci id=\"S4.T2.2.2.2.m1.1.1.2.2.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.2.2\">\ud835\udc31</ci></apply><apply id=\"S4.T2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.3\"><plus id=\"S4.T2.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.3.1\"></plus><ci id=\"S4.T2.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.3.2\">\ud835\udc61</ci><cn id=\"S4.T2.2.2.2.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T2.2.2.2.m1.1.1.3.3\">1</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">\\hat{\\mathbf{x}}_{t+1}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.2.2.2.m1.1d\">over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.9.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T2.3.3.1\"><math alttext=\"\\sigma_{\\mathbf{x}}^{2}=0.0\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.3.3.1.m1.1\"><semantics id=\"S4.T2.3.3.1.m1.1a\"><mrow id=\"S4.T2.3.3.1.m1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.cmml\"><msubsup id=\"S4.T2.3.3.1.m1.1.1.2\" xref=\"S4.T2.3.3.1.m1.1.1.2.cmml\"><mi id=\"S4.T2.3.3.1.m1.1.1.2.2.2\" xref=\"S4.T2.3.3.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T2.3.3.1.m1.1.1.2.2.3\" xref=\"S4.T2.3.3.1.m1.1.1.2.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T2.3.3.1.m1.1.1.2.3\" xref=\"S4.T2.3.3.1.m1.1.1.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T2.3.3.1.m1.1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.3.3.1.m1.1.1.3\" xref=\"S4.T2.3.3.1.m1.1.1.3.cmml\">0.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.1.m1.1b\"><apply id=\"S4.T2.3.3.1.m1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1\"><eq id=\"S4.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.1\"></eq><apply id=\"S4.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.3.3.1.m1.1.1.2.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\">superscript</csymbol><apply id=\"S4.T2.3.3.1.m1.1.1.2.2.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.3.3.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\">subscript</csymbol><ci id=\"S4.T2.3.3.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><ci id=\"S4.T2.3.3.1.m1.1.1.2.2.3.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2.2.3\">\ud835\udc31</ci></apply><cn id=\"S4.T2.3.3.1.m1.1.1.2.3.cmml\" type=\"integer\" xref=\"S4.T2.3.3.1.m1.1.1.2.3\">2</cn></apply><cn id=\"S4.T2.3.3.1.m1.1.1.3.cmml\" type=\"float\" xref=\"S4.T2.3.3.1.m1.1.1.3\">0.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.1.m1.1c\">\\sigma_{\\mathbf{x}}^{2}=0.0</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.3.3.1.m1.1d\">italic_\u03c3 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.0</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T2.6.6.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.6.6.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.2.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.4.4.2.1.1.1.m1.1\"><semantics id=\"S4.T2.4.4.2.1.1.1.m1.1a\"><mi id=\"S4.T2.4.4.2.1.1.1.m1.1.1\" xref=\"S4.T2.4.4.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.4.2.1.1.1.m1.1b\"><ci id=\"S4.T2.4.4.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.4.4.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.4.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.4.4.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.5.5.3.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.5.5.3.2.2.2.m1.1\"><semantics id=\"S4.T2.5.5.3.2.2.2.m1.1a\"><mi id=\"S4.T2.5.5.3.2.2.2.m1.1.1\" xref=\"S4.T2.5.5.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.5.3.2.2.2.m1.1b\"><ci id=\"S4.T2.5.5.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.5.5.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.5.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.5.5.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.6.6.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.6.6.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.6.6.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.4.3.4.3\">29.32</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.4.3.4.4\">347.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.5.3\">29.29</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.5.4\">360.26</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.6.3\">29.34</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.4.3.6.4\">342.73</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_rr ltx_border_tt\" id=\"S4.T2.9.9.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.9.9.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.9.9.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.7.7.5.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.7.7.5.1.1.1.m1.1\"><semantics id=\"S4.T2.7.7.5.1.1.1.m1.1a\"><mi id=\"S4.T2.7.7.5.1.1.1.m1.1.1\" xref=\"S4.T2.7.7.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.7.7.5.1.1.1.m1.1b\"><ci id=\"S4.T2.7.7.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.7.7.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.7.7.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.7.7.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.8.8.6.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.8.8.6.2.2.2.m1.1\"><semantics id=\"S4.T2.8.8.6.2.2.2.m1.1a\"><mi id=\"S4.T2.8.8.6.2.2.2.m1.1.1\" xref=\"S4.T2.8.8.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.8.8.6.2.2.2.m1.1b\"><ci id=\"S4.T2.8.8.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.8.8.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.8.8.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.8.8.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.9.9.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.9.9.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.9.9.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.9.9.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.9.9.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.9.9.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.9.9.7.3.4.3\">29.30</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.9.9.7.3.4.4\">352.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.9.9.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.5.3\">29.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.5.4\">401.94</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.9.9.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.6.3\">29.31</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.7.3.6.4\">344.89</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T2.10.10.1\"><math alttext=\"\\sigma_{\\mathbf{x}}^{2}=0.25^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.10.10.1.m1.1\"><semantics id=\"S4.T2.10.10.1.m1.1a\"><mrow id=\"S4.T2.10.10.1.m1.1.1\" xref=\"S4.T2.10.10.1.m1.1.1.cmml\"><msubsup id=\"S4.T2.10.10.1.m1.1.1.2\" xref=\"S4.T2.10.10.1.m1.1.1.2.cmml\"><mi id=\"S4.T2.10.10.1.m1.1.1.2.2.2\" xref=\"S4.T2.10.10.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T2.10.10.1.m1.1.1.2.2.3\" xref=\"S4.T2.10.10.1.m1.1.1.2.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T2.10.10.1.m1.1.1.2.3\" xref=\"S4.T2.10.10.1.m1.1.1.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T2.10.10.1.m1.1.1.1\" xref=\"S4.T2.10.10.1.m1.1.1.1.cmml\">=</mo><msup id=\"S4.T2.10.10.1.m1.1.1.3\" xref=\"S4.T2.10.10.1.m1.1.1.3.cmml\"><mn id=\"S4.T2.10.10.1.m1.1.1.3.2\" xref=\"S4.T2.10.10.1.m1.1.1.3.2.cmml\">0.25</mn><mn id=\"S4.T2.10.10.1.m1.1.1.3.3\" xref=\"S4.T2.10.10.1.m1.1.1.3.3.cmml\">2</mn></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.10.10.1.m1.1b\"><apply id=\"S4.T2.10.10.1.m1.1.1.cmml\" xref=\"S4.T2.10.10.1.m1.1.1\"><eq id=\"S4.T2.10.10.1.m1.1.1.1.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.1\"></eq><apply id=\"S4.T2.10.10.1.m1.1.1.2.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.10.10.1.m1.1.1.2.1.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2\">superscript</csymbol><apply id=\"S4.T2.10.10.1.m1.1.1.2.2.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.10.10.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2\">subscript</csymbol><ci id=\"S4.T2.10.10.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><ci id=\"S4.T2.10.10.1.m1.1.1.2.2.3.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.2.2.3\">\ud835\udc31</ci></apply><cn id=\"S4.T2.10.10.1.m1.1.1.2.3.cmml\" type=\"integer\" xref=\"S4.T2.10.10.1.m1.1.1.2.3\">2</cn></apply><apply id=\"S4.T2.10.10.1.m1.1.1.3.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T2.10.10.1.m1.1.1.3.1.cmml\" xref=\"S4.T2.10.10.1.m1.1.1.3\">superscript</csymbol><cn id=\"S4.T2.10.10.1.m1.1.1.3.2.cmml\" type=\"float\" xref=\"S4.T2.10.10.1.m1.1.1.3.2\">0.25</cn><cn id=\"S4.T2.10.10.1.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T2.10.10.1.m1.1.1.3.3\">2</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.10.10.1.m1.1c\">\\sigma_{\\mathbf{x}}^{2}=0.25^{2}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.10.10.1.m1.1d\">italic_\u03c3 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.25 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.13.13.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.13.13.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.13.13.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.11.11.2.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.11.11.2.1.1.1.m1.1\"><semantics id=\"S4.T2.11.11.2.1.1.1.m1.1a\"><mi id=\"S4.T2.11.11.2.1.1.1.m1.1.1\" xref=\"S4.T2.11.11.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.11.11.2.1.1.1.m1.1b\"><ci id=\"S4.T2.11.11.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.11.11.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.11.11.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.11.11.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.12.12.3.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.12.12.3.2.2.2.m1.1\"><semantics id=\"S4.T2.12.12.3.2.2.2.m1.1a\"><mi id=\"S4.T2.12.12.3.2.2.2.m1.1.1\" xref=\"S4.T2.12.12.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.12.12.3.2.2.2.m1.1b\"><ci id=\"S4.T2.12.12.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.12.12.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.12.12.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.12.12.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.13.13.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.13.13.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.13.13.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.13.13.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.13.13.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.13.13.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.13.13.4.3.4.3\">26.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.13.13.4.3.4.4\">1029.88</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.13.13.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.5.3\">26.52</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.5.4\">1039.02</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.13.13.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.6.3\">26.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.4.3.6.4\">1042.06</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_rr ltx_border_t\" id=\"S4.T2.16.16.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.16.16.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.14.14.5.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.14.14.5.1.1.1.m1.1\"><semantics id=\"S4.T2.14.14.5.1.1.1.m1.1a\"><mi id=\"S4.T2.14.14.5.1.1.1.m1.1.1\" xref=\"S4.T2.14.14.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.14.14.5.1.1.1.m1.1b\"><ci id=\"S4.T2.14.14.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.14.14.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.14.14.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.14.14.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.15.15.6.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.15.15.6.2.2.2.m1.1\"><semantics id=\"S4.T2.15.15.6.2.2.2.m1.1a\"><mi id=\"S4.T2.15.15.6.2.2.2.m1.1.1\" xref=\"S4.T2.15.15.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.15.15.6.2.2.2.m1.1b\"><ci id=\"S4.T2.15.15.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.15.15.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.15.15.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.15.15.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.16.16.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.16.16.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.16.16.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.16.16.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.16.16.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.16.16.7.3.4.3\">26.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.16.16.7.3.4.4\">1024.53</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.5.3\">26.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.5.4\">1040.52</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.6.3\">26.54</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.7.3.6.4\">1030.01</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.23.23\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T2.17.17.1\"><math alttext=\"\\sigma_{\\mathbf{x}}^{2}=0.5^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.17.17.1.m1.1\"><semantics id=\"S4.T2.17.17.1.m1.1a\"><mrow id=\"S4.T2.17.17.1.m1.1.1\" xref=\"S4.T2.17.17.1.m1.1.1.cmml\"><msubsup id=\"S4.T2.17.17.1.m1.1.1.2\" xref=\"S4.T2.17.17.1.m1.1.1.2.cmml\"><mi id=\"S4.T2.17.17.1.m1.1.1.2.2.2\" xref=\"S4.T2.17.17.1.m1.1.1.2.2.2.cmml\">\u03c3</mi><mi id=\"S4.T2.17.17.1.m1.1.1.2.2.3\" xref=\"S4.T2.17.17.1.m1.1.1.2.2.3.cmml\">\ud835\udc31</mi><mn id=\"S4.T2.17.17.1.m1.1.1.2.3\" xref=\"S4.T2.17.17.1.m1.1.1.2.3.cmml\">2</mn></msubsup><mo id=\"S4.T2.17.17.1.m1.1.1.1\" xref=\"S4.T2.17.17.1.m1.1.1.1.cmml\">=</mo><msup id=\"S4.T2.17.17.1.m1.1.1.3\" xref=\"S4.T2.17.17.1.m1.1.1.3.cmml\"><mn id=\"S4.T2.17.17.1.m1.1.1.3.2\" xref=\"S4.T2.17.17.1.m1.1.1.3.2.cmml\">0.5</mn><mn id=\"S4.T2.17.17.1.m1.1.1.3.3\" xref=\"S4.T2.17.17.1.m1.1.1.3.3.cmml\">2</mn></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.17.17.1.m1.1b\"><apply id=\"S4.T2.17.17.1.m1.1.1.cmml\" xref=\"S4.T2.17.17.1.m1.1.1\"><eq id=\"S4.T2.17.17.1.m1.1.1.1.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.1\"></eq><apply id=\"S4.T2.17.17.1.m1.1.1.2.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.17.17.1.m1.1.1.2.1.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2\">superscript</csymbol><apply id=\"S4.T2.17.17.1.m1.1.1.2.2.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.T2.17.17.1.m1.1.1.2.2.1.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2\">subscript</csymbol><ci id=\"S4.T2.17.17.1.m1.1.1.2.2.2.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2.2.2\">\ud835\udf0e</ci><ci id=\"S4.T2.17.17.1.m1.1.1.2.2.3.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.2.2.3\">\ud835\udc31</ci></apply><cn id=\"S4.T2.17.17.1.m1.1.1.2.3.cmml\" type=\"integer\" xref=\"S4.T2.17.17.1.m1.1.1.2.3\">2</cn></apply><apply id=\"S4.T2.17.17.1.m1.1.1.3.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T2.17.17.1.m1.1.1.3.1.cmml\" xref=\"S4.T2.17.17.1.m1.1.1.3\">superscript</csymbol><cn id=\"S4.T2.17.17.1.m1.1.1.3.2.cmml\" type=\"float\" xref=\"S4.T2.17.17.1.m1.1.1.3.2\">0.5</cn><cn id=\"S4.T2.17.17.1.m1.1.1.3.3.cmml\" type=\"integer\" xref=\"S4.T2.17.17.1.m1.1.1.3.3\">2</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.17.17.1.m1.1c\">\\sigma_{\\mathbf{x}}^{2}=0.5^{2}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.17.17.1.m1.1d\">italic_\u03c3 start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T2.20.20.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.20.20.4.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.20.20.4.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.18.18.2.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.18.18.2.1.1.1.m1.1\"><semantics id=\"S4.T2.18.18.2.1.1.1.m1.1a\"><mi id=\"S4.T2.18.18.2.1.1.1.m1.1.1\" xref=\"S4.T2.18.18.2.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.18.18.2.1.1.1.m1.1b\"><ci id=\"S4.T2.18.18.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.18.18.2.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.18.18.2.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.18.18.2.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.19.19.3.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.19.19.3.2.2.2.m1.1\"><semantics id=\"S4.T2.19.19.3.2.2.2.m1.1a\"><mi id=\"S4.T2.19.19.3.2.2.2.m1.1.1\" xref=\"S4.T2.19.19.3.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.19.19.3.2.2.2.m1.1b\"><ci id=\"S4.T2.19.19.3.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.19.19.3.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.19.19.3.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.19.19.3.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.20.20.4.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.20.20.4.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.20.20.4.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.20.20.4.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.20.20.4.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.20.20.4.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.20.20.4.3.4.3\">19.82</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.20.20.4.3.4.4\">2947.03</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.20.20.4.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.5.3\">19.83</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.5.4\">2940.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.20.20.4.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.6.3\">19.85</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4.3.6.4\">2945.56</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_rr ltx_border_t\" id=\"S4.T2.23.23.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.23.23.7.3\">\n<tr class=\"ltx_tr\" id=\"S4.T2.23.23.7.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.21.21.5.1.1.1\"><math alttext=\"H\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.21.21.5.1.1.1.m1.1\"><semantics id=\"S4.T2.21.21.5.1.1.1.m1.1a\"><mi id=\"S4.T2.21.21.5.1.1.1.m1.1.1\" xref=\"S4.T2.21.21.5.1.1.1.m1.1.1.cmml\">H</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.21.21.5.1.1.1.m1.1b\"><ci id=\"S4.T2.21.21.5.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.21.21.5.1.1.1.m1.1.1\">\ud835\udc3b</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.21.21.5.1.1.1.m1.1c\">H</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.21.21.5.1.1.1.m1.1d\">italic_H</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.22.22.6.2.2.2\"><math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.22.22.6.2.2.2.m1.1\"><semantics id=\"S4.T2.22.22.6.2.2.2.m1.1a\"><mi id=\"S4.T2.22.22.6.2.2.2.m1.1.1\" xref=\"S4.T2.22.22.6.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.22.22.6.2.2.2.m1.1b\"><ci id=\"S4.T2.22.22.6.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.22.22.6.2.2.2.m1.1.1\">\ud835\udc47</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.22.22.6.2.2.2.m1.1c\">T</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.22.22.6.2.2.2.m1.1d\">italic_T</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.23.23.7.3.3.4.1\">PSNR (db)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.3.3\">\n<span class=\"ltx_text\" id=\"S4.T2.23.23.7.3.3.3.1\">L</span><sub class=\"ltx_sub\" id=\"S4.T2.23.23.7.3.3.3.2\">1</sub>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.23.23.7.3.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.23.23.7.3.4.1\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.23.23.7.3.4.2\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.23.23.7.3.4.3\">19.88</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.23.23.7.3.4.4\">2923.69</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.23.23.7.3.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.5.1\">10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.5.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.5.3\">19.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.5.4\">2939.25</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.23.23.7.3.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.6.1\">20</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.6.2\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.6.3\">19.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.23.23.7.3.6.4\">2943.92</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>"
        }
    ],
    "metadata": {},
    "pdf_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\pdfs\\2405.19785v3.pdf",
    "HTML_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\htmls\\2405.19785v3.html"
}