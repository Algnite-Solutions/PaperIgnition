{
    "doc_id": "2405.19787v2",
    "title": "From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers",
    "authors": [
        "Dylan Zhang",
        "Justin Wang",
        "Francois Charton"
    ],
    "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.PL"
    ],
    "published_date": "2024-05-30 07:54:07+00:00",
    "abstract": "Instruction tuning -- tuning large language models on instruction-output\npairs -- is a promising technique for making models better adapted to the real\nworld. Yet, the key factors driving the model's capability to understand and\nfollow instructions not seen during training remain under-explored. Our\ninvestigation begins with a series of synthetic experiments within the\ntheoretical framework of a Turing-complete algorithm called Markov algorithm,\nwhich allows fine-grained control over the instruction-tuning data.\nGeneralization and robustness with respect to the training distribution emerge\nonce a diverse enough set of tasks is provided, even though very few examples\nare provided for each task. We extend these initial results to a real-world\napplication scenario of code generation and find that a more diverse\ninstruction set, extending beyond code-related tasks, improves the performance\nof code generation. Our observations suggest that a more diverse semantic space\nfor instruction-tuning sets greatly improves the model's ability to follow\ninstructions and perform tasks.",
    "text_chunks": [
        {
            "id": "S1",
            "type": "text",
            "title": "1Introduction",
            "caption": "1Introduction",
            "metadata": {},
            "text": "\n1 Introduction\nThe rapid advance of large language models (LLMs) is one of the most exciting recent developments in artificial intelligence. LLMs, pre-trained on large text corpora, have demonstrated impressive generalizable reasoning capabilities and can achieve remarkable performance across a broad set of tasks, ranging from natural language comprehension\u00a0[34] and generation\u00a0[3] to mathematical reasoning\u00a0[10] and programming\u00a0[6]. These models have shown promise in performing real-world tasks in various applications and business solutions. One fundamental pillar of such success lies in the capabilities of these models to perform tasks through generalizable reasoning.\n\nInstruction tuning is a popular approach to unlock the capabilities of these models originally trained on next-token-prediction objectives to understand instructions and perform reasoning to complete tasks. By training models on pairs of instructions and expected outcomes, instruction tuning teaches LLMs to perform specific tasks, thus enabling them to address real-world problems and seamlessly interact with humans. In practice, however, fine-tuning data is limited, and instruction tuning can only focus on a limited set of tasks. Its success is therefore critically dependent on the model\u2019s ability to generalize beyond its fine-tuning instructions to unseen tasks not encountered during training. Several factors influence this generalization: the size of the fine-tuning sample, the diversity of the instruction sets, and the quality of the annotations. Yet, there is little systematic research on their relative impact.\n\nOur work aims to fill this gap by proposing two contributions to the study of generalization in instruction tuning. First, we propose a systematic analysis of the impact of instruction diversity by focusing on a simple yet important symbolic task: string rewrites. This basic setting enables us to exercise fine control over the factors that may affect generalization and to demonstrate the importance of instruction diversity. To highlight the broader applicability, we describe this task in terms of a Markov algorithm, a classic Turing-complete model, ensuring rigorous examination of string replacements. Second, we extend this analysis to a real-world application: code generation, and show that fine-tuning on an instruction set that extends beyond coding tasks significantly improves performance.\n\nOur main findings are:\n\n1.\nInstruction diversity is the main driver of generalization. Models trained on a diverse set of instructions generalize better, even when the number of examples per instruction is small.\n\n2.\nThe semantic diversity of instructions matters, together with the number of instructions.\n\n3.\nInstruction diversity improves model robustness and can compensate for the adverse impact of non-uniform fine-tuning distributions.\n\n\nWe demonstrate that generalization and robustness with respect to the training distribution emerge once a diverse enough set of tasks is provided, even though very few examples are provided for each task. These initial results are extended to a real-world application scenario of code generation, where we find that a more diverse instruction set, extending beyond code-related tasks, improves performance. Our observations suggest that a more diverse semantic space for instruction-tuning sets greatly improves the model\u2019s ability to follow instructions and perform tasks.\n"
        },
        {
            "id": "S2",
            "type": "text",
            "title": "2Related works",
            "caption": "2Related works",
            "metadata": {},
            "text": "\n2 Related works\nDatasets for instruction-tuning.\nMany datasets for instruction-tuning have been proposed. The best quality is achieved for sets collated by human\nannotators\u00a0[18, 42, 31, 38, 27, 11, 21], but their size is constrained by the cost of annotation. Alternative methods, which use large language models to generate instruction sets, have been\nproposed\u00a0[37, 14, 32, 29, 8, 40, 20, 19]. They provide larger instruction sets, at the cost of reduced annotation quality.\n\nData curation for instruction-tuning.\nIt is widely recognized that the quality of instruction-tuning datasets has a massive impact on the performance of fine-tuned models. Previous works acknowledged the contributions of several key factors.\nMost research on the subject insist on the importance of the size and quality of the instruction sets\u00a0[9, 17, 36].\nLiang et al.\u00a0[23] point out the importance of consistent formats.\nSeveral recent works\u00a0[43, 5] suggest that models fine-tuned on carefully selected examples can achieve high performance with small datasets.\n\nVarious strategies for data curation have been proposed, focusing on instruction diversity, and the quality of answers \u00a0[43, 5, 41, 22, 26].\nSeveral authors discuss the benefit of mixing tasks from different\ncategories\u00a0[27, 17, 4]. Closest to our work, Dong et al.\u00a0[12] discuss the impact of mixing general and domain-specific instructions, in order to achieve the best results with the smallest dataset.\n"
        },
        {
            "id": "S3",
            "type": "text",
            "title": "3String replacements",
            "caption": "3String replacements",
            "metadata": {},
            "text": "\n3 String replacements\nOur first synthetic task is string replacement. The model is trained to apply a replacement rule R\ud835\udc45Ritalic_R (a pair of string letters, like a\u2062a\u2192b\u2062a\u2062c\u2192\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4e\ud835\udc50aa\\to bacitalic_a italic_a \u2192 italic_b italic_a italic_c) to some string of letters I\ud835\udc3cIitalic_I (e.g. c\u2062a\u2062a\u2062b\u2062a\ud835\udc50\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4ecaabaitalic_c italic_a italic_a italic_b italic_a), resulting in an output string O\ud835\udc42Oitalic_O (e.g. c\u2062b\u2062a\u2062c\u2062b\u2062a\ud835\udc50\ud835\udc4f\ud835\udc4e\ud835\udc50\ud835\udc4f\ud835\udc4ecbacbaitalic_c italic_b italic_a italic_c italic_b italic_a). Rule R\ud835\udc45Ritalic_R is applied once only, to the leftmost occurrence of the rule. If rule R\ud835\udc45Ritalic_R be applied, the models returns the initial string I\ud835\udc3cIitalic_I. For instance, applying rule R:i\u2062s\u2062s\u2192a\u2062r\u2062t:\ud835\udc45\u2192\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc5f\ud835\udc61R:iss\\to artitalic_R : italic_i italic_s italic_s \u2192 italic_a italic_r italic_t to I=m\u2062i\u2062s\u2062s\u2062i\u2062s\u2062s\u2062i\u2062p\u2062i\ud835\udc3c\ud835\udc5a\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5d\ud835\udc56I=mississipiitalic_I = italic_m italic_i italic_s italic_s italic_i italic_s italic_s italic_i italic_p italic_i yields O=m\u2062a\u2062r\u2062t\u2062i\u2062s\u2062s\u2062i\u2062p\u2062i\ud835\udc42\ud835\udc5a\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5d\ud835\udc56O=martissipiitalic_O = italic_m italic_a italic_r italic_t italic_i italic_s italic_s italic_i italic_p italic_i, and applying R\ud835\udc45Ritalic_R to I=c\u2062a\u2062n\u2062a\u2062d\u2062a\ud835\udc3c\ud835\udc50\ud835\udc4e\ud835\udc5b\ud835\udc4e\ud835\udc51\ud835\udc4eI=canadaitalic_I = italic_c italic_a italic_n italic_a italic_d italic_a yields O=c\u2062a\u2062n\u2062a\u2062d\u2062a\ud835\udc42\ud835\udc50\ud835\udc4e\ud835\udc5b\ud835\udc4e\ud835\udc51\ud835\udc4eO=canadaitalic_O = italic_c italic_a italic_n italic_a italic_d italic_a.\n\nDespite its simplicity, string replacement play a central role in theoretical computer science and formal logic. It is the basic operation in Markov Algorithms\u00a0[28], a Turing-complete model of computation. A Markov algorithm processes sequences of letters on a fixed alphabet by means of an ordered set of rewrite rules R:(xi\u2192yi)i\u2208{1,\u2026,n},:\ud835\udc45subscript\u2192subscript\ud835\udc65\ud835\udc56subscript\ud835\udc66\ud835\udc56\ud835\udc561\u2026\ud835\udc5bR:(x_{i}\\rightarrow y_{i})_{i\\in\\{1,\\dots,n\\}},italic_R : ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2192 italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i \u2208 { 1 , \u2026 , italic_n } end_POSTSUBSCRIPT , with xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and yisubscript\ud835\udc66\ud835\udc56y_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT words over an extended alphabet.\n\nWhen processing a sequence z0subscript\ud835\udc670z_{0}italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, the algorithms considers all rules in R\ud835\udc45Ritalic_R in order, finds the first one that applies to z0subscript\ud835\udc670z_{0}italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT (say xi\u2192yi\u2192subscript\ud835\udc65\ud835\udc56subscript\ud835\udc66\ud835\udc56x_{i}\\to y_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2192 italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), and produces z1subscript\ud835\udc671z_{1}italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT by replacing the leftmost occurence of xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in z0subscript\ud835\udc670z_{0}italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT by yisubscript\ud835\udc66\ud835\udc56y_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. The algorithms is then applied to z1subscript\ud835\udc671z_{1}italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, iteratively producing z2,z3,\u2026\u2062znsubscript\ud835\udc672subscript\ud835\udc673\u2026subscript\ud835\udc67\ud835\udc5bz_{2},z_{3},\\dots z_{n}italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , \u2026 italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, and terminates either when a special rule of the form xi\u2192\u22c5\u2192subscript\ud835\udc65\ud835\udc56\u22c5x_{i}\\to\\cdotitalic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2192 \u22c5 is encountered, causing the model to return znsubscript\ud835\udc67\ud835\udc5bz_{n}italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, its last input string, or when no rules can be applied, in which case the algorithm is said to be blocked (and produces no output). Appendix\u00a0A provides examples of Markov algorithms.\n\nAlthough very simples, Markov algorithms can be show to be Turing-complete: any finite computation can be implemented by a Markov Algorithm (this is Markov\u2019s thesis). As a result, a language model that can be trained to implement string rewrites could in theory become a universal computation machine (the practical difficulty, here, being the model capability to handle large number of rules, and its reliability over large numbers of rewrites).\n\nIn this paper, we consider two tasks based on string rewrites:\n\n1.\napply rule x\u2192y\u2192\ud835\udc65\ud835\udc66x\\to yitalic_x \u2192 italic_y to a sequence containing x\ud835\udc65xitalic_x,\n\n2.\napply rule x\u2192y\u2192\ud835\udc65\ud835\udc66x\\to yitalic_x \u2192 italic_y when the sequence contains x\ud835\udc65xitalic_x, return the input sequence when it does not.\n\n\nTask 1111 is the base rewrite operation. Task 2222, referred to as \u201cno-op\u201d involves an additional decision step, on whether the rule is applicable. It is central to Markov algorithms, where the model must decide, at every step, which rule to apply.\n\nIn our experiments, model inputs and outputs are sequences of the lowercase letters a\u2062\u2026\u2062z\ud835\udc4e\u2026\ud835\udc67a\\dots zitalic_a \u2026 italic_z. Model inputs are triplets of strings, (x,y,z)\ud835\udc65\ud835\udc66\ud835\udc67(x,y,z)( italic_x , italic_y , italic_z ) (separated by a special token), representing the rule x\u2192y\u2192\ud835\udc65\ud835\udc66x\\to yitalic_x \u2192 italic_y and the input sequence z\ud835\udc67zitalic_z. Model outputs are the strings z\u2032superscript\ud835\udc67\u2032z^{\\prime}italic_z start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT obtained by replacing the leftmost instance of x\ud835\udc65xitalic_x by y\ud835\udc66yitalic_y, when x\ud835\udc65xitalic_x is in z\ud835\udc67zitalic_z, or z\ud835\udc67zitalic_z if x\ud835\udc65xitalic_x is not in z\ud835\udc67zitalic_z. Our models uses a very limited vocabulary of 29292929 tokens (26262626 lowercase letters, a special separator token, and beginning and end of sequence tokens).\n"
        },
        {
            "id": "S4",
            "type": "text",
            "title": "4Experiments with string replacements",
            "caption": "4Experiments with string replacements",
            "metadata": {},
            "text": "\n4 Experiments with string replacements\nIn this first set of experiments, we train GPT-2\u00a0[30] models with 256 dimensions, 6666 layers, and 4444 attention heads. The model is trained from scratch, and supervised, on a generated dataset of instruction/outcome pairs. The training details can be found in Appendix\u00a0B.\n\nThe training sets include S\u00d7I\ud835\udc46\ud835\udc3cS\\times Iitalic_S \u00d7 italic_I input sequences, featuring I\ud835\udc3cIitalic_I different replacements rules (instructions), applied to S\ud835\udc46Sitalic_S different input sequences. Trained models are then tested on 105superscript10510^{5}10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT examples, all featuring unseen instructions. The goal of these experiments is to assess the relative impact of S\ud835\udc46Sitalic_S and I\ud835\udc3cIitalic_I for generalization to unseen instructions (measured by the accuracy of the trained model on the test set).\n\n\n4.1 Instruction Diversity Is Decisive To Generalization\nFigure\u00a02(a) presents the generalization accuracy for models trained on a fixed budget of I\u00d7S=106\ud835\udc3c\ud835\udc46superscript106I\\times S=10^{6}italic_I \u00d7 italic_S = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT examples, as a function of the number I\ud835\udc3cIitalic_I of\ndifferent instructions in the training set. The number of examples per instruction (S\ud835\udc46Sitalic_S) decreases as I\ud835\udc3cIitalic_I increases. In these experiments, all input sequences feature at least one instance of the replacement rule: we are learning task 1.\n\nThe accuracy curve has a step shape. Models trained on less than 300300300300 rules (instructions) never generalize to unseen instructions, no matter the number of examples provided for each rule. On the other hand, models trained on 1000100010001000 rules or more always generalize, even when each rule is featured in a handful of examples. A sharp phase transition happens around 400400400400 instructions.\nWe conclude that the number of different rules in the training set (I\ud835\udc3cIitalic_I) is the key factor that allows the model to generalize to unseen instructions.\n\n\n4.2 Diversification Allows Generalization In Case-Based Reasoning Set-Up\nIn previous experiments, the model was trained to perform a specific task: replacing a substring that was always present in the input sequence. We now consider a more general and challenging setup involving a new task where some rules may not apply. In such cases, the model returns the input sequence unchanged. This new setup presents a two-step task: first, the model must decide whether the rule applies; second, it must either perform the replacement or copy the input.\n\nThis scenario represents a broader context for reasoning with LLMs. In LLM-agent frameworks, No-Ops are akin to decision points in complex environments where the agent must determine the relevance of actions based on the current context\u00a0[16, 35]..\n\nTo explore this, we introduce a third parameter in the training set: the frequency of \u201cNo-Ops\u201d (instructions that cannot be satisfied), which we vary between 10% and 50%. The size of the training and test sets remains the same as in previous experiments.\n\nFigure\u00a02(b) presents the generalization accuracies of trained models, as a function of the number of instructions and the frequency of No-Ops. Accuracies for Ops and No-Ops unseen instructions are measured separately (these are, in fact, different tasks). Given the simplicity of No-Ops cases and their predominance in the data111Consider a dataset containing 100,000 data points, 10% No-Ops, and 100 rules. No-Ops takes up 10,000 in total, \u223csimilar-to\\sim\u223c11\u00d7\\times\u00d7 of any has-Ops., the model defaults to apply it when the number of instructions are small. Has-Ops cases, on the other hand, display the same patterns as in the previous experiments: the model exhibits full generalization to unseen instructions once the training set features more than a given number of different instructions (around 400, here), below this number, the model performs the lazy operation of applying No-Ops to all inputs. Interestingly, the proportion of No-Ops in the training set seems to have little impact on generalization.\n\nOverall, our conclusions remain consistent with previous experiments, albeit with a slightly lower number of instructions needed for generalization (400 vs. 500). This demonstrates the effectiveness of diversification in more complex scenarios involving case-based reasoning.\n\n\n4.3 Imbalanced Distribution Is Still Effective In Driving Generalization\nIn previous experiments, instructions were evenly distributed between examples in the training set: in a training set of 1111 million examples, with 500500500500 different instructions, every instruction would be featured 2000200020002000 times. Such a situation is unlikely to happen in real-world settings. In real-world training sets, some tasks will be much more common than others (due to the availability of fine-tuning data and the nature of the tasks).\n\nTo investigate the impact of the distribution of instructions on generalization to unseen tasks, we generate datasets of 1,000, 10,000 and 100,000 different instructions,\nand distribute the number of examples per instruction according to a power law distribution with PMF f\u2062(x)=\u03b1\u2062x\u03b1\u22121\ud835\udc53\ud835\udc65\ud835\udefcsuperscript\ud835\udc65\ud835\udefc1f(x)=\\alpha x^{\\alpha-1}italic_f ( italic_x ) = italic_\u03b1 italic_x start_POSTSUPERSCRIPT italic_\u03b1 - 1 end_POSTSUPERSCRIPT where \u03b1\ud835\udefc\\alphaitalic_\u03b1 is the shape parameter. By varying the shape parameter of the power law, we can generate a distribution of examples that range from close to uniform, to extremely peaked as shown in Fig.\u00a03(b).\n\nFigure\u00a03(a) presents model generalization as a function of the shape parameter of the power law, for training sets of 1111 million examples with 1,000, 10,000, and 100,000 instructions. Models trained on 10,000 different instructions or more prove to be robust with respect to the distribution of examples per instruction. For models trained on 1000100010001000 instructions, generalization accuracy drop steeply when the shape parameter is larger than 0.20.20.20.2. This observation nicely matches the result of previous experiments. In a training set of 1111 million examples, featuring 1000100010001000 different instructions distributed according to a power law, instructions with a probability lower than 0.1%percent0.10.1\\%0.1 % are hardly visible. When the shape parameter falls below 0.20.20.20.2, more than half of the instructions are below that threshold, and the model is effectively trained on less than 500500500500 instructions, the lower limit for generalization to unseen instructions.\n\n\n4.4 Semantic Diversification Boosts Task Performance\nSo far, instruction diversity has only been measured in terms of the number of instructions in the fine-tuning set. We now investigate the impact of semantic diversity in the instruction set. In the string rewrite setting, we constrain the semantic diversity of instructions by restraining the patterns that can appear in the rule substrings. In a semantically diverse set of rules, instructions would be randomly sampled from every possible sequence of lowercase letters. In a constrained setting, rule substrings must obey certain rules, like being composed of repeated letters, or repeated patterns, or having a palindromic structure.\n\nSpecifically, we experiment with three sets of semantic constraints:\n\n\u2022\nrepeated: characters repeated k\ud835\udc58kitalic_k times: a\u2062a\u2062a\u2062b\u2062b\u2062b\u2062c\u2062c\u2062c\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc50\ud835\udc50\ud835\udc50aaabbbcccitalic_a italic_a italic_a italic_b italic_b italic_b italic_c italic_c italic_c for k=3\ud835\udc583k=3italic_k = 3,\n\n\u2022\nperiodic: patterns repeated k\ud835\udc58kitalic_k times: a\u2062b\u2062c\u2062a\u2062b\u2062c\ud835\udc4e\ud835\udc4f\ud835\udc50\ud835\udc4e\ud835\udc4f\ud835\udc50abcabcitalic_a italic_b italic_c italic_a italic_b italic_c for k=2\ud835\udc582k=2italic_k = 2,\n\n\u2022\nmirror: mirroring patterns repeated k\ud835\udc58kitalic_k times: a\u2062b\u2062c\u2062c\u2062b\u2062a\u2062a\u2062b\u2062c\ud835\udc4e\ud835\udc4f\ud835\udc50\ud835\udc50\ud835\udc4f\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc50abccbaabcitalic_a italic_b italic_c italic_c italic_b italic_a italic_a italic_b italic_c for k=3\ud835\udc583k=3italic_k = 3,\n\n\nand train models on sets of rules where both substrings obey the constraint (e.g. a\u2062a\u2062a\u2062b\u2062b\u2062b\u2192b\u2062b\u2062b\u2062c\u2062c\u2062c\u2192\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc50\ud835\udc50\ud835\udc50aaabbb\\to bbbcccitalic_a italic_a italic_a italic_b italic_b italic_b \u2192 italic_b italic_b italic_b italic_c italic_c italic_c). Note that all sets of constrains depend on a parameter k\ud835\udc58kitalic_k, and that increasing k\ud835\udc58kitalic_k makes the instruction set less diverse. To measure the impact of semantic diversity, we train models on instruction sets with large k\ud835\udc58kitalic_k, and test them on examples with low k\ud835\udc58kitalic_k.\n\nFirst, we observe that models trained on one set of semantic constraints (e.g. all instructions repeated, or periodic, or mirror) with high values of k\ud835\udc58kitalic_k, never generalize to low values of k\ud835\udc58kitalic_k. Models \u201coverfit\u201d the high-k\ud835\udc58kitalic_k semantic pattern. Training on a mixture of repeated and periodic instruction (with high k\ud835\udc58kitalic_k) bring no improvement: the model does not generalize to low k\ud835\udc58kitalic_k, for either constraint.\n\nThe situation changes when models are trained on a mixture of instructions from the three constrained sets\u00a0(Figure \u00a04).\nModels trained on large k\ud835\udc58kitalic_k (k\ud835\udc58kitalic_k between 3333 and 6666 for all three constraints) do generalize to small k\ud835\udc58kitalic_k (k<3\ud835\udc583k<3italic_k < 3), and unconstrained instructions. As before the number of training instructions improves generalization. Models trained on only 500500500500 instructions do not generalize at all. Models trained on 5000500050005000 achieve high accuracies. Finally, for a given number of instructions, training on more constrained sets, i.e. with larger k\ud835\udc58kitalic_k, makes generalization harder.\n\nThese experiments prove that instruction diversity goes further than having many different instructions in the fine-tuning dataset. Models trained on a diverse set of semantically constrained rules \u2013the string rewrite equivalent of a diverse set of tasks \u2013 generalize to broad sets of less constrained rules.\n\n\n4.5 Generalization Across Input Semantics\nIn the previous section, we studied the impact on generalization of the semantic diversity of instructions. In this section, we focus on the diversity of the input sequences provided with the rules. Specifically, for a rule xi\u2192yi\u2192subscript\ud835\udc65\ud835\udc56subscript\ud835\udc66\ud835\udc56x_{i}\\to y_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2192 italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, applied to a sequence sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we study the impact of the distribution of sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in the training set, measured by the number \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O of occurrences of xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (always greater than 1111 for task 1111, this number of always larger than 1111).\n\nTable\u00a01 presents the acccuracy of models trained on instruction sets with specific values of \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O, on test sets with a uniform distribution o \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O between 1111 and 20202020. For models trained on one value of \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O, there is a marked decline in generalization accuracy. And models with less than 500500500500 different instructions no longer learn to satisfactory levels. A more diverse instruction set, featuring with a wider range of \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O (1,5,10,151510151,5,10,151 , 5 , 10 , 15 and 20202020) achieves much better generalization accuracy.\n\nThis concludes our experiments on string replacement. The key takeaway is the undeniable importance of instruction diversity. To generalize to unseen rules, models must be trained on large (\u2265500absent500\\geq 500\u2265 500) number of different instructions, featuring diverse rules and instructions.\n\n\n4.6 String replacements with pre-trained models\nExtending our results about string replacement to pre-trained models is not straightforward. After pre-training most LLM can perform string replacements with high accuracy, and it will be hard to tell whether their performance after fine-tuning is due to instruction tuning, or to their initial pre-training. To circumvent this, we introduce a more difficult task: encrypted rewrites. As in the string replacement task, the model is presented with a replacement rule x\u2192y\u2192\ud835\udc65\ud835\udc66x\\to yitalic_x \u2192 italic_y and a string to be replaced s\ud835\udc60sitalic_s, but the input also contains an encryption key k\ud835\udc58kitalic_k, and the model must replace x\ud835\udc65xitalic_x by E\u2062(y,k)\ud835\udc38\ud835\udc66\ud835\udc58E(y,k)italic_E ( italic_y , italic_k ), the encrypted value of y\ud835\udc66yitalic_y with key k\ud835\udc58kitalic_k: instead of replacing the string s=s1\u2062x\u2062s2\ud835\udc60subscript\ud835\udc601\ud835\udc65subscript\ud835\udc602s=s_{1}xs_{2}italic_s = italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT by s1\u2062y\u2062s2subscript\ud835\udc601\ud835\udc66subscript\ud835\udc602s_{1}ys_{2}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_y italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, the model replaces it with s1\u2062E\u2062(y,k)\u2062s2subscript\ud835\udc601\ud835\udc38\ud835\udc66\ud835\udc58subscript\ud835\udc602s_{1}E(y,k)s_{2}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_E ( italic_y , italic_k ) italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The encryption algorithm used is the Caesar cipher.\n\nThis resembles the scenario of instruction-tuning a pre-trained language model, where it already has the ability to replace strings, and rotate tokens, but need to be supervised to capture the meaning of an instruction and follow it correctly.\n\nWe keep two disjoint dictionaries for train and test sets and prompt GPT-3.5-turbo to generate sentences containing words from the dictionary. If the word is in the generated sentence, we randomly sample a replacement and encrypt it with a random key. In no-ops cases, the input should be returned. We generate training sets of 40,0004000040,00040 , 000 sequences and test them on sets of 5,00050005,0005 , 000 instances - each generated using a distinct word in the test dictionary and again a randomly chosen key. Both sets contain 40%percent4040\\%40 % no-ops cases.\n\nWe fine-tuned the pre-trained language model (Llama2-7b)\u00a0[33] with LoRA\u00a0[15] with rank 256 and \u03b1\ud835\udefc\\alphaitalic_\u03b1 of 256 till convergence. Consistent with our earlier observations, the diversity of instructions benefits the model\u2019s generalization. With a smaller number of instructions, the pre-trained LLM also only solves no-op cases but cannot correctly perform the \u201creplace-then-encrypt\u201d operation (Figure\u00a05(a)). The impact of long-tailed distributions over rules, in this case, also can be diluted by the diversification of rules appearing in the dataset, as shown in Figure\u00a05(b).\n\n"
        },
        {
            "id": "S5",
            "type": "text",
            "title": "5Effect of Diversification on Real-World Scenario: Code Generation",
            "caption": "5Effect of Diversification on Real-World Scenario: Code Generation",
            "metadata": {},
            "text": "\n5 Effect of Diversification on Real-World Scenario: Code Generation\nOur synthetic experiments suggest that curating datasets with a small number of diversified instructions significantly enhances model performance for instruction following. Diversifying instructions improves the model\u2019s ability to handle previously unseen instructions and benefits the model even if the dataset does not cover the entire semantic space, provided the restrictions are not too stringent. Additionally, the model gains from diversification even in long-tailed distributions, where a few instruction classes dominate. This highlights that proper diversification can boost specialized models.\n\nThis suggests that when constructing real-world instruction-tuning datasets for some specific task, it may not be necessarily optimal\nto fine-tune the model entirely on instruction-response pairs of that specific task. In other words, given a fixed data budget,\nit might be better if a certain quantity of data from a wider range of task domains is included in the instruction following data,\ninstead of exhausting the budget on the data from that single domain. In addition, prior works \u00a0[12] have found that the performance\non coding and math reasoning tasks consistently grows with data size. We therefore conjecture that an optimal mixture might exist under each setting, depending\non the model, datasets, and number of instances.\n\n5.1 Experiments\nWe demonstrate how the findings from our earlier investigation can potentially lead to benefits in real-world instruction-following. We experimented with the task of code generation, in which the model re-writes natural language descriptions of a program into code. Besides, this task enjoys a relatively subjective evaluation protocol based on functional correctness.\nBy applying our insights on instruction diversification to the domain of program generation, we can effectively assess whether a diversified instruction set enhances the models\u2019 performance in handling unseen instructions.\n\nWe evaluate two popular code generation benchmarks, HumanEval\u00a0[7] and MBPP\u00a0[1], as well as\nEvalPlus \u2013 a widely-adopted augmented version\u00a0[25] of these two datasets. We sample training instances from OSS-Instruct\u00a0[39] dataset for code generation training. OSS-Instruct\nis a synthetic dataset generated using GPT-3.5-turbo and has gone through a sanitizing phase to eliminate data contamination.\nWe sample 20,0002000020,00020 , 000 training instances from OSS-Instruct as our baseline instruction-tuning dataset.\nThen we gradually remove code instruction-tuning data and incorporate randomly sampled\ngeneral-domain instruction-tuning data. We used Alpaca\u00a0[32], which is one of the most widely-known instruction datasets for general domain instruction following, diversified across different domains to spread across a wide semantic domain. As shown in figure\u00a06(a), its embedding space overlaps with coding, reasoning, and mathematics domains.\n\nWe chose two well-performing pre-trained code LM base models - DeepSeek-Coder-6.7B-Base\u00a0[13] and CodeQwen-7B-Base\u00a0[2].\n\n\n5.2 Instruction Diversity Can Help, But There Is A Price To Pay\nInclusion of Non-Coding Data\nAs shown in tables\u00a02 and \u00a03, extending the semantics of instruction-tuning data, at a price of even suppressing the number of code generation-specific data points,\n\nconsistently brings better overall performance for code-generation tasks, which echos our previous findings from string-rewriting experiments. However, by incorporating general-domain data, we pay a price of less diversification within the code-generation domain. Our results show that the benefit of introducing Alpaca data does not accumulate forever as we trade the diversity within the code generation domain (which is the target domain) with that across different domains.\n\nThis trade-off occurs because while general-domain data can improve the model\u2019s ability to understand and generate a wider variety of instructions, it also dilutes the model\u2019s specialization in the code-generation domain\u00a0[24]. As the proportion of general-domain data increases, the model\u2019s focus on the specific patterns and intricacies of code generation diminishes, leading to a plateau or even a decline in performance on code-generation tasks.\nTherefore, there exists the best mixture from which the model achieves optimal performance for both models respectively, as shown in Figure\u00a07.\n\nThe results echo our earlier conjecture drawn from the string-rewriting experiments. The inclusion of the Alpaca dataset highly\ndiversifies the distribution of SFT data.\n\nAlthough the majority of the training data still centers around the code generation domain,\nthe instructions in the Alpaca dataset span across a larger semantic space. Also, although only a small number of instances\nare included for each since the total number of instructions is large enough and the semantics are diverse enough,\nthe small number of data does play a part in boosting the model\u2019s code generation performance.\n\n\nDiversification Across Domains\nAs found in Section\u00a04.4, diversification across instruction semantics is yet another important dimension. As illustrated in Figure \u00a06(a) each instruction-tuning dataset cluster around a specific subspace of semantics, a further variety among instruction semantics could be obtained by further incorporating other datasets that cover a different space.\nSince the Alpaca dataset was mainly curated to build language model assistants that are optimized for interaction with humans, we consider expanding the semantics domain further by additionally incorporating data that requires more complex, multi-hop reasoning from the CoT-Collection dataset\u00a0[19] which contains reasoning problems and chain-of-thought style responses.\n\nAs shown in Figure\u00a04, we observe the CoT data indeed is complementary in its semantics space to the OSS-Alpaca mixture.\nTo investigate the effect of diversification across semantics domains, we trained the models with various OSS-Instruct v.s. non-coding ratios and benchmarked their performances against previous results. The primary goal of this experiment is to explore the benefits of further extending the semantics domain rather than finding the optimal mixture. Therefore, we used equal numbers of instances from the Alpaca and CoT-Collection datasets to rule out additional confounding factors.\n\nThe results obtained using CodeQwen are presented in Table\u00a04. Consistent with our findings from string replacement, the model trained on the optimal ratio within the 3-way mixture outperforms the one trained on the optimal OSS-Instruct + Alpaca mixture. This outcome reinforces the advantages of cross-domain diversification in enhancing model performance. However, it is important to note that this performance boost may not be consistent across all splits. When comparing the mix ratios of O\u2062S\u2062S:C\u2062o\u2062T=17:1.5:1.5:\ud835\udc42\ud835\udc46\ud835\udc46\ud835\udc36\ud835\udc5c\ud835\udc4717:1.5:1.5OSS:CoT=17:1.5:1.5italic_O italic_S italic_S : italic_C italic_o italic_T = 17 : 1.5 : 1.5 and O\u2062S\u2062S=17:3:\ud835\udc42\ud835\udc46\ud835\udc46173OSS=17:3italic_O italic_S italic_S = 17 : 3, we observe a performance decline when CoT data is included. We conjecture that the effectiveness of diversification is influenced by the specific mix ratio between the datasets used.\n\n\n\n5.3 Beating Open Source Code-LMs With Its Own Data (+ Diversification)\nAs yet a further step to demonstrate the benefit of diversification, we train a code language model by applying the same ideas of diversification to the whole OSS-Instruct dataset and compare the performance against the model trained on it: MagiCoder-DS-6.7B\u00a0[39]. We train all the trainable weights (instead of LoRA) in this set of experiments. As shown in Table\u00a05, appropriate diversification still leads to performance advantages. The observations are also consistent with our earlier experiments for code generation and string replacement, where a small fraction of non-coding data can drive performance gain, and that diversifying across multiple domains can push the performance even higher.\n\n"
        },
        {
            "id": "S6",
            "type": "text",
            "title": "6Conclusion and Limitations",
            "caption": "6Conclusion and Limitations",
            "metadata": {},
            "text": "\n6 Conclusion and Limitations\nThrough our symbolic experiments, we have shown that language models only generalize to instructions unseen during training when trained on a large and diverse set of instructions. For a fixed data budget, instruction diversity outweighs better illustration (i.e. more examples) for each instruction. These observations apply not only to the number of different instructions in the dataset but also to their semantic diversity. The negative effect of an unbalanced distribution of examples can be counteracted by a larger number of instructions in the training set. Putting all these together, this implies the possibility of improving the model\u2019s performance on some task by incorporating a small portion of data from other task domains. We demonstrated that diversity can bring benefits for real-world instruction following using the example scenario of code generation, and provided insights into effective diversification for better task performances.\n\nLimitations\nWe did not propose an algorithm to find the best data mixture including domains and ratios for task-specific instruction-tuning but differed the methods to search for the optimal strategy of diversification for future work.\n\n"
        },
        {
            "id": "Sx1",
            "type": "text",
            "title": "Acknowledgement",
            "caption": "Acknowledgement",
            "metadata": {},
            "text": "\nAcknowledgement\nWe thank Chi Han, Jialiang Xu, Yifeng Ding and Yuchen Li for providing suggestions and valuable feedback on this project.\n\n"
        },
        {
            "id": "A1",
            "type": "text",
            "title": "",
            "caption": "",
            "metadata": {},
            "text": "\nAppendix A Complement on Markov algorithms\nMarkov algorithms\u00a0[28] are ordered sets of rewrite rules, operating on sequences of symbols in a fixed alphabet \ud835\udcb0\ud835\udcb0\\mathcal{U}caligraphic_U. A sequence S\ud835\udc46Sitalic_S is processed by applying the first rewrite applicable to S\ud835\udc46Sitalic_S, at the leftmost position if several exist: i.e. the rewrite rule s\u2062s\u2192t\u2062r\u2192\ud835\udc60\ud835\udc60\ud835\udc61\ud835\udc5fss\\to tritalic_s italic_s \u2192 italic_t italic_r transforms the sequence S=m\u2062i\u2062s\u2062s\u2062i\u2062s\u2062s\u2062i\u2062p\u2062i\ud835\udc46\ud835\udc5a\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5d\ud835\udc56S=mississipiitalic_S = italic_m italic_i italic_s italic_s italic_i italic_s italic_s italic_i italic_p italic_i into S\u2032=m\u2062i\u2062t\u2062r\u2062i\u2062s\u2062s\u2062i\u2062p\u2062isuperscript\ud835\udc46\u2032\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc5f\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5d\ud835\udc56S^{\\prime}=mitrissipiitalic_S start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_m italic_i italic_t italic_r italic_i italic_s italic_s italic_i italic_p italic_i. The algorithm is then applied to S\u2032superscript\ud835\udc46\u2032S^{\\prime}italic_S start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, and the process is repeated until either no rules apply, and the algorithm is said to be blocked, or a special rule, called a stop rule is invoked, and the algorithm terminates and returns the final rewritten sequence.\n\nSpecifically, the algorithm uses and alphabet \ud835\udc9c\ud835\udc9c\\mathcal{A}caligraphic_A, which includes the alphabet \ud835\udcb0\ud835\udcb0\\mathcal{U}caligraphic_U used buy the sequences to be processed (henceforth, small case latin letters), a set of additional symbols (henceforth, the small case greek letters {\u03b1,\u03b2\u2062\u2026}\ud835\udefc\ud835\udefd\u2026\\{\\alpha,\\beta\\dots\\}{ italic_\u03b1 , italic_\u03b2 \u2026 }, and a special symbol \u22c5\u22c5\\cdot\u22c5 indicating a stop rule.\n\nFor instance, we could define the following algorithm, with \ud835\udcb0={a,b}\ud835\udcb0\ud835\udc4e\ud835\udc4f\\mathcal{U}=\\{a,b\\}caligraphic_U = { italic_a , italic_b }, and \ud835\udc9c={a,b,\u03b1,\u03b2,\u22c5}\ud835\udc9c\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udefd\u22c5\\mathcal{A}=\\{a,b,\\alpha,\\beta,\\cdot\\}caligraphic_A = { italic_a , italic_b , italic_\u03b1 , italic_\u03b2 , \u22c5 }, and the rules\n\n\n\u03b1\u2062x\ud835\udefc\ud835\udc65\\displaystyle\\alpha xitalic_\u03b1 italic_x\n\u2192\u2192\\displaystyle\\to\u2192\nx\u2062\u03b1\u2062\u03b2\u2062x\ud835\udc65\ud835\udefc\ud835\udefd\ud835\udc65\\displaystyle x\\alpha\\beta xitalic_x italic_\u03b1 italic_\u03b2 italic_x\n(1)\n\n\u03b2\u2062x\u2062y\ud835\udefd\ud835\udc65\ud835\udc66\\displaystyle\\beta xyitalic_\u03b2 italic_x italic_y\n\u2192\u2192\\displaystyle\\to\u2192\ny\u2062\u03b2\u2062x\ud835\udc66\ud835\udefd\ud835\udc65\\displaystyle y\\beta xitalic_y italic_\u03b2 italic_x\n(2)\n\n\u03b1\u2062\u03b2\u2062x\ud835\udefc\ud835\udefd\ud835\udc65\\displaystyle\\alpha\\beta xitalic_\u03b1 italic_\u03b2 italic_x\n\u2192\u2192\\displaystyle\\to\u2192\nx\u2062\u03b1\ud835\udc65\ud835\udefc\\displaystyle x\\alphaitalic_x italic_\u03b1\n(3)\n\n\u03b1\ud835\udefc\\displaystyle\\alphaitalic_\u03b1\n\u2192\u2192\\displaystyle\\to\u2192\n\u22c5\u22c5\\displaystyle\\cdot\u22c5\n(4)\n\n\n\u2192\u2192\\displaystyle\\to\u2192\n\u03b1\ud835\udefc\\displaystyle\\alphaitalic_\u03b1\n(5)\n\nwhere x\ud835\udc65xitalic_x and y\ud835\udc66yitalic_y stand for any letter a\ud835\udc4eaitalic_a or b\ud835\udc4fbitalic_b. This will transform any sequence of a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b into a concatenation of the sequence and its reverse. Applied on a\u2062b\u2062b\ud835\udc4e\ud835\udc4f\ud835\udc4fabbitalic_a italic_b italic_b, the algorithm will perform the following rewrites:\n\n\na\u2062b\u2062b\ud835\udc4e\ud835\udc4f\ud835\udc4f\\displaystyle abbitalic_a italic_b italic_b\n\u2192\u03b1\u2062a\u2062b\u2062b\u2192absent\ud835\udefc\ud835\udc4e\ud835\udc4f\ud835\udc4f\\displaystyle\\to\\alpha abb\u2192 italic_\u03b1 italic_a italic_b italic_b\n(by\u00a0\u20625)by\u00a05\\displaystyle(\\text{by }5)( by 5 )\n\n\n\u03b1\u2062a\u2062b\u2062b\ud835\udefc\ud835\udc4e\ud835\udc4f\ud835\udc4f\\displaystyle\\alpha abbitalic_\u03b1 italic_a italic_b italic_b\n\u2192a\u2062\u03b1\u2062\u03b2\u2062a\u2062b\u2062b\u2192absent\ud835\udc4e\ud835\udefc\ud835\udefd\ud835\udc4e\ud835\udc4f\ud835\udc4f\\displaystyle\\to a\\alpha\\beta abb\u2192 italic_a italic_\u03b1 italic_\u03b2 italic_a italic_b italic_b\n(by\u00a0\u20621)by\u00a01\\displaystyle(\\text{by }1)( by 1 )\n\n\na\u2062\u03b1\u2062\u03b2\u2062a\u2062b\u2062b\ud835\udc4e\ud835\udefc\ud835\udefd\ud835\udc4e\ud835\udc4f\ud835\udc4f\\displaystyle a\\alpha\\beta abbitalic_a italic_\u03b1 italic_\u03b2 italic_a italic_b italic_b\n\u2192a\u2062\u03b1\u2062b\u2062\u03b2\u2062a\u2062b\u2192absent\ud835\udc4e\ud835\udefc\ud835\udc4f\ud835\udefd\ud835\udc4e\ud835\udc4f\\displaystyle\\to a\\alpha b\\beta ab\u2192 italic_a italic_\u03b1 italic_b italic_\u03b2 italic_a italic_b\n(by\u00a0\u20622)by\u00a02\\displaystyle(\\text{by }2)( by 2 )\n\n\na\u2062\u03b1\u2062b\u2062\u03b2\u2062a\u2062b\ud835\udc4e\ud835\udefc\ud835\udc4f\ud835\udefd\ud835\udc4e\ud835\udc4f\\displaystyle a\\alpha b\\beta abitalic_a italic_\u03b1 italic_b italic_\u03b2 italic_a italic_b\n\u2192a\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062\u03b2\u2062a\u2062b\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\ud835\udc4f\\displaystyle\\to ab\\alpha\\beta b\\beta ab\u2192 italic_a italic_b italic_\u03b1 italic_\u03b2 italic_b italic_\u03b2 italic_a italic_b\n(by\u00a0\u20621)by\u00a01\\displaystyle(\\text{by }1)( by 1 )\n\n\na\u2062b\u2062\u03b1\u2062b\u2062\u03b2\u2062b\u2062\u03b2\u2062a\u2062b\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udc4f\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\ud835\udc4f\\displaystyle ab\\alpha b\\beta b\\beta abitalic_a italic_b italic_\u03b1 italic_b italic_\u03b2 italic_b italic_\u03b2 italic_a italic_b\n\u2192a\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062b\u2062\u03b2\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle\\to ab\\alpha\\beta bb\\beta a\u2192 italic_a italic_b italic_\u03b1 italic_\u03b2 italic_b italic_b italic_\u03b2 italic_a\n(by\u00a0\u20622)by\u00a02\\displaystyle(\\text{by }2)( by 2 )\n\n\na\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062b\u2062\u03b2\u2062a\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle ab\\alpha\\beta bb\\beta aitalic_a italic_b italic_\u03b1 italic_\u03b2 italic_b italic_b italic_\u03b2 italic_a\n\u2192a\u2062b\u2062\u03b1\u2062b\u2062\u03b2\u2062b\u2062\u03b2\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udc4f\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle\\to ab\\alpha b\\beta b\\beta a\u2192 italic_a italic_b italic_\u03b1 italic_b italic_\u03b2 italic_b italic_\u03b2 italic_a\n(by\u00a0\u20622)by\u00a02\\displaystyle(\\text{by }2)( by 2 )\n\n\na\u2062b\u2062\u03b1\u2062b\u2062\u03b2\u2062b\u2062\u03b2\u2062a\ud835\udc4e\ud835\udc4f\ud835\udefc\ud835\udc4f\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle ab\\alpha b\\beta b\\beta aitalic_a italic_b italic_\u03b1 italic_b italic_\u03b2 italic_b italic_\u03b2 italic_a\n\u2192a\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062\u03b2\u2062b\u2062\u03b2\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle\\to abb\\alpha\\beta b\\beta b\\beta a\u2192 italic_a italic_b italic_b italic_\u03b1 italic_\u03b2 italic_b italic_\u03b2 italic_b italic_\u03b2 italic_a\n(by\u00a0\u20621)by\u00a01\\displaystyle(\\text{by }1)( by 1 )\n\n\na\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062\u03b2\u2062b\u2062\u03b2\u2062a\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle abb\\alpha\\beta b\\beta b\\beta aitalic_a italic_b italic_b italic_\u03b1 italic_\u03b2 italic_b italic_\u03b2 italic_b italic_\u03b2 italic_a\n\u2192a\u2062b\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062\u03b2\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle\\to abbb\\alpha\\beta b\\beta a\u2192 italic_a italic_b italic_b italic_b italic_\u03b1 italic_\u03b2 italic_b italic_\u03b2 italic_a\n(by\u00a0\u20623)by\u00a03\\displaystyle(\\text{by }3)( by 3 )\n\n\na\u2062b\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062b\u2062\u03b2\u2062a\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4f\ud835\udefd\ud835\udc4e\\displaystyle abbb\\alpha\\beta b\\beta aitalic_a italic_b italic_b italic_b italic_\u03b1 italic_\u03b2 italic_b italic_\u03b2 italic_a\n\u2192a\u2062b\u2062b\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4e\\displaystyle\\to abbbb\\alpha\\beta a\u2192 italic_a italic_b italic_b italic_b italic_b italic_\u03b1 italic_\u03b2 italic_a\n(by\u00a0\u20623)by\u00a03\\displaystyle(\\text{by }3)( by 3 )\n\n\na\u2062b\u2062b\u2062b\u2062b\u2062\u03b1\u2062\u03b2\u2062a\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udefc\ud835\udefd\ud835\udc4e\\displaystyle abbbb\\alpha\\beta aitalic_a italic_b italic_b italic_b italic_b italic_\u03b1 italic_\u03b2 italic_a\n\u2192a\u2062b\u2062b\u2062b\u2062b\u2062a\u2062\u03b1\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4e\ud835\udefc\\displaystyle\\to abbbba\\alpha\u2192 italic_a italic_b italic_b italic_b italic_b italic_a italic_\u03b1\n(by\u00a0\u20623)by\u00a03\\displaystyle(\\text{by }3)( by 3 )\n\n\na\u2062b\u2062b\u2062b\u2062b\u2062a\u2062\u03b1\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4e\ud835\udefc\\displaystyle abbbba\\alphaitalic_a italic_b italic_b italic_b italic_b italic_a italic_\u03b1\n\u2192a\u2062b\u2062b\u2062b\u2062b\u2062a\u2192absent\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4e\\displaystyle\\to abbbba\u2192 italic_a italic_b italic_b italic_b italic_b italic_a\n(by\u00a0\u20624)by\u00a04\\displaystyle(\\text{by }4)( by 4 )\n\n\nSince rule 4444 is a stop rule, the algorithm terminates and returns a\u2062b\u2062b\u2062b\u2062b\u2062a\ud835\udc4e\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4eabbbbaitalic_a italic_b italic_b italic_b italic_b italic_a.\n\nJudicious introduction of additional (greek) letters allows one to compose Markov algorithms, effectively writing complex programs. Any effective process (i.e. finite computation) can be represented as a Markov algorithm (this is Markov\u2019s thesis).\n"
        },
        {
            "id": "A2",
            "type": "text",
            "title": "",
            "caption": "",
            "metadata": {},
            "text": "\nAppendix B Experimental set-up\n\nB.1 Model and Training\nIn rewrite experiments, we train GPT-2 models\u00a0[30], a decoder-only transformer-based architecture, with 6666 layers, 256256256256 dimensions and 4444 attention heads from scratch, on a generated instruction-tuning dataset using standard supervised fine-tuning approach. We use the AdamW optimizer, a learning rate of 10\u22123superscript10310^{-3}10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, and linear scheduling. All models are trained for 50 epochs. For the encrypted-rewriting task, we LoRA fine-tuned Llama-2 models with a learning rate of 1e-5, batch size 64, gradient accumulation step 1, and 8-bit quantization. The model takes about 2000 steps to converge. For coding experiments, we trained the model with a learning rate of 1e-5, batch size 4, and gradient accumulation step 1, 8-bit quantization for 3 epochs with a maximum length of 768. The models are trained and inferenced on 1 Nvidia A40 GPU. We used greedy decoding for all experiments.\n\n\nB.2 Data Generation\nSynthetic Experiment\nExcept for the diversity of semantics experiment, the results we reported in the main paper are obtained from an input length of 50 and a pattern length of 20.\nTo validate the generality of our findings, we conducted experiments on various input sizes {50, 100, 200} and, correspondingly, pattern lengths {20,40,50}.\n\nIn the diversity of semantics experiment, we used an input length of 500 and a pattern length of 60. We strictly restricted the sub-strings to look for and to replace them with both to be unseen during testing.\n\nCode Generation\nWe downloaded the data from the official Huggingface Datasets Repos.\n\n"
        }
    ],
    "figure_chunks": [
        {
            "id": "S3.F1",
            "type": "figure",
            "title": "2405.19787v2_Figure1",
            "caption": "(a)Our string-rewriting task set-up.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure1.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F1.sf1",
            "type": "figure",
            "title": "2405.19787v2_Figure1(1)",
            "caption": "(a)Our string-rewriting task set-up.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure1(1).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S3.F1.sf2",
            "type": "figure",
            "title": "2405.19787v2_Figure1(2)",
            "caption": "(b)Encrypted Re-writing. Similar to the re-writing experiment, but the model needs to infer the rule of encryption based on the rule of shifting specified in the instructions and compute the encrypted word.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure1(2).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F2",
            "type": "figure",
            "title": "2405.19787v2_Figure2",
            "caption": "(a)Re-writing accuracy against the number of instructions with a fixed-size training set.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure2.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F2.sf1",
            "type": "figure",
            "title": "2405.19787v2_Figure2(1)",
            "caption": "(a)Re-writing accuracy against the number of instructions with a fixed-size training set.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure2(1).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F2.sf2",
            "type": "figure",
            "title": "2405.19787v2_Figure2(2)",
            "caption": "(b)Rewriting with no-op situation included.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure2(2).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F3",
            "type": "figure",
            "title": "2405.19787v2_Figure3",
            "caption": "(a)Effect of long-tail task distributions on model\u2019s generalization ability.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure3.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F3.sf1",
            "type": "figure",
            "title": "2405.19787v2_Figure3(1)",
            "caption": "(a)Effect of long-tail task distributions on model\u2019s generalization ability.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure3(1).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F3.sf2",
            "type": "figure",
            "title": "2405.19787v2_Figure3(2)",
            "caption": "(b)The sorted percentage of each instruction following power-law distribution with different shape parameters. The y-axis is the percentage of the rules in the training mixture. The x-axis is the ranked index (by proportion of examples) of instructions.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure3(2).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F4",
            "type": "figure",
            "title": "2405.19787v2_Figure4",
            "caption": "Figure 4:Model\u2019s performance onk<3\ud835\udc583k<3italic_k < 3when trained on the three classes of restricted semantics as in4.4. Models trained on 500 or less instructions never generalize to smaller k.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure4.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F5",
            "type": "figure",
            "title": "2405.19787v2_Figure5",
            "caption": "(a)Performance of Llama-2 model on the encrypted-rewriting task. We also conducted uniform / non-uniform sub-samplings to half the total sample size at 9000 instructions. Uniform sub-sampling does not harm performance whereas non-uniform subsampling impacts generalization.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure5.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F5.sf1",
            "type": "figure",
            "title": "2405.19787v2_Figure5(1)",
            "caption": "(a)Performance of Llama-2 model on the encrypted-rewriting task. We also conducted uniform / non-uniform sub-samplings to half the total sample size at 9000 instructions. Uniform sub-sampling does not harm performance whereas non-uniform subsampling impacts generalization.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure5(1).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S4.F5.sf2",
            "type": "figure",
            "title": "2405.19787v2_Figure5(2)",
            "caption": "(b)Effect of long-tail distribution on encrypted-rewriting experiments. As the number of rules increase, the impact of imbalanced distribution diminishes.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure5(2).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S5.F6",
            "type": "figure",
            "title": "2405.19787v2_Figure6",
            "caption": "(a)Semantic clustering of relevant datasets.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure6.png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S5.F6.sf1",
            "type": "figure",
            "title": "2405.19787v2_Figure6(1)",
            "caption": "(a)Semantic clustering of relevant datasets.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure6(1).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S5.F6.sf2",
            "type": "figure",
            "title": "2405.19787v2_Figure6(2)",
            "caption": "(b)OSS-Alpaca mixture and test instructions.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure6(2).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S5.F6.sf3",
            "type": "figure",
            "title": "2405.19787v2_Figure6(3)",
            "caption": "(c)OSS-COT-Alpaca mixture and test instructions.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure6(3).png",
            "alt_text": "Refer to caption"
        },
        {
            "id": "S5.F7",
            "type": "figure",
            "title": "2405.19787v2_Figure7",
            "caption": "Figure 7:Trend of Pass@1 with data mixture. The baseline result is marked with dotted lines.",
            "metadata": {},
            "image_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\imgs\\2405.19787v2_Figure7.png",
            "alt_text": "Refer to caption"
        }
    ],
    "table_chunks": [
        {
            "id": "S4.T1",
            "type": "table",
            "title": "2405.19787v2_Table1",
            "caption": "Table 1:Generalization across input semantics.\ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_Ois the number of occurrences of the rule substring in the training set. Accuracies are measures on a test set with\ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_Ouniformly distributed between 1 and 20",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T1.1.2.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\" id=\"S4.T1.1.2.1.2\"><span class=\"ltx_text\" id=\"S4.T1.1.2.1.2.1\" style=\"font-size:90%;\">Number of instructions</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T1.1.1.1.1\" style=\"font-size:90%;\">Training set occurences </span><math alttext=\"\\mathcal{O}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.1.1.1.m1.1\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.T1.1.1.1.m1.1.1\" mathsize=\"90%\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">\ud835\udcaa</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">\ud835\udcaa</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\mathcal{O}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T1.1.1.1.m1.1d\">caligraphic_O</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T1.1.1.2\"><span class=\"ltx_text\" id=\"S4.T1.1.1.2.1\" style=\"font-size:90%;\">2000</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T1.1.1.3\"><span class=\"ltx_text\" id=\"S4.T1.1.1.3.1\" style=\"font-size:90%;\">1000</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T1.1.1.4\"><span class=\"ltx_text\" id=\"S4.T1.1.1.4.1\" style=\"font-size:90%;\">500</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column\" id=\"S4.T1.1.1.5\"><span class=\"ltx_text\" id=\"S4.T1.1.1.5.1\" style=\"font-size:90%;\">200</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.1.3.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.3.1.1.1\" style=\"font-size:90%;\">1</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.3.1.2\"><span class=\"ltx_text\" id=\"S4.T1.1.3.1.2.1\" style=\"font-size:90%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.3.1.3\"><span class=\"ltx_text\" id=\"S4.T1.1.3.1.3.1\" style=\"font-size:90%;\">0.41</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.3.1.4\"><span class=\"ltx_text\" id=\"S4.T1.1.3.1.4.1\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T1.1.3.1.5\"><span class=\"ltx_text\" id=\"S4.T1.1.3.1.5.1\" style=\"font-size:90%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.4.2.1\"><span class=\"ltx_text\" id=\"S4.T1.1.4.2.1.1\" style=\"font-size:90%;\">10</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.4.2.2\"><span class=\"ltx_text\" id=\"S4.T1.1.4.2.2.1\" style=\"font-size:90%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.4.2.3\"><span class=\"ltx_text\" id=\"S4.T1.1.4.2.3.1\" style=\"font-size:90%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.4.2.4\"><span class=\"ltx_text\" id=\"S4.T1.1.4.2.4.1\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.4.2.5\"><span class=\"ltx_text\" id=\"S4.T1.1.4.2.5.1\" style=\"font-size:90%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.5.3.1\"><span class=\"ltx_text\" id=\"S4.T1.1.5.3.1.1\" style=\"font-size:90%;\">15</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.5.3.2\"><span class=\"ltx_text\" id=\"S4.T1.1.5.3.2.1\" style=\"font-size:90%;\">0.84</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.5.3.3\"><span class=\"ltx_text\" id=\"S4.T1.1.5.3.3.1\" style=\"font-size:90%;\">0.59</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.5.3.4\"><span class=\"ltx_text\" id=\"S4.T1.1.5.3.4.1\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.5.3.5\"><span class=\"ltx_text\" id=\"S4.T1.1.5.3.5.1\" style=\"font-size:90%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.6.4.1\"><span class=\"ltx_text\" id=\"S4.T1.1.6.4.1.1\" style=\"font-size:90%;\">20</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.6.4.2\"><span class=\"ltx_text\" id=\"S4.T1.1.6.4.2.1\" style=\"font-size:90%;\">0.73</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.6.4.3\"><span class=\"ltx_text\" id=\"S4.T1.1.6.4.3.1\" style=\"font-size:90%;\">0.28</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.6.4.4\"><span class=\"ltx_text\" id=\"S4.T1.1.6.4.4.1\" style=\"font-size:90%;\">0.07</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.6.4.5\"><span class=\"ltx_text\" id=\"S4.T1.1.6.4.5.1\" style=\"font-size:90%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T1.1.7.5.1\"><span class=\"ltx_text\" id=\"S4.T1.1.7.5.1.1\" style=\"font-size:90%;\">1,5,10,15,20</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.7.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.7.5.2.1\" style=\"font-size:90%;\">0.94</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.7.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.7.5.3.1\" style=\"font-size:90%;\">0.94</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.7.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.7.5.4.1\" style=\"font-size:90%;\">0.62</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T1.1.7.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.7.5.5.1\" style=\"font-size:90%;\">0.00</span></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S5.T2",
            "type": "table",
            "title": "2405.19787v2_Table2",
            "caption": "Table 2:Pass@1 on DeepSeek-Coder-6.7B. We highlighted the accuracies surpassing baseline result with green and those falling below with red.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T2.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.2.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.1.1.1.1.1\" style=\"font-size:90%;\">OSS</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.1.1.2.1.1\" style=\"font-size:90%;\">-Inst.</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.2.1\" style=\"font-size:90%;\">Alpaca</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.3.1\" style=\"font-size:90%;\">HumanEval</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.4.1\" style=\"font-size:90%;\">HE+</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.5.1\" style=\"font-size:90%;\">MBPP</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S5.T2.2.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.6.1\" style=\"font-size:90%;\">MBPP+</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.2.1.1.7.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.7.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.7.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.7.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.7.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.7.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.7.1.2.1.1\" style=\"font-size:90%;\">(Base)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.8\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.2.1.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.8.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.8.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.1.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.2.1.1.8.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.8.1.2.1.1\" style=\"font-size:90%;\">(+)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.2.1.1.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.1.1.9.1\" style=\"font-size:90%;\">Avg.</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.2.2\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.2.2.1.1\" style=\"font-size:90%;\">20K</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.2.2.2.1\" style=\"font-size:90%;\">0</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.3\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.3.1\" style=\"font-size:90%;\">62.2</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.4\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.4.1\" style=\"font-size:90%;\">56.7</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.5\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.5.1\" style=\"font-size:90%;\">75.7</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S5.T2.2.2.2.6\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.6.1\" style=\"font-size:90%;\">62.4</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.7\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.7.1\" style=\"font-size:90%;\">68.9</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.8\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.8.1\" style=\"font-size:90%;\">59.5</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T2.2.2.2.9\"><span class=\"ltx_text\" id=\"S5.T2.2.2.2.9.1\" style=\"font-size:90%;\">64.2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T2.2.3.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.3.1.1.1\" style=\"font-size:90%;\">18K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.3.1.2.1\" style=\"font-size:90%;\">2K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.3.1.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.3.1.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.5\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T2.2.3.1.5.1\" style=\"font-size:90%;background-color:#FFCCC9;\">75.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T2.2.3.1.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.3.1.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.3.1.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.3.1.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.4</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S5.T2.2.3.1.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.3.1.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.4.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.4.2.1.1\" style=\"font-size:90%;\">17K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.4.2.2.1\" style=\"font-size:90%;\">3K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.4.2.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.6</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.4.2.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">60.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.4.2.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T2.2.4.2.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.4.2.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.4.2.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">70.5</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.4.2.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T2.2.4.2.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.9</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T2.2.4.2.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T2.2.4.2.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.5.3\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.5.3.1.1\" style=\"font-size:90%;\">19K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.5.3.2.1\" style=\"font-size:90%;\">1K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">59.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">75.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T2.2.5.3.6\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.6.1\" style=\"font-size:90%;background-color:#FFCCC9;\">62.2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T2.2.5.3.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.5.3.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.0</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T2.2.5.3.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.5.3.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.6.4\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.6.4.1.1\" style=\"font-size:90%;\">16K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.6.4.2.1\" style=\"font-size:90%;\">4K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">65.2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">58.5</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T2.2.6.4.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.7</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T2.2.6.4.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.1</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T2.2.6.4.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.6.4.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.2.7.5\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.7.5.1.1\" style=\"font-size:90%;\">15K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.2.7.5.2.1\" style=\"font-size:90%;\">5K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.6</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">57.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.5\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.5.1\" style=\"font-size:90%;background-color:#FFCCC9;\">73.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S5.T2.2.7.5.6\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.6.1\" style=\"font-size:90%;background-color:#FFCCC9;\">61.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">69.3</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">59.7</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\" id=\"S5.T2.2.7.5.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T2.2.7.5.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.5</span></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S5.T3",
            "type": "table",
            "title": "2405.19787v2_Table3",
            "caption": "Table 3:Pass@1 with CodeQwen-7B. We highlighted the accuracies surpassing baseline result with green and those falling below with red.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.2.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.1.1.1.1\" style=\"font-size:90%;\">OSS</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.1.2.1.1\" style=\"font-size:90%;\">-Inst.</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.2.1\" style=\"font-size:90%;\">Alpaca</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.3.1\" style=\"font-size:90%;\">HumanEval</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.4.1\" style=\"font-size:90%;\">HE+</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.5.1\" style=\"font-size:90%;\">MBPP</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S5.T3.2.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.6.1\" style=\"font-size:90%;\">MBPP+</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.2.1.1.7.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.7.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.7.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.7.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.7.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.7.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.7.1.2.1.1\" style=\"font-size:90%;\">(Base)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.8\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.2.1.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.8.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.8.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.2.1.1.8.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.8.1.2.1.1\" style=\"font-size:90%;\">(+)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.2.1.1.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.9.1\" style=\"font-size:90%;\">Avg.</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.2.2\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.2.2.1.1\" style=\"font-size:90%;\">20K</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.2.2.2.1\" style=\"font-size:90%;\">0</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.3\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.3.1\" style=\"font-size:90%;\">65.9</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.4\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.4.1\" style=\"font-size:90%;\">59.8</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.5\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.5.1\" style=\"font-size:90%;\">73.7</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S5.T3.2.2.2.6\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.6.1\" style=\"font-size:90%;\">62.2</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.7\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.7.1\" style=\"font-size:90%;\">69.8</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.8\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.8.1\" style=\"font-size:90%;\">61.0</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.2.2.9\"><span class=\"ltx_text\" id=\"S5.T3.2.2.2.9.1\" style=\"font-size:90%;\">65.4</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.3.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.3.1.1.1\" style=\"font-size:90%;\">18K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.3.1.2.1\" style=\"font-size:90%;\">2K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.3.1.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">69.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.3.1.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.3.1.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T3.2.3.1.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.3.1.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.3.1.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">73.0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T3.2.3.1.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.3</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S5.T3.2.3.1.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.3.1.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.4.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.4.2.1.1\" style=\"font-size:90%;\">17K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.4.2.2.1\" style=\"font-size:90%;\">3K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.4.2.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.4.2.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.4.2.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T3.2.4.2.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.4.2.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.9</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T3.2.4.2.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">72.5</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.4.2.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.4.2.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.4</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T3.2.4.2.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S5.T3.2.4.2.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.5.3\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.5.3.1.1\" style=\"font-size:90%;\">19K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.5.3.2.1\" style=\"font-size:90%;\">1K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.7</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">75.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T3.2.5.3.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.5.3.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.5</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T3.2.5.3.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.5.3.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.6.4\">\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.6.4.1.1\" style=\"font-size:90%;\">15K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.6.4.2.1\" style=\"font-size:90%;\">5K</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.3\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.3.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">75.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T3.2.6.4.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T3.2.6.4.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T3.2.6.4.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.6.4.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.7.5\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.7.5.1.1\" style=\"font-size:90%;\">16K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.7.5.2.1\" style=\"font-size:90%;\">4K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.3\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.3.1\" style=\"font-size:90%;background-color:#FFCCC9;\">65.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.4\" style=\"background-color:#FFCCC9;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.4.1\" style=\"font-size:90%;background-color:#FFCCC9;\">58.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S5.T3.2.7.5.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.1</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\" id=\"S5.T3.2.7.5.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T3.2.7.5.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.0</span></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S5.T4",
            "type": "table",
            "title": "2405.19787v2_Table4",
            "caption": "Table 4:CodeQwen-7B-Base trained with mixture of OSS-Instruct, CoT Collection and Alpaca.Ostands for OSS-Instruct,Cstands for CoT-Collection andAstands for Alpaca. The best results for each ratio are boldfaced.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.1\" style=\"font-size:90%;\">Data Mixture</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.2.1\" style=\"font-size:90%;\">Ratio</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.3.1\" style=\"font-size:90%;\">HumanEval</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.4.1\" style=\"font-size:90%;\">HE+</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.5.1\" style=\"font-size:90%;\">MBPP</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S5.T4.2.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.6.1\" style=\"font-size:90%;\">MBPP+</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.7\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T4.2.1.1.7.1\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1.7.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T4.2.1.1.7.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.7.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1.7.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T4.2.1.1.7.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.7.1.2.1.1\" style=\"font-size:90%;\">(Base)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.8\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T4.2.1.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T4.2.1.1.8.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.8.1.1.1.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T4.2.1.1.8.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.8.1.2.1.1\" style=\"font-size:90%;\">(+)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.2.1.1.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.9.1\" style=\"font-size:90%;\">Avg.</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.2.2.1.1\" style=\"font-size:90%;\">O</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.2.2.2.1\" style=\"font-size:90%;\">-</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.3\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.3.1\" style=\"font-size:90%;\">65.9</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.4\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.4.1\" style=\"font-size:90%;\">59.8</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.5\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.5.1\" style=\"font-size:90%;\">73.7</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S5.T4.2.2.2.6\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.6.1\" style=\"font-size:90%;\">62.2</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.7\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.7.1\" style=\"font-size:90%;\">69.8</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.8\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.8.1\" style=\"font-size:90%;\">61.0</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.2.2.9\"><span class=\"ltx_text\" id=\"S5.T4.2.2.2.9.1\" style=\"font-size:90%;\">65.4</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.3.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.3.1.1.1\" style=\"font-size:90%;\">O+A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.3.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.3.1.2.1\" style=\"font-size:90%;\">18:2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.3\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.3.1\" style=\"font-size:90%;\">69.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.3.1.4.1\" style=\"font-size:90%;\">63.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.5\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.5.1\" style=\"font-size:90%;\">76.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T4.2.3.1.6\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.6.1\" style=\"font-size:90%;\">63.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.7\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.7.1\" style=\"font-size:90%;\">73.0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.8\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.8.1\" style=\"font-size:90%;\">63.3</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S5.T4.2.3.1.9\"><span class=\"ltx_text\" id=\"S5.T4.2.3.1.9.1\" style=\"font-size:90%;\">68.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.4.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.1.1\" style=\"font-size:90%;\">O+C+A</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.2.1\" style=\"font-size:90%;\">18:1:1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.3.1\" style=\"font-size:90%;\">68.9</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.4.1\" style=\"font-size:90%;\">63.4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.5.1\" style=\"font-size:90%;\">77.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T4.2.4.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.6.1\" style=\"font-size:90%;\">64.2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.4.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.7.1\" style=\"font-size:90%;\">73.2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.4.2.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.8.1\" style=\"font-size:90%;\">63.8</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T4.2.4.2.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.2.9.1\" style=\"font-size:90%;\">68.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.5.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.5.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.5.3.1.1\" style=\"font-size:90%;\">O+A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.5.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.5.3.2.1\" style=\"font-size:90%;\">16:4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.3\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.3.1\" style=\"font-size:90%;\">65.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.4\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.4.1\" style=\"font-size:90%;\">58.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.5\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.5.1\" style=\"font-size:90%;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T4.2.5.3.6\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.6.1\" style=\"font-size:90%;\">63.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.7\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.7.1\" style=\"font-size:90%;\">71.0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.8\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.8.1\" style=\"font-size:90%;\">61.1</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S5.T4.2.5.3.9\"><span class=\"ltx_text\" id=\"S5.T4.2.5.3.9.1\" style=\"font-size:90%;\">66.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.6.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.1.1\" style=\"font-size:90%;\">O+C+A</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.6.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.2.1\" style=\"font-size:90%;\">16:2:2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.6.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.3.1\" style=\"font-size:90%;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.6.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.4.1\" style=\"font-size:90%;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.6.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.5.1\" style=\"font-size:90%;\">77.2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T4.2.6.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.6.1\" style=\"font-size:90%;\">63.7</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.6.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.7.1\" style=\"font-size:90%;\">72.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T4.2.6.4.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.8.1\" style=\"font-size:90%;\">62.7</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S5.T4.2.6.4.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.4.9.1\" style=\"font-size:90%;\">67.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.7.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.7.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.1.1\" style=\"font-size:90%;\">O+A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.7.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.2.1\" style=\"font-size:90%;\">17:3</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.3.1\" style=\"font-size:90%;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.4.1\" style=\"font-size:90%;\">62.8</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.5.1\" style=\"font-size:90%;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T4.2.7.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.6.1\" style=\"font-size:90%;\">63.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.7.1\" style=\"font-size:90%;\">72.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.8.1\" style=\"font-size:90%;\">63.4</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S5.T4.2.7.5.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.7.5.9.1\" style=\"font-size:90%;\">67.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.8.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.2.8.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.8.6.1.1\" style=\"font-size:90%;\">O+C+A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.2.8.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.8.6.2.1\" style=\"font-size:90%;\">17:1.5:1.5</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.8.6.3.1\" style=\"font-size:90%;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.4\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.4.1\" style=\"font-size:90%;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.5\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.5.1\" style=\"font-size:90%;\">75.4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S5.T4.2.8.6.6\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.6.1\" style=\"font-size:90%;\">62.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.7\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.7.1\" style=\"font-size:90%;\">71.9</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.8\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.8.1\" style=\"font-size:90%;\">62.3</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\" id=\"S5.T4.2.8.6.9\"><span class=\"ltx_text\" id=\"S5.T4.2.8.6.9.1\" style=\"font-size:90%;\">67.1</span></td>\n</tr>\n</tbody>\n</table>"
        },
        {
            "id": "S5.T5",
            "type": "table",
            "title": "2405.19787v2_Table5",
            "caption": "Table 5:Comparison With MagiCoder-DS-6.7B[39]. We demonstrated that one could achieve higher performances by means of diversification.",
            "metadata": {},
            "table_html": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T5.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T5.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.1.1\" style=\"font-size:90%;\">Mix</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T5.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.2.1\" style=\"font-size:90%;\">Ratio</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T5.2.1.1.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T5.2.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T5.2.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.3.1.1.1.1\" style=\"font-size:90%;\">Total</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T5.2.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.3.1.2.1.1\" style=\"font-size:90%;\">#Data</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.4.1\" style=\"font-size:90%;\">HE</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.5.1\" style=\"font-size:90%;\">HE+</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.6.1\" style=\"font-size:90%;\">MBPP</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.7.1\" style=\"font-size:90%;\">MBPP+</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.8\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T5.2.1.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.1.1.8.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.8.1.1.1.1\" style=\"font-size:90%;\">Avg</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.1.1.8.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.8.1.2.1.1\" style=\"font-size:90%;\">(Base)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.9\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T5.2.1.1.9.1\">\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.9.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.1.1.9.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.9.1.1.1.1\" style=\"font-size:90%;\">Avg</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.1.1.9.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.1.1.9.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.9.1.2.1.1\" style=\"font-size:90%;\">(+)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.10.1\" style=\"font-size:90%;\">Avg</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.2.1.1.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.1.1.11.1\" style=\"font-size:90%;\">Rel.\u2191</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T5.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.2.1.1.1\" style=\"font-size:90%;\">O</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.2.1.2.1\" style=\"font-size:90%;\">-</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.2.1.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.4\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.4.1\" style=\"font-size:90%;\">66.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.5\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.5.1\" style=\"font-size:90%;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.6\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.6.1\" style=\"font-size:90%;\">75.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.7\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.7.1\" style=\"font-size:90%;\">61.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.8\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.8.1\" style=\"font-size:90%;\">71.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.9\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.9.1\" style=\"font-size:90%;\">61.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.10\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.10.1\" style=\"font-size:90%;\">66.4</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T5.2.2.1.11\"><span class=\"ltx_text\" id=\"S5.T5.2.2.1.11.1\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.3.2.1.1\" style=\"font-size:90%;\">O+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.3.2.2.1\" style=\"font-size:90%;\">60:15</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.3.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.3.2.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.5\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.5.1\" style=\"font-size:90%;background-color:#F4CCCC;\">59.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">77.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">72.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.3.2.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.2</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.3.2.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.3.2.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">1.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.4.3.1.1\" style=\"font-size:90%;\">O+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.4.3.2.1\" style=\"font-size:90%;\">67.5:7.5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.4.3.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">72.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.4.3.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.4.3.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.4.3.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">1.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.5.4.1.1\" style=\"font-size:90%;\">O+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.5.4.2.1\" style=\"font-size:90%;\">72.5:2.5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.5.4.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.5\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.5.1\" style=\"font-size:90%;background-color:#F4CCCC;\">61.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">72.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.5.4.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.5</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.5.4.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.5.4.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">1.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.6.5.1.1\" style=\"font-size:90%;\">O+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.6.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.6.5.2.1\" style=\"font-size:90%;\">74:1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.6.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.6.5.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.6.5.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">69.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.6.5.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.6.5.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.6.5.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.6.5.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">72.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T5.2.6.5.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.6.5.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T5.2.6.5.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.1</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.6.5.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T5.2.6.5.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">2.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.7.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.7.6.1.1\" style=\"font-size:90%;\">O+C+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.7.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.7.6.2.1\" style=\"font-size:90%;\">60:7.5:7.5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.2.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.7.6.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.4\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.4.1\" style=\"font-size:90%;background-color:#F4CCCC;\">64.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.5\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.5.1\" style=\"font-size:90%;background-color:#F4CCCC;\">59.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.8\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.8.1\" style=\"font-size:90%;background-color:#F4CCCC;\">70.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.9\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.9.1\" style=\"font-size:90%;background-color:#F4CCCC;\">61.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">65.9</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T5.2.7.6.11\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.7.6.11.1\" style=\"font-size:90%;background-color:#F4CCCC;\">-0.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.8.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.8.7.1.1\" style=\"font-size:90%;\">O+C+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.8.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.8.7.2.1\" style=\"font-size:90%;\">67.5:3.25:3.25</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.8.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.8.7.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">64.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.8.7.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">67.3</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.8.7.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.8.7.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">1.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.9.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.1.1\" style=\"font-size:90%;\">O+C+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.9.8.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.2.1\" style=\"font-size:90%;\">72.5:1.25:1.25</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.2.9.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.9.8.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.5\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.9.8.5.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.9.8.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">77.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.9.8.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">65.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.9.8.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">73.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.2.9.8.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">68.4</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T5.2.9.8.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.9.8.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">3.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T5.2.10.9.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.10.9.1.1\" style=\"font-size:90%;\">O+C+A</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T5.2.10.9.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.10.9.2.1\" style=\"font-size:90%;\">74:0.5:0.5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T5.2.10.9.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.2.10.9.3.1\" style=\"font-size:90%;\">75K</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.4\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.4.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.5\" style=\"background-color:#F4CCCC;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.5.1\" style=\"font-size:90%;background-color:#F4CCCC;\">61.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.6\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.6.1\" style=\"font-size:90%;background-color:#D9EAD3;\">76.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.7\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.7.1\" style=\"font-size:90%;background-color:#D9EAD3;\">63.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.8\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.8.1\" style=\"font-size:90%;background-color:#D9EAD3;\">71.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.9\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.9.1\" style=\"font-size:90%;background-color:#D9EAD3;\">62.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.10\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.10.1\" style=\"font-size:90%;background-color:#D9EAD3;\">66.8</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T5.2.10.9.11\" style=\"background-color:#D9EAD3;\"><span class=\"ltx_text\" id=\"S5.T5.2.10.9.11.1\" style=\"font-size:90%;background-color:#D9EAD3;\">0.7</span></td>\n</tr>\n</tbody>\n</table>"
        }
    ],
    "metadata": {},
    "pdf_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\pdfs\\2405.19787v2.pdf",
    "HTML_path": "D:\\PaperIgnition\\PaperIgnition\\orchestrator\\htmls\\2405.19787v2.html"
}