#!/usr/bin/env python3
"""
vLLM Generatoræµ‹è¯•
æµ‹è¯•åšå®¢ç”ŸæˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬vLLMæœåŠ¡è¿æ¥å’Œåšå®¢ç”Ÿæˆ
"""

import sys
import os
import asyncio
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from AIgnite.data.docset import DocSet
from orchestrator.generate_blog import run_batch_generation, run_batch_generation_abs, run_batch_generation_title

def create_test_paper():
    """åˆ›å»ºä¸€ä¸ªæµ‹è¯•è®ºæ–‡å¯¹è±¡"""
    return DocSet(
        doc_id="test_paper_vllm_001",
        title="Attention Is All You Need: A Comprehensive Study of Transformer Architecture",
        authors=["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit"],
        categories=["cs.CL", "cs.LG"],  # æ·»åŠ å¿…éœ€çš„categorieså­—æ®µ
        published_date="2017-06-12",  # æ·»åŠ å¿…éœ€çš„published_dateå­—æ®µ
        abstract="The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing with large and limited training data.",
        content="This is the full content of the test paper about Transformer architecture. It includes detailed information about the research methodology, experimental results, and conclusions.",
        pdf_path="/tmp/test_paper_vllm.pdf",  # æ·»åŠ å¿…éœ€çš„pdf_pathå­—æ®µ
        HTML_path="/tmp/test_paper_vllm.html"
    )

def test_vllm_connection():
    """æµ‹è¯•vLLMæœåŠ¡è¿æ¥"""
    print("ğŸ” æµ‹è¯•vLLMæœåŠ¡è¿æ¥...")
    
    try:
        import aiohttp
        
        # æµ‹è¯•è¿æ¥åˆ°vLLMæœåŠ¡
        vllm_url = "http://localhost:5666"
        
        async def check_connection():
            try:
                async with aiohttp.ClientSession() as session:
                    # å°è¯•å‘é€ä¸€ä¸ªç®€å•çš„è¯·æ±‚
                    async with session.get(f"{vllm_url}/health", timeout=5) as response:
                        if response.status == 200:
                            print("âœ… vLLMæœåŠ¡è¿æ¥æˆåŠŸ")
                            return True
                        else:
                            print(f"âŒ vLLMæœåŠ¡å“åº”å¼‚å¸¸: {response.status}")
                            return False
            except Exception as e:
                print(f"âŒ vLLMæœåŠ¡è¿æ¥å¤±è´¥: {e}")
                return False
        
        # è¿è¡Œå¼‚æ­¥è¿æ¥æµ‹è¯•
        result = asyncio.run(check_connection())
        return result
        
    except ImportError:
        print("âŒ aiohttpæ¨¡å—æœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•vLLMè¿æ¥")
        return False
    except Exception as e:
        print(f"âŒ vLLMè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_blog_generation():
    """æµ‹è¯•åšå®¢ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•åšå®¢ç”ŸæˆåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è®ºæ–‡
        test_papers = [create_test_paper()]
        
        print(f"   æµ‹è¯•è®ºæ–‡: {test_papers[0].title}")
        print(f"   è®ºæ–‡ID: {test_papers[0].doc_id}")
        
        # è°ƒç”¨åšå®¢ç”ŸæˆåŠŸèƒ½
        async def run_generation():
            try:
                result = await run_batch_generation(test_papers)
                return result
            except Exception as e:
                print(f"   åšå®¢ç”Ÿæˆå¼‚å¸¸: {e}")
                return None
        
        result = asyncio.run(run_generation())
        
        if result is not None:
            print("âœ… åšå®¢ç”ŸæˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("âŒ åšå®¢ç”ŸæˆåŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ åšå®¢ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_blog_abs_generation():
    """æµ‹è¯•åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è®ºæ–‡
        test_papers = [create_test_paper()]
        
        print(f"   æµ‹è¯•è®ºæ–‡: {test_papers[0].title}")
        
        # è°ƒç”¨åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½
        async def run_abs_generation():
            try:
                result = await run_batch_generation_abs(test_papers)
                return result
            except Exception as e:
                print(f"   åšå®¢æ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {e}")
                return None
        
        result = asyncio.run(run_abs_generation())
        
        if result is not None:
            print("âœ… åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")
            if result and len(result) > 0:
                print(f"   ç”Ÿæˆçš„æ‘˜è¦é•¿åº¦: {len(result[0])} å­—ç¬¦")
            return True
        else:
            print("âŒ åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ åšå®¢æ‘˜è¦ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_blog_title_generation():
    """æµ‹è¯•åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è®ºæ–‡
        test_papers = [create_test_paper()]
        
        print(f"   æµ‹è¯•è®ºæ–‡: {test_papers[0].title}")
        
        # è°ƒç”¨åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½
        async def run_title_generation():
            try:
                result = await run_batch_generation_title(test_papers)
                return result
            except Exception as e:
                print(f"   åšå®¢æ ‡é¢˜ç”Ÿæˆå¼‚å¸¸: {e}")
                return None
        
        result = asyncio.run(run_title_generation())
        
        if result is not None:
            print("âœ… åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")
            if result and len(result) > 0:
                print(f"   ç”Ÿæˆçš„æ ‡é¢˜: {result[0]}")
            return True
        else:
            print("âŒ åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ åšå®¢æ ‡é¢˜ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_blog_file_save():
    """æµ‹è¯•åšå®¢æ–‡ä»¶ä¿å­˜åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•åšå®¢æ–‡ä»¶ä¿å­˜åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è®ºæ–‡
        test_papers = [create_test_paper()]
        
        # å…ˆç”Ÿæˆåšå®¢
        async def generate_and_check():
            try:
                await run_batch_generation(test_papers)
                
                # æ£€æŸ¥åšå®¢æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
                blog_path = project_root / "orchestrator" / "blogs" / f"{test_papers[0].doc_id}.md"
                
                if blog_path.exists():
                    print(f"âœ… åšå®¢æ–‡ä»¶ä¿å­˜æˆåŠŸ: {blog_path}")
                    
                    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
                    with open(blog_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        print(f"   æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
                        print(f"   å†…å®¹é¢„è§ˆ: {content[:200]}...")
                    
                    return True
                else:
                    print(f"âŒ åšå®¢æ–‡ä»¶æœªæ‰¾åˆ°: {blog_path}")
                    return False
                    
            except Exception as e:
                print(f"   åšå®¢ç”Ÿæˆå’Œä¿å­˜å¼‚å¸¸: {e}")
                return False
        
        result = asyncio.run(generate_and_check())
        return result
        
    except Exception as e:
        print(f"âŒ åšå®¢æ–‡ä»¶ä¿å­˜æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_batch_processing():
    """æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•è®ºæ–‡
        test_papers = [
            create_test_paper(),
            DocSet(
                doc_id="test_paper_vllm_002",
                title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                authors=["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"],
                categories=["cs.CL", "cs.LG"],  # æ·»åŠ å¿…éœ€çš„categorieså­—æ®µ
                published_date="2018-10-11",  # æ·»åŠ å¿…éœ€çš„published_dateå­—æ®µ
                abstract="We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.",
                content="This is the full content of the BERT paper.",
                pdf_path="/tmp/test_paper_vllm_002.pdf",  # æ·»åŠ å¿…éœ€çš„pdf_pathå­—æ®µ
                HTML_path="/tmp/test_paper_vllm_002.html"
            )
        ]
        
        print(f"   æµ‹è¯•è®ºæ–‡æ•°é‡: {len(test_papers)}")
        
        # è°ƒç”¨æ‰¹é‡åšå®¢ç”ŸæˆåŠŸèƒ½
        async def run_batch_generation_test():
            try:
                result = await run_batch_generation(test_papers)
                return result
            except Exception as e:
                print(f"   æ‰¹é‡åšå®¢ç”Ÿæˆå¼‚å¸¸: {e}")
                return None
        
        result = asyncio.run(run_batch_generation_test())
        
        if result is not None:
            print("âœ… æ‰¹é‡å¤„ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("âŒ æ‰¹é‡å¤„ç†åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰vLLM Generatoræµ‹è¯•"""
    print("=" * 60)
    print("ğŸš€ å¼€å§‹vLLM Generatoræµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    # æµ‹è¯•å„ä¸ªåŠŸèƒ½
    results.append(("vLLMæœåŠ¡è¿æ¥", test_vllm_connection()))
    results.append(("åšå®¢ç”ŸæˆåŠŸèƒ½", test_blog_generation()))
    results.append(("åšå®¢æ‘˜è¦ç”ŸæˆåŠŸèƒ½", test_blog_abs_generation()))
    results.append(("åšå®¢æ ‡é¢˜ç”ŸæˆåŠŸèƒ½", test_blog_title_generation()))
    results.append(("åšå®¢æ–‡ä»¶ä¿å­˜åŠŸèƒ½", test_blog_file_save()))
    results.append(("æ‰¹é‡å¤„ç†åŠŸèƒ½", test_batch_processing()))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰vLLM Generatoræµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†vLLM Generatoræµ‹è¯•å¤±è´¥")
        if not results[0][1]:  # vLLMæœåŠ¡è¿æ¥å¤±è´¥
            print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿vLLMæœåŠ¡æ­£åœ¨è¿è¡Œ (ç«¯å£5666)")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
